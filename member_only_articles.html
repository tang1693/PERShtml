<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2026/00000092/00000001/art00011;jsessionid=20in16ui51h6u.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Lightweight YOLO-Based Algorithm for Digital Target Recognition Integrating Positional Enhancement and Morphological Processing
        </a>
    </h3>
    <div style="font-style: italic;">January 2026, pp. 65-72(8)</div>
    <div>Authors: Wang, Sheng; Zheng, Nae; Lv, Pinpin; Gao, Tian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Target detection is vital for modern military applications, yet deploying deep learning models on resource-limited edge devices remains challenging. Existing lightweight models often exhibit poor boundary localization and low digit recognition accuracy, falling short of real-time and precision requirements. This paper introduces a lightweight YOLO-based algorithm enhanced with a novel positional mechanism and morphological processing. The key component, a position-enhanced feature pyramid network (Enhanced-FPN), fuses shallow high-resolution and deep semantic features to improve localization accuracy. A ShuffleNetv2 backbone ensures low computational overhead, while a postdetection module applies morphological processing to robustly extract digit contours and orientation. Evaluated on a custom military data set, the model achieves 49.92% mean average precision at a 50% intersection over union threshold (mAP50) at 11.24 frames/second on an edge device–improving accuracy by 7.02 points and speed by 12.8% over the Yolo-FastestV2 baseline, with a comparable 0.11 GFLOP (Giga Floating Point Operations per second) cost. These results highlight the method’s effectiveness for real-time, high-precision target recognition in constrained environments.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000012/art00011;jsessionid=2onsdfraphhf3.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Novel Multi-level Feature Collaborative Matching Network for Optical and Synthetic Aperture Radar Image Registration
        </a>
    </h3>
    <div style="font-style: italic;">December 2025, pp. 753-761(9)</div>
    <div>Authors: Pang, Bo; Wang, Lei; Wei, Bo; Zhu, Wenlei; Gao, Haiyun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Due to the complementary characteristics of synthetic aperture radar (SAR) and optical images, image registration as a prerequisite for their information fusion has received increasing attention. Currently, learning-based methods can better handle the significant radiometric and geometric differences between optical and SAR images compared to traditional registration approaches, but they still have limitations in distinguishing difficult samples, making high-precision registration a remaining challenge. To address these challenges, this paper proposes a multi-level feature collaborative matching network (MFC-Net) that effectively integrates high-level abstract features and low-level spatial features for precise registration. Furthermore, a novel dual-dimension joint attention module (DDJA) is designed to dynamically capture feature dependencies across both channel and spatial dimensions, enhancing cross-modal feature consistency and improving matching performance. Additionally, to address the problem of similarity between hard positive and negative samples caused by high-precision registration requirements, a dynamic differentiation factor is introduced at the loss function level, enabling the model to better distinguish between these similar samples in training. Extensive experiments conducted on the WHU-OPT-SAR data set and WHU-SENCity data set demonstrate that the proposed MFC-Net outperforms state-of-the-art methods in both matching accuracy and precision, validating its superiority in cross-modal image registration tasks.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000012/art00013;jsessionid=2onsdfraphhf3.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Joint Detection and Parameters Regression of Detailed Windows based on Facade Textures via an Adaptive Soft Teacher
        </a>
    </h3>
    <div style="font-style: italic;">December 2025, pp. 763-775(13)</div>
    <div>Authors: Hu, Han; Li, Chenwei; Xu, Bo; Chen, Min; Zhu, Qing; Han, Zujie; Ning, Xinwen; Fu, Xuesong</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The detailed and precise reconstruction of building facades with semantic information conforming to the level-of-detail protocol has drawn increasing attention in recent years. However, despite windows being a major component of building facades, current research often oversimplifies them in the modeling process, primarily focusing on their location and size. This study proposes a joint approach to simultaneously address window detection and detailed parametric modeling. All required window information, including type, location, and interior structure parameters, is obtained via an end-to-end network. This information is then consolidated into predefined window syntax accessible via the SketchUp Ruby application programming interface (API), resulting in the construction of detailed three-dimensional window models. To resolve the issue of training the network with limited labeled data, an adaptive threshold method based on Soft Teacher is proposed, leveraging the pseudolabel technique and consistency regularization to enhance detection precision. Experiments performed on multiple datasets demonstrate that the proposed methods achieve improved window-detection precision with reduced cell estimation errors compared with existing Faster R‐CNN‐based methods. The mean average precision and average precision at the intersection of union = 0.5 (AP50) metrics increased from 47.9% and 61.9% to 69.0% and 83.1%, respectively. The mean absolute error metric for cell estimation improved from 0.103 to 0.076.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000012/art00017;jsessionid=2onsdfraphhf3.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            ETF-MNet:A Multi-Scale Fusion Network for Enhancing Target Features for Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">December 2025, pp. 787-797(11)</div>
    <div>Authors: Shan, Huilin; Wang, Shuoyang; Hu, Yuxiang; Chen, Xin; Wu, Xinyue; Zhang, Yinsheng</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In response to the challenges of dense target distribution, significant scale variations, and limited feature information for small objects in remote sensing images, this paper introduces a multi-scale fusion network with enhanced target features. Initially, a multi-layer feature aggregation module is constructed within the backbone network to enhance the capability of feature extraction. Subsequently, a multi-channel feature fusion module is implemented in the neck portion of the network to effectively capture cross-channel information and further enhance the expressive power of features at different scales. Moreover, a bi-directional multi-scale feature fusion module is proposed as a mechanism for feature fusion, using top-down and bottom-up fusion strategies to facilitate information interaction among features at different levels. Finally, in the detection layer, a fractional Fourier transform is applied to the image to extract additional feature information, which, combined with convolutional operations, improves the accuracy of small object detection. To validate the effectiveness of the proposed method, experiments were conducted on the data set for object detection in aerial images and Northwestern Polytechnical University very high resolution 10 data sets. The average detection accuracy achieved was 78.7% and 95.4%, respectively. Computational complexity was measured at 95.6 G, and the overall model size was 30.7 M. These results demonstrate that the proposed method excels at high detection accuracy, low computational complexity, and strong feature representation capability. It effectively improves the detection accuracy of small objects in remote sensing images, thereby enhancing the overall performance of small object detection in remote sensing imagery.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000011/art00010;jsessionid=2a4rbjrb9p6t.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Thermal Point Cloud Generation and Evaluation from Uncalibrated Unmanned Aerial Vehicle–Visible and Infrared Camera Images Using Position and Orientation System Prior
        </a>
    </h3>
    <div style="font-style: italic;">November 2025, pp. 693-702(10)</div>
    <div>Authors: Liu, Siqi; Wang, Qiang; Fan, Shenghong; Cui, Ximin; Zou, Yue; Liang, Yubin; Wang, Qian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This paper presents a methodology for thermal infrared (TIR) point cloud acquisition, leveraging information from the visible camera, TIR camera, and their respective unmanned aerial vehicle (UAV) position and their position and orientation systems (POSs) prior. First, the visible images and their corresponding UAV POS information are used to generate a red–green–blue (RGB) dense point cloud with geographic coordinates; subsequently, using the RGB dense point cloud as a reference, the acquisition of a calibration parameter between global navigation satellite system/inertial measurement unit and the TIR camera is conducted using the POS information corresponding to the selected TIR images; finally, a TIR point cloud of the entire survey area is generated based on the calibration parameters. The availability and suitability of the fused TIR point cloud generated and UAV POS data are also evaluated in terms of localization deviations and orientation deviations. The experimental results demonstrate that the acquisition of coarse quality TIR point cloud can be achieved by using a priori POS data provided by different small UAVs. The TIR point cloud generated by the UAV POS data guidance can be directly applied to medium and large-sized buildings. The POS guided projected images achieved an 86.67% registration success rate with the TIR images, indicating that the orientation deviations are within acceptable limits and establishing a solid foundation for subsequent fine fusion.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000011/art00013;jsessionid=2a4rbjrb9p6t.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Novel Spatiotemporal ConvLSTM-Based Cellular Automata Model for Simulating Urban Expansion
        </a>
    </h3>
    <div style="font-style: italic;">November 2025, pp. 715-726(12)</div>
    <div>Authors: Zhou, Ye; Qiu, Yu; Wu, Tao; Lv, Laishui</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurately capturing and simulating the spatiotemporal dynamics of urban expansion remains a persistent challenge in urban planning and environmental management. Traditional machine learning methods often struggle to capture the complexity of spatial features and the multi-scale spatiotemporal dynamics involved in deriving the transition rules of cellular automata (CA), making it difficult to balance detailed local expansion with broader overall trends during the urban expansion simulation process. To address these challenges, we propose a novel spatiotemporal CA model based on the convolutional long short-term memory (ConvLSTM) neural network. This model, termed ST-ConvLSTM-CA, simultaneously enhances critical spatial features and incorporates multi-scale spatiotemporal features by integrating the shuffle attention mechanism and a spatiotemporal expression (SE) block into the ConvLSTM architecture. First, the channel dimensions of spatial features are grouped and channel spatial attention is performed in parallel, allowing for efficient fusion and weighting of key spatial features with minimal computational cost. Second, the SE module is used to integrate the multi-scale information within ConvLSTM cells, enhancing the representation of neighborhood details across different spatial granularities and capturing dynamic temporal features. Finally, the improved model generates conversion probability maps, which are used by the CA model to simulate time series urban expansion maps. Using the urban agglomerations of the Guangdong-Hong Kong-Macao Greater Bay Area, the Yangtze River Delta, and Beijing-Tianjing-Tangshan as case studies, results show that ST-ConvLSTM-CA achieves the highest accuracy across all three regions. This demonstrates its robust adaptability to complex spatiotemporal data and superior predictive performance.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00007;jsessionid=11u1ggiec04i4.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Global Multi-Scale Fusion Self-Calibration Network for Remote Sensing Object Detection
        </a>
    </h3>
    <div style="font-style: italic;">October 2025, pp. 607-621(15)</div>
    <div>Authors: Chen, Yan; Shi, Xinlu; Wang, Xiaofeng; Gu, Qi; Zhang, Chen; Xu, Lixiang; Zhan, Shian; Yu, Wenle</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Applications of remote sensing images in both defense and civilian sectors have spurred substantial research interest. In the field of remote sensing, object detection confronts challenges such as complex backgrounds, scale diversity, and the presence of dense small objects. To address these issues, we propose an improved deep learning-based model, the Global Multi-scale Fusion Self-calibration Network, which is expected to contribute to alleviating the challenges. It consists of three main components: the hierarchical feature aggregation backbone, which uses improved modules such as the receptive field context-aware feature extraction module, the global information acquisition module, and the simple parameter-free attention module to extract key features and minimize the background interference. To couple multi-scale features, we enhanced the fusing component and designed the multi-scale enhanced pyramid structure integrating the proposed new modules. During the detection phase, especially when focusing on small object detection, we designed a novel convolutional attention feature fusion head. This head is constructed to integrate local and global branches for feature extraction by leveraging channel shuffling and multi-head attention mechanisms for efficient and accurate detection. Experiments on the Detection in Optical Remote Sensing Images (DIOR), Northwestern Polytechnical University Very High-Resolution‐10 (NWPU VHR‐10), remote sensing object detection (RSOD), and DOTAv1.0 data sets show that our method achieves mAP50(mean average precision at 50% intersection over union) of 69.7%, 91.3%, 94.2%, and 70.0%, respectively, outperforming existing comparative methods. The proposed network is expected to provide new perspectives for remote sensing tasks and possible solutions for relevant applications in the image domain.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000009/art00008;jsessionid=ppltffgxmf29.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Crack Parameter Determination Based on Multiple-Window Matching Strategy and Crack Grid Geometry Analysis
        </a>
    </h3>
    <div style="font-style: italic;">September 2025, pp. 551-562(12)</div>
    <div>Authors: Tong, Xiaohua; Gao, Sa; Ye, Zhen; Chen, Peng; Liu, Shijie; Xie, Huan; Liu, Xianglei; Hong, Zhonghua; Zhang, Dezhi; Yang, Jun; Song, Yanfeng; Lv, Hongpeng; Cao, Dong</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurate deformation measurement of building materials has consistently been a focal point of research within the field of material testing. This paper proposes a robust 3D crack parameter estimation approach to measure the crack propagation characteristics of concrete pillars under compression testing. Through the use of an improved multiple-window matching strategy and other advanced image processing algorithms, the precise positional information of speckle target points can be calculated in speckle image sequences. 3D point cloud data and full-field deformation of target points on the concrete pillar surface can be further calculated through photogrammetric analysis and spatiotemporal analysis, respectively. Finally, a robust crack estimation algorithm based on grid geometry analysis is proposed to extract accurate crack parameters in the presence of complex speckle texture interference. To verify the superiority and reliability of the proposed approach, both a simulation test and an empirical test were conducted. The experimental results, including positional comparisons with previous matching strategies and displacement comparisons with third-party equipment, corroborate the effectiveness of our method.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000009/art00009;jsessionid=ppltffgxmf29.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            LFSA‐YOLOv7: A Novel Method for Ship Detection in Remote Sensing Images with Complex Backgrounds
        </a>
    </h3>
    <div style="font-style: italic;">September 2025, pp. 563-571(9)</div>
    <div>Authors: Gu, Heng; Li, Wei; Zhang, Linlin; Meng, Qingyan; Wei, Lianhuan; Wu, Hantian; Ma, Jian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Ship target detection is a critical component for marine environmental monitoring and the protection of maritime rights and interests. However, existing methods for ship detection in remote sensing imagery often face challenges such as false positives and missed detections, particularly in the presence of complex backgrounds and multi-scale targets. To address these issues, we propose a novel method called LFSA‐YOLOv7, (LDConv {Linear Deformable Convolution}; SPPFCSPC‐G {Spatial Pyramid Pooling Fast Cross Stage Partial Channel ‐ Group}, SimAM{Simple Attention Module}, and Alpha‐CoIoU {Alpha‐Coordinate Point Orienta tion ‐ Intersection over Union}) which is designed to enhance the accuracy and robustness of ship detection in complex backgrounds: (a) a novel network architecture (LDConv + SPPFCSPC‐G + SimAM) to enhance the model’s ship detection capabilities, and (b) a novel Alpha‐CoIoU loss function to improve the model’s ship localization accuracy. To evaluate the performance of our algorithm in complex backgrounds, we have developed a novel ship classification detection (SCD) data set and conducted comprehensive experiments. Furthermore, we have validated the generalization of our algorithm across various remote sensing ship data sets. The experimental results demonstrate that our algorithm outperforms previous techniques, exhibiting strong generalization and robustness, making it effectively suitable for ship detection in complex backgrounds. The SCD data set and code will be available at https://github.com/wionn/LFSA-YOLOv7.git.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000009/art00011;jsessionid=ppltffgxmf29.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Lightweight and Accurate Video Synthetic Aperture Radar Target Detection Network
        </a>
    </h3>
    <div style="font-style: italic;">September 2025, pp. 573-581(9)</div>
    <div>Authors: Ma, Huilian; Li, Yinwei; Li, Weisong; Zhu, Yiming</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Video synthetic aperture radar (SAR) target detection has seen rapid development in recent years, but current methods generally suffer from high computational complexity as well as frequent false alarms and missed alarms. Additionally, in video SAR scenarios, small targets become more difficult to identify due to low resolution and complex backgrounds. Recently, leveraging shadows for video SAR moving target detection has proven advantageous as it provides accurate location information and additional boundary details. To address the challenges of target detection in video SAR caused by low resolution and complex backgrounds, as well as the high computational cost of current methods, this paper proposes a lightweight algorithm for video SAR shadow detection based on the YOLOv5 architecture, named Lavs-DeNet. First, a lightweight feature extraction backbone network combining both global and local information called CGLLNet is proposed. This backbone improves the detection performance by mitigating false alarms and missed alarms caused by defocus in video SAR images. Next, a slanted ladder bidirectional feature pyramid network (SL‐BiFPN) is designed. By using tilted upsampling with multiple stacked layers, this network efficiently extracts multi-scale features, further reducing missed alarms. Finally, a lightweight information interaction module (LII‐C3) has been developed, significantly reducing computational complexity. To validate the effectiveness of the proposed method, experiments were conducted using the data set released by Sandia National Laboratories. The experimental results show that the proposed Lavs-DeNet can achieve 97.88% detection accuracy, requiring only 21.02G floating points and 0.88M parameters, which is superior to the current classical video SAR target detection networks.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000008/art00010;jsessionid=uw86g81w98nl.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Hierarchical Multi-Scale Cross Interaction Network for Enhanced Hyperspectral Image Classification
        </a>
    </h3>
    <div style="font-style: italic;">August 2025, pp. 495-507(13)</div>
    <div>Authors: Feng, Yuting; Yang, Lina; Wu, Thomas; Huang, Youju</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The significance of hyperspectral image classification lies in its ability to discern subtle differences between materials, making it essential in fields such as agriculture, mineral exploration, and urban planning. Convolutional neural networks (CNNs) and transformer-based methods have become standard for hyperspectral imagery classification, with hybrid approaches gaining popularity. Yet, these methods often lack efficient interaction between the features extracted by CNNs and transformers. To address this, we propose the hierarchical multiscale cross interaction network (HMCI-Net), which leverages both CNNs and transformers to enhance classification accuracy. The CNN branch extracts local spatial-spectral features, and the transformer branch captures global spectral information, allowing the network to model long-range dependencies and complex correlations. Additionally, HMCI-Net incorporates a hierarchical multi-scale feature extraction module and a multi-view feature fusion module, further improving its ability to extract fine-grained, multi-perspective features. Extensive experiments on four benchmark hyperspectral data sets—Indian Pines, Pavia University, WHU-Hi-LongKou, and Houston2013—demonstrate that HMCI-Net outperforms existing methods, achieving an average improvement of 6.24% in average accuracy, 6.14% in kappa coefficient, and 5.55% in overall accuracy. Specifically, HMCI-Net achieves significant gains, with overall accuracy higher by 8.86%, 4.34%, 4.44%, and 4.42% on Indian Pines, Pavia University, WHU-HiLongKou, and Houston2013, respectively. Similarly, average accuracy is higher by 10.57%, 4.94%, 5.65%, and 4.81% for Indian Pines, Pavia University, WHU-Hi-LongKou, and Houston2013, respectively; kappa coefficient is higher by 10.39%, 4.88%, 4.70%, and 4.60%, respectively, on these data sets. The code and data set for this paper can be accessed at: https://github.com/codemanvon30/HMCI_Net.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00012;jsessionid=uk38v2ur8f6d.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Analysis of Landslide Susceptibility of the Darjeeling District Using a Frequency Ratio Model and Geographical Weighted Regression
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 419-432(14)</div>
    <div>Authors: Sen, Suhel; Sarif, Md.Omar</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            India yearly experiences natural disasters such as floods, droughts, cyclones, and landslides, which not only disrupt but also significantly affect the socioeconomic activities of its people. Darjeeling, one of the most valuable districts of West Bengal, India, is located in the foothills of the mighty Himalayas. Landslides in Darjeeling, particularly during the monsoon season, severely affect the socioeconomic conditions of the local population. This research creates a landslide susceptibility map of Darjeeling using the frequency ratio model (FRM) and geographical weighted regression (GWR). The study considers 16 landslide-conditioning factors and 743 past landslide events, of which 70% are used for modeling and the remaining 30% are used for validation. The generated landslide susceptibility map categorizes the area into very low, low, moderate, high, and very high susceptibility zones. Results show that most of the study area falls within the high susceptibility zone, covering approximately 28.45% of the region. The study also reveals that the northern hilly regions of the district are more prone to landslides compared with the southern part, based on FRM and GWR. The area under curve indicates that the model achieved a 74.7% success rate. The highest value of the landslide density index was found in areas classified as having very high landslide susceptibility. Therefore, considering the landslide susceptibility, implementation of effective management strategies is essential for ensuring the future development of the district.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00014;jsessionid=uk38v2ur8f6d.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Leadership in COVID-19: Mitigation Strategies across Top 30 Gross Domestic Product Countries
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 433-442(10)</div>
    <div>Authors: Ozdenerol, Esra; Bingham-Byrne, Rebecca Michelle</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This study analyzes COVID-19 response strategies in the top 30 gross domestic product countries from the first case until 30 September 2021, a period marked by increased vaccinations, the dominance of the Delta variant, and changing public health measures. We examined which mitigation efforts effectively reduced new cases and the viral reproduction rate. Vaccination policies, movement restrictions, and mask mandates were critical in reducing cases per million, while testing, public information, income support, and contact tracing were crucial for lowering the viral reproduction rate. Vaccination policies did not significantly affect the reproduction rate during implementation. The gender of leaders showed no significant effect on cases, deaths, or excess mortality, though female leaders generally implemented fewer isolation days and prioritized additional measures like movement restrictions and stay-at-home orders.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00015;jsessionid=uk38v2ur8f6d.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Lyme Disease Risk Map and Prioritizing Areas for Vaccine Deployment
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 443-454(12)</div>
    <div>Authors: Bingham-Byrne, Rebecca Michelle; Ozdenerol</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Disease surveillance, including risk modeling, is beneficial for infectious diseases. Risk prediction maps can be used to prioritize areas to deliver vaccines reducing disease transmission. For zoonotic infectious diseases such as Lyme disease, potential vaccine deployment areas include cost-effective places key to vectors, wildlife hosts, and humans. This paper uses machine-learning techniques to develop models to predict Lyme disease risk, then uses the critical variables within the models, as well those considered principal from previous literature, to create a Lyme disease risk map and to prioritize areas for wildlife vaccine deployment. It was found that highest disease risk is in the eastern United States, especially the upper Midwest and Northeast regions, which coincides with previous literature. The study found national parks and counties within these areas to prioritize wildlife vaccine deployment. Future work includes ground-truthing of the risk map and dispersal of vaccine to priority areas.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00016;jsessionid=uk38v2ur8f6d.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Enhancing Residential Building Identification in a Coastal Texas City: An Integrated Framework Leveraging Remote Sensing, GIS, and Transfer Learning Techniques
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 455-462(8)</div>
    <div>Authors: Ye, Xinyue; Bai, Weishan; Huang, Xiao</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Rapid urbanization and population growth have intensified the need for accurate and efficient identification of residential buildings in urban planning and disaster management. This paper presents a novel approach for identifying residential buildings by leveraging multiple source data and a transfer learning model, with a case study conducted in Galveston Island, Texas. We propose an integrated framework that combines very-high-resolution (VHR) remote sensing imagery, lidar data, points of interest (POI) data, and GIS-based land use information to extract features of residential buildings. We fine-tune a pretrained deep learning model with our data sets to enhance the model’s adaptability and efficiency in detecting residential buildings in the study area. The results demonstrate that the proposed approach achieves high accuracy in identifying residential buildings, with overall accuracy of 85.6% in the case study. This study also offers valuable insights into the potential of combining multiple data sources and transfer learning techniques for improving residential building identification and other related tasks in urban remote sensing applications.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006/art00012;jsessionid=1xsloaxr9urwi.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Texture-Semantic Point: Registration for Point Clouds of Porcelain Relics
        </a>
    </h3>
    <div style="font-style: italic;">June 2025, pp. 347-360(14)</div>
    <div>Authors: Ge, Xuming; Wu, Chengze; Chen, Min; Xu, Bo; Zhu, Qing; Hu, Han</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Point cloud models of porcelain are captured through the multi-registration of point clouds, which presents a challenging task. On the one hand, the smooth surface of porcelain lacks geometric feature variation, making it difficult to establish corresponding points. On the other hand, the overall geometric symmetry of most porcelain relics can easily lead to iterative calculations falling into the local minimum convergence trap. To address the difficulties in feature point selection, we propose a novel approach using texture-semantic points as features for coarse registration. We first select rich texture points as 2D candidates and establish a 2D-3D matching relationship, giving each candidate its 3D spatial location and associated texture information. Using these correspondences, we perform coarse alignment of the point clouds. However, in reality, the point clouds are not aligned, and the registration calculation fails because of geometric symmetry issues. To address this, we integrate a control net into the iterative closest point (ICP) calculation to guide iterations towards the correct Special Euclidean group in 3 dimensions (SE(3)) transformation, achieving refined alignment. Finally, considering porcelain's symmetrical geometry, we introduce a pose optimization constraint using the symmetry axis as a weighted parameter to limit degrees of freedom and enhance registration accuracy. Experiments were conducted on seven porcelain datasets to evaluate the proposed approach. A qualitative analysis demonstrated successful refined alignment using the proposed approach. In addition, we performed a quantitative comparison with state-of-the-art methods. Experimental results showed that our approach outperformed others across all models when applied to the registration of geometrically symmetric porcelain; Specifically, the proposed method achieved a 50% enhancement in accuracy compared with others, measured by the distance between the labeled corresponding points.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006/art00015;jsessionid=1xsloaxr9urwi.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Phase Center Extraction of Corner Reflector Points in Single-Look Complex Image
        </a>
    </h3>
    <div style="font-style: italic;">June 2025, pp. 371-381(11)</div>
    <div>Authors: Zhao, Ruishan; Yu, Zhi; Wang, Libo; Chen, Chunsen; Huang, Wenchao; Dai, Jiguang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The geometric calibration accuracy of the Synthetic Aperture Radar (SAR) system is affected by the extraction accuracy of Corner Reflector (CR) points in a Single-Look Complex (SLC) image. There are some problems in traditional artificial extraction methods for CR points, such as the difficulty of identifying CR points without prior knowledge, low efficiency, and limited extraction accuracy. An extraction method of the phase center for CR points without prior knowledge was proposed in this paper through the construction of a geometric error compensation model for SAR images and the study of high precision fitting methods of the phase center for CR points. The effectiveness of the proposed method was verified by the Gaofen-3 (GF-3) satellite image data. Experimental results demonstrated that the extraction accuracy of CR points could be better than 0.2 pixel for GF-3 images.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000005/art00009;jsessionid=2hhkmhekdaqu.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            PROSAIL Modeling Coupled with Environmental Stress: Remote Sensing Retrieval of Multiple Dry Matters in the Canopy of Moso Bamboo Forests under the Stress ofPantana phyllostachysaeChao
        </a>
    </h3>
    <div style="font-style: italic;">May 2025, pp. 285-297(13)</div>
    <div>Authors: Xu, Zhanghua; Sun, Lei; Zhang, Yiwei; Zhang, Huafeng; Zhang, Hongbin; Guan, Fengying; Li, Haitao; Yang, Yuanyao; Zhang, Chaofei</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            To address gaps in understanding how external stresses influence remote-sensing inversion of vegetation biochemical components, a P-PROSAIL model incorporating stress factors was developed, with Shunchang County and Yanping District in Fujian Province as the study areas. The model's effectiveness was assessed, yielding R² values of 0.7133, 0.7066, 0.6441, 0.6392, 0.6057, 0.7038, 0.5323, and 0.5149 for leaf area index (LAI), canopy dry matter content (CDMC), canopy cellulose content (CCC), canopy lignin content (CLC), canopy protein content (CPC), canopy nitrogen content (CNC), canopy tannin content (CTC), and canopy flavonoid content (CFC), respectively. While CDMC and most other components showed stable inversions, CTC and CFC exhibited uncertainties due to pest stress. This study clarified the internal and external change characteristics and mechanisms of Moso bamboo forests underPantana phyllostachysaestress, providing empirical support for the ecological health of bamboo forests.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000005/art00011;jsessionid=2hhkmhekdaqu.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Wave Period and Direction Inversion from Marine X-band Radar Images using Spatiotemporal Feature Joint Learning
        </a>
    </h3>
    <div style="font-style: italic;">May 2025, pp. 299-306(8)</div>
    <div>Authors: Wang, Li; Mei, Hui; Yang, Na; She, Caiyun; Qu, Jian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This paper presents a novel artificial intelligence framework based on a spatiotemporal feature joint learning network aimed at con - structing a trainable end-to-end intelligent model for ocean wave period and direction inversion, effectively addressing issues inherent in traditional spectral analysis methods. The spatiotemporal feature joint learning network model proficiently integrates spatial and temporal information of waves and directly maps the obtained results to wave period and direction. The efficacy of the proposed model is validated through application to both simulation data and actual field test data. Comparative analysis with wave period and direction derived from traditional spectral analysis methods reveals a reduction in root mean square error by 0.08 s and 5.5°, respectively, alongside an increase in correlation coefficient by 8% and 9%, respectively, demonstrating that the intelligent method enhances the accuracy of ocean wave parameter inversion without requiring prior knowledge.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00011;jsessionid=19m2fwh144ij7.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Aboveground Carbon Stock of Moso Bamboo Forests Is Significantly Reduced byPantana phyllostachysaeChao Stress: Evidence from Multi-source Remote Sensing Imagery
        </a>
    </h3>
    <div style="font-style: italic;">April 2025, pp. 213-224(12)</div>
    <div>Authors: Yang, Yuanyao; Xu, Zhanghua; Chen, Lingyan; Shen, Wanling; Li, Haitao; Zhang, Chaofei; Sun, Lei; Guo, Xiaoyu; Guan, Fengying</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This study estimated aboveground carbon stock (AGC) using field data and integrated multi-source remote sensing imagery to understand the effects of Pantana phyllostachysae Chao (P. phyllostachysae) stress. AGC remote sensing inversion was performed while accounting for P. phyllostachysae stress, and changes were analyzed. Results indicate: (1) Carbon content coefficients of Moso bamboo leaves, branches, and culms under pest stress ranged from 0.422 to 0.543 g/g, decreasing with increased stress. (2) A random forest model using multi-source data demonstrated the best performance (R2 = 0.688), estimating average AGC at 28.427 t/ha and total carbon sequestration at 913.902 MtC (Million tons of Carbon). (3) Increased pest stress resulted in gradual reductions in AGC. (4) Pest stress is estimated to result in a carbon sequestration loss of 77.443 MtC. The AGC estimation model indicates thatP. phyllostachysaesignificantly reduces AGC, providing crucial data for understanding carbon cycling and enhancing carbon sink management in Moso bamboo forests.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00012;jsessionid=19m2fwh144ij7.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Cost-Effective High-Definition Building Mapping: Box-Supervised Rooftop Delineation Using High- Resolution Remote Sensing Imagery
        </a>
    </h3>
    <div style="font-style: italic;">April 2025, pp. 225-239(15)</div>
    <div>Authors: He, Hongjie; Xu, Linlin; Chapman, Michael A.; Ma, Lingfei; Li, Jonathan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Deep learning–based high-definition building mapping faces challenges due to the need for extensive high-quality training data, leading to significant annotation costs. To mitigate this challenge, we introduce Box2Boundary, a novel approach using box supervision, in conjunction with the segment anything model (SAM), to achieve cost-effective rooftop delineation. Leveraging the tiny InternImage architecture for enhanced feature extraction and using the dynamic scale training strategy to tackle scale variance, Box2Boundary demonstrates superior performance compared to alternative box-supervised methods. Extensive experiments on the Wuhan University Building Data Set validate our method's effectiveness, showcasing remarkable results with an average precision of 48.7%, outperforming DiscoBox, BoxInst, and Box2Mask by 22.0%, 11.3%, and 2.0%, respectively. In semantic segmentation, our method achieved an F1score of 89.54%, an overall accuracy (OA) of 97.73%, and an intersection over union (IoU) of 81.06%, outperforming all other bounding-box-supervised methods, image tag–supervised methods, and most scribble-supervised methods. It also demonstrated competitive performance compared to fully supervised methods and scribble-supervised methods. SAM integration further boosts performance, yielding an F1score of 90.55%, OA of 97.84%, and IoU of 82.73%. Our approach's efficacy extends to the Waterloo Building and xBD Data Sets, achieving an OA of 98.48%, IoU of 84.72%, and F1score of 91.73% for the former and an OA of 97.32%, IoU of 60.10%, and F1score of 75.08% for the latter. These results underscore the method's robustness and cost-effectiveness in rooftop delineation across diverse data sets.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000003/art00010;jsessionid=7tic6vbu3nnb.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Accuracy Assessment of Dense Point Cloud Generated by Deep Learning and Semiglobal Matching
        </a>
    </h3>
    <div style="font-style: italic;">March 2025, pp. 153-162(10)</div>
    <div>Authors: Sadeq, Haval Abduljabbar</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This study assesses two techniques for generating point clouds based on dense image matching (DIM): semiglobal matching (SGM) implemented in Trimble INPHO MATCH-3DX software, and a deep-learning algorithm Pyramid Stereo Matching Network (PSMNet). The PSMNet was trained using three datasets with both automated driving and aerial scenes. Two other distinctive sites were selected to assess the accuracy against LiDAR data. The study found inaccuracies in the PSMNet point clouds and suggested that SGM could potentially result in a better outcome. However, for flat slab or ground surface, its root-mean-square error is better than SGM. The analysis showed that the SGM analyses favorably remove points on vertical surfaces due to occlusion, while PSMNet incorrectly extrapolate them with slopes. Furthermore, the assessment identified the potential to improve PSMNet by using more or in-distribution training dataset for test (unseen) areas.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000003/art00013;jsessionid=7tic6vbu3nnb.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Real-time Vanishing Point Tracking in Manhattan World Using Improved BaySAC
        </a>
    </h3>
    <div style="font-style: italic;">March 2025, pp. 175-186(12)</div>
    <div>Authors: Ye, Chenming; Kang, Zhizhong; Cai, Jinhao; Zhu, Longze</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Vanishing points provide geometric information about a scene and assist in camera calibration, scene understanding, and 3D reconstruction. The random sample consensus (RANSAC) algorithm faces challenges of low efficiency and insufficient robustness. With prior information, the Bayesian sample consensus (BaySAC) algorithm can efficiently derive the correct parameters and compensate for the deficiencies of the RANSAC algorithm. This study proposes an improved BaySAC vanish - ing point detection algorithm, which uses a linear grouping strategy to enhance the distribution of inliers across groups and accelerate convergence. In the continuous frame vanishing point tracking problem, the detection result of the previous frame is employed as a priori infor - mation for the subsequent frames, facilitating efficient convergence for vanishing point detection and tracking in videos. Experimental results on both benchmark datasets and real-world image sets demonstrate that the proposed method achieves remarkable accuracy and efficiency, enabling real-time performance for vanishing point detection and track- ing. The code is available at https://github. com/CHEMYE/BaySAC.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000002/art00008;jsessionid=7bb4imua1a6ot.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spatiotemporal Behavior of Active Forest Fires Using Time-Series MODIS C6 Data
        </a>
    </h3>
    <div style="font-style: italic;">February 2025, pp. 85-90(6)</div>
    <div>Authors: Azimuddin, Syed; Dwivedi, R.S.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Forest fires have a profound influence on the economy, ecology, and environment. Realizing the potential of remote sensing in forest fire management, a study was taken up to investigate the spatiotemporal behavior of active forest fires in a mountainous terrain of Uttarakhand State, north India, using 15 years' time-series historical MODIS (C6) active fire point products. Results indicate an over-all fire incidence detection accuracy of 62.3% with a KHAT value of 0.59. Moreover, a regular trend in intra-annual behavior in fire incidences with peaks during the hot and dry period of the year was observed and a large year-to-year variability in fire regimes with no significant trends over time could be noticed. The approach and results are discussed in detail along with the future perspective.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000002/art00011;jsessionid=7bb4imua1a6ot.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Individual Tree Segmentation Using Deep Learning and Climbing Algorithm: A Method for Achieving High-precision Single-tree Segmentation in High-density Forests under Complex Environments
        </a>
    </h3>
    <div style="font-style: italic;">February 2025, pp. 101-110(10)</div>
    <div>Authors: Ma, He; Zhang, Fangmin; Chen, Simin; Yu, Jinge</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurate individual tree segmentation, which is important for forestry investigation, is still a difficult and challenging task. In this study, we developed a climbing algorithm and combined it with a deep learning model to extract forests and achieve individual tree segmentation using lidar point clouds. We tested the algorithm on mixed forests within complex environments scanned by unmanned aircraft system lidar in ecological restoration mining areas along the Yangtze River of China. Quantitative assessments of the segmentation results showed that the forest extraction achieved a kappa coefficient of 0.88, and the individual tree segmentation results achieved F-scores ranging from 0.86 to 1. The climbing algorithm successfully reduced false positives and false negatives with the increased crown overlapping and outperformed the widely used top-down region-growing point cloud segmentation method. The results indicate that the climbing algorithm proposed in this study will help solve the overlapped crown problem of tree segmentation under complex environments.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000002/art00012;jsessionid=7bb4imua1a6ot.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Lightweight Ship Object Detection Algorithm for Remote Sensing Images Based on Multi-scale Perception and Feature Enhancement
        </a>
    </h3>
    <div style="font-style: italic;">February 2025, pp. 111-122(12)</div>
    <div>Authors: Sun, Wei; Shen, Xinyi; Zhang, Xiaorui; Guan, Fei</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            As global trade and maritime traffic develop, exploring ship detection in remote sensing images has become a research hotspot. However, ships in remote sensing images are so small that it leads to a high detection leakage rate and excessive model parameters, making them difficult to apply on remote sensing equipment with limited resources. To address the challenge, we propose a light-weight ship object detection algorithm, adaptive layered multi-scale You Only Look Once version 8 (ALM-YOLOv8), based on multi-scale perception and feature enhancement. To enhance the model's perception of contextual information in complex backgrounds, a multi-scale channel fusion module is constructed to extract features of various scales. To enhance the extracted features, a small-object detection layer and a dynamic channel attention convolution that assigns dynamic weights are proposed. Additionally, this study embeds the large separable kernel attention mechanism into the original network, which lightens the model. Experiments on the HRSC2016 dataset demonstrate the effectiveness of ALM-YOLOv8.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000001/art00009;jsessionid=4pe9ptjsj03jv.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Landslide Evolution Assessment Based on Sequential InSAR Methods in the Kunming Transmission Line Corridor
        </a>
    </h3>
    <div style="font-style: italic;">January 2025, pp. 19-25(7)</div>
    <div>Authors: Wen, Gang; Li, Yizuo; Xie, Chuhang; Zheng, Zezhong; Ma, Yi; Zhou, Fangrong; Su, Baiyan; Tang, Huahui</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The security of the transmission line corridor is an important guar- antee for the sustainable supply of electricity and an important prerequisite for the rapid development of the economy. Transmission corridors located in high mountains and valleys are often threatened by geological disasters, which seriously affect their stable operation. This research investigates the landslide in the Kunming transmission corridor using 79 Sentinel-1A SAR images from July 2020 to October 2021. Using interferometric synthetic aperture radar (InSAR) methods, deformation changes before the landslide are analyzed. Factors like precipitation, lithology, and vegetation coverage demonstrate a correlation with landslide occurrence. Seasonal variations in deformation were related to precipitation. The landslide's primary causes are attributed to precipitation, carbonate karstification, and vegetation coverage. Ultimately, this research establishes a correlation between deformation changes and influencing factors in the Kunming transmission corridor, contributing to a deeper understanding of landslide evolution and ensuring the corridor's security for sustainable electricity supply and economic development.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000001/art00012;jsessionid=4pe9ptjsj03jv.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Adaptive Orientation Object-Detection Method for Large-scale Remote Sensing Images Based on Multi-scale Block Fusion
        </a>
    </h3>
    <div style="font-style: italic;">January 2025, pp. 27-34(8)</div>
    <div>Authors: Wang, Yanli; Dong, Zhipeng; Wang, Mi; Ding, Yi</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Object detection is crucial to extracting and analyzing information autonomously from high-resolution remote sensing images (HRSIs). To address ideal blocking for large-scale  HRSI object detection, this study uses a novel adaptive orientation object-detection method for largescale HRSIs based on multi-scale block fusion. An adaptive orientation object-detection  framework based on a convolutional neural network is applied to detect diverse objects of large-scale HRSIs through different block scales; average precision (AP) values of diverse object  detection results are calculated at different block scales. Then, block scales matching the largest AP values of diverse objects are determined based on statistical results of the AP  values of the diverse object at different block scales. Finally, object-detection results at block scales matching the largest AP values of diverse objects are fused by the non-maximum  suppression algorithm to achieve large-scale HRSI object-detection results. Experimental findings reveal that the proposed method is better than any single block-scale object-detection  method, resulting in satisfactory large-scale HRSI object-detection results.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000001/art00013;jsessionid=4pe9ptjsj03jv.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            RSODNet: Lightweight Remote Sensing Image Object Detection Combined with BCDNS Compression Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">January 2025, pp. 35-51(17)</div>
    <div>Authors: Zhu, Xinyu; Zhang, Zhihua; Wang, Wei; Hou, Yuhao; Yang, Shuwen</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In recent years, with the gradual increase of neural network Params (the aggregate of trainable elements in a model, including weights, biases, and other adjustable elements)  and calculation volume, model compression within an acceptable range of network accuracy variations has emerged as a prominent research focus in the field of deep learning. Model  pruning and knowledge distillation have been widely used for reducing the complexity and storage cost of neural networks. This study designs the Remote Sensing Object Detection Network  (RSODNet), a lightweight model for remote sensing image object detection, and proposes bridging cross-task distillation network slimming (BCDNS) as a method that integrates model pruning and  knowledge distillation. The experiment results indicate that RSODNet outperforms the YOLOv8 model in various metrics while maintaining almost unchanged Params and calculation volume. The  BCDNS method eliminates redundant channels while preserving a priori knowledge of the initial model intact. This study offers technical support for compressed models used in object detection  from remote sensing images
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000001/art00015;jsessionid=4pe9ptjsj03jv.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring and Predictive Analysis of Surface Deformation Using Combined SBAS-InSAR Technology and CS-Elman Neural Network: A Case Study of Wenchuan County, Sichuan Province, China
        </a>
    </h3>
    <div style="font-style: italic;">January 2025, pp. 53-63(11)</div>
    <div>Authors: Chen, Kuayue; Wang, Baoyun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Earthquakes deposit loose materials in gullies, making seismic mountain gorges prone to landslides and debris flows. Monitoring and predicting ground deformation in these areas is essential. This study introduces a CS-Elman prediction model based on SBAS-InSAR monitoring. SBAS-InSAR technology analyzes 36 Sentinel-1A im- ages from Wenchuan County, Sichuan Province, China (June 2021 to October 2023), focusing on deformation areas and precipitation data. The CS algorithm optimizes the Elman network's parameters, using SBAS-InSAR data as training samples. Validation shows that: (1) Wenchuan County experiences varied deformation, with Banzi Gully in Miansi Town showing the highest uplift at 183.74 mm/a due to heavy rain. (2) As sample size increases, prediction error decreases and accuracy improves. Predictions suggest ongo- ing uplift at about 4.50 mm per month above Cutou Gully over the next four months, highlighting the need for continued monitoring.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00008;jsessionid=1gwjqzhhk8piu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Remote Sensing Tailing Pond Image–Detection Method Based on YOLOv8-RVSW
        </a>
    </h3>
    <div style="font-style: italic;">December 2024, pp. 735-744(10)</div>
    <div>Authors: Dang, Zhengjun; Li, Kun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This study proposes an automated tailings pond-detection method based on the YOLOv8-RVSW model to address the limitations of traditional surveys. A tailings pond dataset was created using high-resolution satellite images, and data quality was improved through data augmentation techniques. In the model, YOLOv8's backbone feature network was replaced with RepViT to effectively capture global and local information. Additionally, the C2f module was enhanced to QuadraSE_C2f to focus on essential feature channels, and WIoUv3 was used as the loss function to improve object localization and detection accuracy. Experimental results indicate that compared with the original model, accuracy increased by 3.9% to 97.4%, recall improved by 4.9% to 96.3%, and mean average precision rose by 2.4% to 98.5%. This method significantly enhances the automation and intelligence of tailings pond monitoring, providing an effective tool for emergency monitoring.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00010;jsessionid=wo3vdpacs6r9.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Morphology-Based Feature Extraction Network for Arbitrary-Oriented SAR Vehicle Detection
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 665-673(9)</div>
    <div>Authors: Chen, Ting; Huang, Xiaohong</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In recent years, synthetic aperture radar (SAR) vehicle detection has become a research hotspot. However, algorithms using horizontal bounding boxes can lead to redundant detection areas due to the varying aspect ratio and arbitrary orientation of vehicle targets. This paper proposes a morphology-based feature extraction network (MFE-Net), which fully uses the prior shape knowledge of the vehicle targets. Specifically, we adopt rotatable bounding boxes to predict the targets, and a novel rectangular rotation-invariant coordinate convolution (RRICC) is proposed to extract the feature, which can determine more accurately the convolutional sampling location of the vehicles. The adaptive thresholding denoising module (ATDM) is designed to suppress background clutter. Furthermore, inspired by the convolutional neural networks (CNNs) and self-attention, we propose the hybrid representation enhancement module (HREM) to highlight the vehicle target features. The experiment results show that the proposed model obtains an average precision (AP) of 93.1% on the SAR vehicle detection data set (SVDD).
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00011;jsessionid=wo3vdpacs6r9.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spatial-Spectral Middle Cross-Attention Fusion Network for Hyperspectral Image Superresolution
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 675-686(12)</div>
    <div>Authors: Lang, Xiujuan; Lu, Tao; Zhang, Yanduo; Jiang, Junjun; Xiong, Zixiang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The spatial and spectral features of hyperspectral images exhibit complementarity, and neglecting them prevents the full exploitation of useful information for superresolution. This article proposes a spatial-spectral middle cross-attention fusion network to explore the spatial-spectral structure correlation. Initially, we learn spatial and spectral features through spatial and spectral branches instead of single ones to reduce information compression. Then, a novel middle-cross attention fusion block that includes middle features fusion strategy and cross-attention is proposed to fuse spatial-spectral features to enhance their mutual effects, which aims to explore the spatial-spectral structural correlations. Finally, we propose a spectral feature compensation mechanism to provide complementary information for adjacent band groups. The experimental results show that the proposed method outperforms state-of-the-art algorithms in object values and visual quality.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00014;jsessionid=wo3vdpacs6r9.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Variable-Iterative Fully Convolutional Neural Network for Sparse Unmixing
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 699-706(8)</div>
    <div>Authors: Kong, Fanqiang; Lv, Zhijie; Wang, Kun; Fang, Xu; Zheng, Yuhan; Yu, Shengjie</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Neural networks have greatly promoted the development of hyperspectral unmixing (HU). Most data-driven deep networks extract features of hyperspectral images (HSIs) by stacking convolutional layers to achieve endmember extraction and abundance estimation. Some model-driven networks have strong interpretability but fail to mine the deep feature. We propose a variable-iterative fully convolutional neural network (VIFCNN) for sparse unmixing, combining the characteristics of these two networks. Under the model-driven iterative framework guided by sparse unmixing by variable splitting and augmented lagrangian (SUnSAL), a data-driven spatial-spectral feature learning module and a spatial information updating module are introduced to enhance the learning of data information. Experimental results on synthetic and real datasets show that VIFCNN significantly outperforms several traditional unmixing methods and two deep learning-based methods. On real datasets, our method improves signal-to-reconstruction error by 17.38%, reduces abundance root-mean-square error by 25.24%, and reduces abundance spectral angle distance by 31.40% compared with U-ADMM-ßUNet.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00008;jsessionid=16mf6lifehhl7.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Attention Heat Map-Based Black-Box Local Adversarial Attack for Synthetic Aperture Radar Target Recognition
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 601-609(9)</div>
    <div>Authors: Wan, Xuanshen; Liu, Wei; Niu, Chaoyang; Lu, Wanjie</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Synthetic aperture radar (SAR) automatic target recognition (ATR) models based on deep neural networks (DNNs) are susceptible to adversarial attacks. In this study, we proposed an SAR black-box local adversarial attack algorithm named attention heat map- based black-box local adversarial attack (AH-BLAA). First, we designed an attention heat map extraction module combined with the layer-wise relevance propagation (LRP) algorithm to obtain the high concerning areas of the SAR-ATR models. Then, to gener- ate SAR adversarial attack examples, we designed a perturbation generator module, introducing the structural dissimilarity (DSSIM) metric in the loss function to limit image distortion and the dif- ferential evolution (DE) algorithm to search for optimal perturba- tions. Experimental results on the MSTAR and FUSAR-Ship datasets showed that compared with existing adversarial attack algorithms, the attack success rate of the AH-BLAA algorithm increased by 0.63% to 33.59% and 1.05% to 17.65%, respectively. Moreover, the low- est perturbation ratios reached 0.23% and 0.13%, respectively.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00010;jsessionid=16mf6lifehhl7.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Exploring the Potential of the Hyperspectral Remote Sensing Data China OrbitaZhuhai-1in Land Cover Classification
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 611-619(9)</div>
    <div>Authors: Li, Caixia; Xiong, Xiaoyan; Wang, Lin; Li, Yunfan; Wang, Jiaqi; Zhang, Xiaoli</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Responding to the shortcomings of China's civil remote sensing data in land cover classification, such as the difficulty of data acquisition and the low utilization rate, we used Landsat-8, China Orbita Zhuhai-1 hyperspectral remote sensing (OHS) data, and Landsat-8 + OHS data combined with band (red, green, and blue) and vegetation index features to classify land cover using maximum likelihood (ML), Mahalanobis distance (MD), and support vector machine (SVM). The results show that Landsat-8 + OHS data have the highest classification accuracy in SVM, with an overall accuracy of 83.52% and a kappa coefficient of 0.71, and this result is higher than that of Landsat-8 images and OHS images separately. In addition, the classification accuracy of OHS images was higher than that of Landsat-8 images. The results of the study provide a reference for the use of civil satellite remote sensing data in China.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00012;jsessionid=16mf6lifehhl7.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Teacher-Student Prototype Enhancement Network for a Few-Shot Remote Sensing Scene Classification
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 621-630(10)</div>
    <div>Authors: Zhu, Ye; Yang, Shanying; Yu, Yang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Few-shot remote sensing scene classification identifies new classes from limited labeled samples where the great challenges are intraclass diversity, interclass similarity, and limited supervision. To alleviate these problems, a teacher-student prototype enhancement network is proposed for a few-shot remote sensing scene classification. Instead of introducing an attentional mechanism in mainstream studies, a prototype enhancement module is recommended to adaptively select high-confidence query samples, which can enhance the support prototype representations to emphasize intraclass and interclass relationships. The construction of a few-shot teacher model generates more discriminative predictive representations with inputs from many labeled samples, thus providing a strong supervisory signal to the student model and encouraging the network to achieve accurate classification with a limited number of labeled samples. Extensive experiments of four public datasets, including NWPU-remote sens ing image scene classification (NWPU-RESISC45), aerial image dataset (AID), UC Merced, and WHU-RS19, demonstrate that this method achieves superior competitive performance than the state-of-the-art methods on five-way, one-shot, and five-shot classifications.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00007;jsessionid=3hjadkof6p7d8.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Development of an Automatic Feature Point Classification Method for Three-Dimensional Mapping Around Slewing and Derricking Cranes
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 538-552(15)</div>
    <div>Authors: Shigemori, Hisakazu; Susaki, Junichi; Yoneda, Mizuki; Ososinski, Marek</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Crane automation requires a three-dimensional (3D) map around cranes that should be reconstructed and updated quickly.In this study, a high-precision classification method was developed to distinguish stationary objects from moving objects in moving images captured by a monocular camera to stabilize 3D reconstruction. To develop the method, a moving image was captured while the crane was slewed with a monocular camera mounted vertically downward at the tip of the crane. The boom length and angle data were output from a control device, a controller area network. For efficient development, a simulator that imitated the environment of an actual machine was developed and used. The proposed method uses optical flow to track feature points. The classification was performed successfully, independent of derricking motion. Consequently, the proposed method contributes to stable 3D mapping around cranes in construction sites.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00009;jsessionid=3hjadkof6p7d8.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Semantic Segmentation of Point Cloud Scene via Multi-Scale Feature Aggregation and Adaptive Fusion
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 553-563(11)</div>
    <div>Authors: Guo, Baoyun; Sun, Xiaokai; Li, Cailin; Sun, Na; Wang, Yue; Yao, Yukai</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Point cloud semantic segmentation is a key step in 3D scene understanding and analysis. In recent years, deep learning–based point cloud semantic segmentation methods have received extensive attention from researchers. Multi-scale neighborhood feature learning methods are suitable for inhomogeneous density point clouds, but different scale branching feature learning increases the computational complexity and makes it difficult to accurately fuse different scale features to express local information. In this study, a point cloud semantic segmentation network based on RandLA-Net with multi-scale local feature aggregation and adaptive fusion is proposed. The designed structure can reduce computational complexity and accurately express local features. The mean intersection-over-union is improved by 1.1% on the SemanticKITTI data set with an inference speed of nine frames per second, while the mean intersection-over-union is improved by 0.9% on the S3DIS data set, compared with RandLA-Net. We also conduct ablation studies to validate the effectiveness of the proposed key structure.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00011;jsessionid=3hjadkof6p7d8.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Robust Star Identification Algorithm for Resident Space Object Surveillance
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 565-574(10)</div>
    <div>Authors: Wu, Liang; Hao, Pengyu; Zhang, Kaixuan; Zhang, Qian; Han, Ru; Cao, Dekun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Star identification algorithms can be applied to resident space object (RSO) surveillance, which includes a large number of stars and false stars. This paper proposes an efficient, robust star identification algorithm for RSO surveillance based on a neural network. First, a feature called equal-frequency binning radial feature (EFB-RF) is proposed for guide stars, and a superficial neural network is constructed for feature classification. Then the training set is generated based on EFB-RF. Finally, the remaining stars are identified using a residual star matching method. The simulation experiment and results show that the identification rate of our algorithm can reach 99.82% under 1 pixel position noise, and it can reach 99.54% under 5% false stars. When the percentage of missing stars is 15%, it can reach 99.40%. The algorithm is verified by RSO surveillance.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00013;jsessionid=3hjadkof6p7d8.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Wavelets for Self-Calibration of Aerial Metric Camera Systems
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 575-587(13)</div>
    <div>Authors: Ye, Jun-Fu; Tsay, Jaan-Rong; Fritsch, Dieter</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In this paper, wavelets are applied to develop new models for the self-calibration of aerial metric camera systems. It is well known and mathematically proven that additional parameters (APs) can compensate image distortions and remaining error sources by a rigorous photogrammetric bundle-block adjustment. Thus, kernel functions based on orthogonal wavelets (e. g., asymmetric Daubechies wave- lets, least asymmetric Daubechies wavelets, Battle-Lemarié wavelets, Meyer wavelets) are used to build the wavelets-based family of APs for self-calibrating digital frame cameras. These new APs are called wavelet APs. Its applications in rigorous tests are accomplished by using aerial images taken by an airborne digital mapping camera in situ and practical calibrations. The test results demonstrate that these orthogonal wavelet APs are applicable and largely avoid the risk of over-parameterization. Their external accuracy is evaluated using reliable and high precision check points in the calibration field.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00006;jsessionid=1puu3o152mh4a.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Real-Time Semantic Segmentation of Remote Sensing Images for Land Management
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 335-343(9)</div>
    <div>Authors: Zhang, Yinsheng; Ji, Ru; Hu, Yuxiang; Yang, Yulong; Chen, Xin; Duan, Xiuxian; Shan, Huilin</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Remote sensing image segmentation is a crucial technique in the field of land management. However, existing semantic segmentation networks require a large number of floating-point operations (FLOPs) and have long run times. In this paper, we propose a dual-path feature aggregation network (DPFANet) specifically designed for the low-latency operations required in land management applications. Firstly, we use four sets of spatially separable convolutions with varying dilation rates to extract spatial features. Additionally, we use an improved version of MobileNetV2 to extract semantic features. Furthermore, we use an asymmetric multi-scale fusion module and dual-path feature aggregation module to enhance feature extraction and fusion. Finally, a decoder is constructed to enable progressive up-sampling. Experimental results on the Potsdam data set and the Gaofen image data set (GID) demonstrate that DPFANet achieves overall accuracy of 92.2% and 89.3%, respectively. The FLOPs are 6.72 giga and the number of parameters is 2.067 million.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00007;jsessionid=1puu3o152mh4a.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Land Use Change in the Yangtze River Economic Belt during 2010 to 2020 and Future Comprehensive Prediction Based on Markov and ARIMA Models
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 345-354(10)</div>
    <div>Authors: Zheng, Haotian; Yu, Fan; Wan, Huawei; Shi, Peirong; Wang, Haonan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The key data for accurate prediction is of great significance to accurately carry out the next step of sustainable land use development plan according to the demand of China. Consequently, the main purposes of our study are: (1) to delineate the characteristics of land use transitions within the Yangtze River Economic Belt; (2) to use the Markov model and the autoregressive integrated moving average (ARIMA) model for comparative analysis and prediction of land use distribution. This study analyzes land use/cover change (LUCC) data from 2010 and 2020 using the land use transition matrix, dynamic degree, and comprehensive index model and predicts 2025 land use by the Markov model. The study identifies a reduction in land usage over 11 years, particularly in grassland. The Markov and ARIMA models' significance is 0.002 (P < 0.01), showing arable land and woodland dominance, with varying changes in other land types.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00009;jsessionid=1puu3o152mh4a.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Improved YOLO Network for Insulator and Insulator Defect Detection in UAV Images
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 355-361(7)</div>
    <div>Authors: Zhou, Fangrong; Liu, Lifeng; Hu, Hao; Jin, Weishi; Zheng, Zezhong; Li, Zhongnian; Ma, Yi; Wang, Qun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The power grid plays a vital role in the construction of livelihood projects by transmitting electrical energy. In the event of insulator explosions on power grid towers, these insulators may detach, presenting potential safety risks to transmission lines. The identification of such failures relies on the examination of images captured by unmanned aerial vehicles (UAVs). However, accurately detecting insulator defects remains challenging, particularly when dealing with variations in size. Existing methods exhibit limited accuracy in detecting small objects. In this paper, we propose a novel detection method that incorporates the convolutional block attention module (CBAM) as an attention mechanism into the backbone of the "you only look once" version 5 (YOLOv5) model. Additionally, we integrate a residual structure into the model to learn additional information and features related to insulators, thereby enhancing detection efficiency. Experimental results demonstrate that our proposed method achieved F1 scores of 0.87 for insulator detection and 0.89 for insulator defect detection. The improved YOLOv5 network shows promise in detecting insulators and their defects in UAV images.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00007;jsessionid=3n361b37dtmk2.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Pixel Texture Index Algorithm and Its Application
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 277-292(16)</div>
    <div>Authors: Sun, Xiaodan; Sun, Xiaofang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Image segmentation is essential for object-oriented analysis, and classification is a critical parameter influencing analysis accuracy. However, image classification and segmentation based on spectral features are easily perturbed by the high-frequency information of a high spatial resolution remotely sensed (HSRRS) image, degrading its classification and segmentation quality. This article first presents a pixel texture index (PTI) by describing the texture and edge in a local area surrounding a pixel. Indeed.. The experimental results highlight that the HSRRS image classification and segmentation quality can be effectively improved by combining it with the PTI image. Indeed, the overall accuracy improved from 7% to 14%, and the kappa can be increased from 11% to 24%, respectively.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00008;jsessionid=3n361b37dtmk2.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Parcel-Level Crop Classification in Plain Fragmented Regions Based on Multi-Source Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 293-302(10)</div>
    <div>Authors: Zhang, Qiao; Luo, Ziyi; Shen, Yang; Wang, Zhoufeng</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurately obtaining crop cultivation extent and estimating the cultivated area are significant for adjusting regional planting structure. This article proposes a parcel-level crop classification method using time-series, medium-resolution, remote sensing images and single-phase, high-spatial-resolution, remote sensing images. The deep learning semantic segmentation network feature pyramid network with squeeze-and-excitation network (FPN-SENet) and multi-scale segmentation were used to extract cultivated land parcels from Gaofen-2 imagery, while the pixel-level crop types were classified by using support vector machine algorithms from time-series Sentinel-2 images. Then, the parcel-level crop classification was obtained from the pixel-level crop types and land parcels.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00009;jsessionid=3n361b37dtmk2.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Evaluation of SMAP and CYGNSS Soil Moistures in Drought Prediction Using Multiple Linear Regression and GLDAS Product
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 303-312(10)</div>
    <div>Authors: Edokossi, Komi; Jin, Shuanggen; Calabia, Andres; Molina, Iñigo; Mazhar, Usman</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Drought is a devastating natural hazard and exerts profound effects on both the environment and society. Predicting drought occurrences is significant in aiding decision-making and implementing effective mitigation strategies. In regions characterized by limited data availability, such as Southern Africa, the use of satellite remote sensing data promises an excellent opportunity for achieving this predictive goal. In this article, we assess the effectiveness of Soil Moisture Active Passive (SMAP) and Cyclone Global Navigation Satellite System (CYGNSS) soil moisture data in predicting drought conditions using multiple linear regression-predicted data and Global Land Data Assimilation System (GLDAS) soil moisture data.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00010;jsessionid=3n361b37dtmk2.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Debris Flow Susceptibility Evaluation Based on Multi-level Feature Extraction CNN Model: A Case Study of Nujiang Prefecture, China
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 313-323(11)</div>
    <div>Authors: Wang, Xu; Wang, Baoyun; Yuan, Ruohao; Luo, Yumeng; Liu, Cunxi</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Debris flow susceptibility evaluation plays a crucial role in the prevention and control of debris flow disasters. Therefore, this article proposes a convolutional neural network model named multi-level feature extraction network (MFENet). First, a dual-channel CNN architecture incorporating the Embedding Channel Attention mechanism is used to extract shallow features from both digital elevation model images and multispectral images. Subsequently, channel shuffle and feature concatenation are applied to the features from the two channels to obtain fused feature sets. Following this, a deep feature extraction is performed on the fused feature sets using a residual module improved by maximum pooling. Finally, the susceptibility index of gullies to debris flows is calculated based on the similarity scores.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00008;jsessionid=11kwpkbxmfvw6.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Using Improved YOLOv5 and SegFormer to Extract Tailings Ponds from Multi-Source Data
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 223-231(9)</div>
    <div>Authors: Sun, Zhenhui; Xu, Ying; Wang, Dongchuan; Meng, Qingyan; Sun, Yunxiao</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This paper proposes a framework that combines the improved "You Only Look Once" version 5 (YOLOv5) and SegFormer to extract tailings ponds from multi-source data. Points of interest (POIs) are crawled to capture potential tailings pond regions. Jeffries–Matusita distance is used to evaluate the optimal band combination. The improved YOLOv5 replaces the backbone with the PoolFormer to form a PoolFormer backbone. The neck introduces the CARAFE operator to form a CARAFE feature pyramid network neck (CRF-FPN). The head is substituted with an efficiency decoupled head. POIs and classification data optimize improved YOLOv5 results. After that, the SegFormer is used to delineate the boundaries of tailings ponds. Experimental results demonstrate that the mean average precision of the improved YOLOv5s has increased by 2.78% compared to the YOLOv5s, achieving 91.18%. The SegFormer achieves an intersection over union of 88.76% and an accuracy of 94.28%.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00009;jsessionid=11kwpkbxmfvw6.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            GDP Spatialization in City of Zhengzhou Based on NPP/VIIRS Night-time Light and Socioeconomic Statistical Data Using Machine Learning
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 233-240(8)</div>
    <div>Authors: Ullah, Inam; Li, Weidong; Meng, Fanqian; Nadeem, Muhammad Imran; Ahmed, Kanwal</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This article introduces a comprehensive methodology for mapping and assessing the urban built-up areas and establishing a spatial gross domestic product (GDP) model for Zhengzhou using night-time light (NTL) data, alongside socioeconomic statistical data from 2012 to 2017. Two supervised sorting algorithms, namely the support vector machine (SVM) algorithm and the deep learning (DL) algorithm, which includes the U-Net and fully convolutional neural (FCN) network models, are proposed for urban built-up area identification and image classification. Comparisons with Municipal Bureau of Statistics data highlight the U-Net neural network model exhibits superior accuracy, especially in areas with diverse characteristics. For each year from 2012 to 2017, a spatial GDP model was developed based on Zhengzhou's urban GDP and U-Net sorted images. This research provides valuable insights into urban development and economic assessment for the city.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00010;jsessionid=11kwpkbxmfvw6.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring Based on InSAR for the Xinmo Village Landslide in Western Sichuan, China
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 243-249(7)</div>
    <div>Authors: Zheng, Zezhong; Yu, Shuang; Xie, Chuhang; Yang, Jiali; Zhu, Mingcang; He, Yong</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            A devastating landslide incident occurred on 24 June 2017, causing huge losses for Xinmo Village in western Sichuan. In this paper, we used two interferometric synthetic aperture radar (InSAR) methods, permanent scatterer (PS)-InSAR and small baseline subset (SBAS)- InSAR, to analyze deformation signals in the area in the 2 years leading up to the landslide event using Sentinel-1A ascending data. Our experimental findings from PS-InSAR and SBAS-InSAR revealed that the deformation rates in the study region ranged between –50 to 20 mm/year and –30 to 10 mm/year, respectively. Furthermore, the deformation rates of the same points, as determined by these methods, exhibited a significant increase prior to the event. We also investigated the causal relationship between rainfall and landslide events, demonstrating that deformation rates correlate with changes in rainfall, albeit with a time lag. Therefore, using time-series InSAR for landslide monitoring in Xinmo Village is a viable approach.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00006;jsessionid=3bhf6q783oo37.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Scan Angle Analysis of Airborne Lidar Data for Missing Return Approximation in Urban Areas
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 143-154(12)</div>
    <div>Authors: Gharibi, Hamid; Habib, Ayman</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The density and uniformity of lidar data play crucial roles in the cor-responding data processing steps. One factor influencing point density and spacing in lidar data is the presence of empty pulses, where no return is detected. Missing returns can occur due to atmospheric absorption, specular and diffusive reflection, etc. To address this issue and enhance point density, this paper introduces a novel method for approximating missing returns in airborne lidar data collected over urban areas. This technique focuses on approximating returns for empty pulses that hit spots near abrupt slope changes on building and ground surfaces. The proposed methodology is validated through experiments using a lidar data set from downtown Dublin, Ireland. The collected data contained numerous gaps associated with wet surfaces, as well as missing returns on vertical and oblique surfaces.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00008;jsessionid=3bhf6q783oo37.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Keyframe Extraction Approach for 3D Videogrammetry Based on Baseline Constraints
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 171-180(10)</div>
    <div>Authors: Liu, Xinyi; Hu, Qingwu; Huang, Xianfeng</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In this paper, we propose a novel approach for the extraction of high-quality frames to enhance the fidelity of videogrammetry by combining fuzzy frames removal and baseline constraints. We first implement a gradient-based mutual information method to filter out low-quality frames while preserving the integrity of the videos. After frame pose estimation, the geometric properties of the baseline are constrained by three aspects to extract the keyframes: quality of relative orientation, baseline direction, and base to distance ratio. The three-dimensional model is then reconstructed based on these extracted keyframes. Experimental results demonstrate that our approach maintains a strong robustness throughout the aerial triangulation, leading to high levels of reconstruction precision across diverse video scenarios. Compared to other methods, this paper improves the reconstruction accuracy by more than 0.2 mm while simultaneously maintaining the completeness.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00009;jsessionid=3bhf6q783oo37.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Extraction of Terraces in Hilly Areas from Remote Sensing Images Using DEM and Improved U-Net
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 181-188(8)</div>
    <div>Authors: Peng, Fengcan; Peng, Qiuzhi; Chen, Di; Lu, Jiating; Song, Yufei</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            To extract terraced fields in hilly areas on a large scale in an automated and high-precision manner, this paper proposes a terrace extraction method that combines the Digital Elevation Model (DEM), Sentinel-2 imagery, and the improved U-Net semantic segmentation model. The U-Net model is modified by introducing Attention Gate modules into its decoding modules to suppress the interference of redundant features and adding Dropout and Batch Normalization layers to improve training speed, robustness, and fitting ability. In addition, the DEM band is combined with the red, green, and blue bands of the remote sensing images to make full use of terrain information. The experimental results show that the Precision, Recall, F1 score, and Mean Intersection over Union of the proposed method for terrace extraction are improved to other mainstream advanced methods, and the internal information of the terraces extracted is more complete, with fewer false positive and false negative results.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00008;jsessionid=18dj5u3l1hy3.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Remote Sensing Application in Water Quality of Lake Burdur, Türkiye
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 85-87(3)</div>
    <div>Authors: Kokal, Aylin Tuzcu; Kacikoc, Meltem; Musaoglu, Nebiye; Tanik, Aysegul</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The advancements in space technology have facilitated water quality (WQ) monitoring of lake conditions at a spatial resolution of 10 m by freely accessible Sentinel-2 images. The main aim of this article was to elucidate the necessity of spatiotemporal WQ monitoring of the shrinking Lake Burdur in Türkiye by examining the relation between field and satellite data with a state-of-the-art machine learning- based regression algorithm. This study focuses on detection of algal blooms and WQ parameters, which are chlorophyll-a (Chl-a) and suspended solids (SS). Furthermore, this study leverages the advantage of geographic position of Lake Burdur, located at the overlap of two Sentinel-2 frames, which enables the acquisition of satellite images at a temporal resolution of 2–3 days. The findings enrich the understanding of the lake's dynamic structure by rapidly monitoring the occurrence of algal blooms. High accuracies were achieved for Chl-a (R-squared: 0.93) and SS (R-squared: 0.94) detection.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00011;jsessionid=18dj5u3l1hy3.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Few-Shot Semi-Supervised Learning Method for Remote Sensing Image Scene Classification
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 121-125(5)</div>
    <div>Authors: Zhu, Yuxuan; Li, Erzhu; Su, Zhigang; Liu, Wei; Samat, Alim; Liu, Yu</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Few-shot scene classification methods aim to obtain classification discriminative ability from few labeled samples and has recently seen substantial advancements. However, the current few-shot learning approaches still suffer from overfitting due to the scarcity of labeled samples. To this end, a few-shot semi-supervised method is proposed to address this issue. Specifically, semi-supervised learning method is used to increase target domain samples; then we train multiple classification models using the augmented samples. Finally, we perform decision fusion of the results obtained from the multiple models to accomplish the image classification task. According to the experiments conducted on two real few-shot remote sensing scene datasets, our proposed method achieves significantly higher accuracy (approximately 1.70% to 4.33%) compared to existing counterparts.
        </details>
    </div>
</article>
