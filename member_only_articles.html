<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00010;jsessionid=e8dp8ak5h9nsc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Morphology-Based Feature Extraction Network for Arbitrary-Oriented SAR Vehicle Detection
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 665-673(9)</div>
    <div>Authors: Chen, Ting; Huang, Xiaohong</div>
    <div>Abstract: In recent years, synthetic aperture radar (SAR) vehicle detection has become a research hotspot. However, algorithms using horizontal bounding boxes can lead to redundant detection areas due to the varying aspect ratio and arbitrary orientation of vehicle targets. This paper proposes a morphology-based feature extraction network (MFE-Net), which fully uses the prior shape knowledge of the vehicle targets. Specifically, we adopt rotatable bounding boxes to predict the targets, and a novel rectangular rotation-invariant coordinate convolution (RRICC) is proposed to extract the feature, which can determine more accurately the convolutional sampling location of the vehicles. The adaptive thresholding denoising module (ATDM) is designed to suppress background clutter. Furthermore, inspired by the convolutional neural networks (CNNs) and self-attention, we propose the hybrid representation enhancement module (HREM) to highlight the vehicle target features. The experiment results show that the proposed model obtains an average precision (AP) of 93.1% on the SAR vehicle detection data set (SVDD).</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00011;jsessionid=e8dp8ak5h9nsc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Spatial-Spectral Middle Cross-Attention Fusion Network for Hyperspectral Image Superresolution
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 675-686(12)</div>
    <div>Authors: Lang, Xiujuan; Lu, Tao; Zhang, Yanduo; Jiang, Junjun; Xiong, Zixiang</div>
    <div>Abstract: The spatial and spectral features of hyperspectral images exhibit complementarity, and neglecting them prevents the full exploitation of useful information for superresolution. This article proposes a spatial-spectral middle cross-attention fusion network to explore the spatial-spectral structure correlation. Initially, we learn spatial and spectral features through spatial and spectral branches instead of single ones to reduce information compression. Then, a novel middle-cross attention fusion block that includes middle features fusion strategy and cross-attention is proposed to fuse spatial-spectral features to enhance their mutual effects, which aims to explore the spatial-spectral structural correlations. Finally, we propose a spectral feature compensation mechanism to provide complementary information for adjacent band groups. The experimental results show that the proposed method outperforms state-of-the-art algorithms in object values and visual quality.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00014;jsessionid=e8dp8ak5h9nsc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Variable-Iterative Fully Convolutional Neural Network for Sparse Unmixing
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 699-706(8)</div>
    <div>Authors: Kong, Fanqiang; Lv, Zhijie; Wang, Kun; Fang, Xu; Zheng, Yuhan; Yu, Shengjie</div>
    <div>Abstract: Neural networks have greatly promoted the development of hyperspectral unmixing (HU). Most data-driven deep networks extract features of hyperspectral images (HSIs) by stacking convolutional layers to achieve endmember extraction and abundance estimation. Some model-driven networks have strong interpretability but fail to mine the deep feature. We propose a variable-iterative fully convolutional neural network (VIFCNN) for sparse unmixing, combining the characteristics of these two networks. Under the model-driven iterative framework guided by sparse unmixing by variable splitting and augmented lagrangian (SUnSAL), a data-driven spatial-spectral feature learning module and a spatial information updating module are introduced to enhance the learning of data information. Experimental results on synthetic and real datasets show that VIFCNN significantly outperforms several traditional unmixing methods and two deep learning???based methods. On real datasets, our method improves signal-to-reconstruction error by 17.38%, reduces abundance root-mean-square error by 25.24%, and reduces abundance spectral angle distance by 31.40% compared with U-ADMM-ßUNet.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00008;jsessionid=2n7imstjl8t36.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Attention Heat Map-Based Black-Box Local Adversarial Attack for Synthetic Aperture Radar Target Recognition
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 601-609(9)</div>
    <div>Authors: Wan, Xuanshen; Liu, Wei; Niu, Chaoyang; Lu, Wanjie</div>
    <div>Abstract: Synthetic aperture radar (SAR) automatic target recognition (ATR) models based on deep neural networks (DNNs) are susceptible to adversarial attacks. In this study, we proposed an SAR black-box local adversarial attack algorithm named attention heat map- based black-box local adversarial attack (AH-BLAA). First, we designed an attention heat map extraction module combined with the layer-wise relevance propagation (LRP) algorithm to obtain the high concerning areas of the SAR-ATR models. Then, to gener- ate SAR adversarial attack examples, we designed a perturbation generator module, introducing the structural dissimilarity (DSSIM) metric in the loss function to limit image distortion and the dif- ferential evolution (DE) algorithm to search for optimal perturba- tions. Experimental results on the MSTAR and FUSAR-Ship datasets showed that compared with existing adversarial attack algorithms, the attack success rate of the AH-BLAA algorithm increased by 0.63% to 33.59% and 1.05% to 17.65%, respectively. Moreover, the low- est perturbation ratios reached 0.23% and 0.13%, respectively.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00010;jsessionid=2n7imstjl8t36.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Exploring the Potential of the Hyperspectral Remote Sensing Data China OrbitaZhuhai-1in Land Cover Classification
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 611-619(9)</div>
    <div>Authors: Li, Caixia; Xiong, Xiaoyan; Wang, Lin; Li, Yunfan; Wang, Jiaqi; Zhang, Xiaoli</div>
    <div>Abstract: Responding to the shortcomings of China's civil remote sensing data in land cover classification, such as the difficulty of data acquisition and the low utilization rate, we used Landsat-8, China Orbita Zhuhai-1 hyperspectral remote sensing (OHS) data, and Landsat-8 + OHS data combined with band (red, green, and blue) and vegetation index features to classify land cover using maximum likelihood (ML), Mahalanobis distance (MD), and support vector machine (SVM). The results show that Landsat-8 + OHS data have the highest classification accuracy in SVM, with an overall accuracy of 83.52% and a kappa coefficient of 0.71, and this result is higher than that of Landsat-8 images and OHS images separately. In addition, the classification accuracy of OHS images was higher than that of Landsat-8 images. The results of the study provide a reference for the use of civil satellite remote sensing data in China.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00012;jsessionid=2n7imstjl8t36.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Teacher-Student Prototype Enhancement Network for a Few-Shot Remote Sensing Scene Classification
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 621-630(10)</div>
    <div>Authors: Zhu, Ye; Yang, Shanying; Yu, Yang</div>
    <div>Abstract: Few-shot remote sensing scene classification identifies new classes from limited labeled samples where the great challenges are intraclass diversity, interclass similarity, and limited supervision. To alleviate these problems, a teacher-student prototype enhancement network is proposed for a few-shot remote sensing scene classification. Instead of introducing an attentional mechanism in mainstream studies, a prototype enhancement module is recommended to adaptively select high-confidence query samples, which can enhance the support prototype representations to emphasize intraclass and interclass relationships. The construction of a few-shot teacher model generates more discriminative predictive representations with inputs from many labeled samples, thus providing a strong supervisory signal to the student model and encouraging the network to achieve accurate classification with a limited number of labeled samples. Extensive experiments of four public datasets, including NWPU-remote sens ing image scene classification (NWPU-RESISC45), aerial image dataset (AID), UC Merced, and WHU-RS19, demonstrate that this method achieves superior competitive performance than the state-of-the-art methods on five-way, one-shot, and five-shot classifications.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00007;jsessionid=3wawo99a1uv3d.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Development of an Automatic Feature Point Classification Method for Three-Dimensional Mapping Around Slewing and Derricking Cranes
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 538-552(15)</div>
    <div>Authors: Shigemori, Hisakazu; Susaki, Junichi; Yoneda, Mizuki; Ososinski, Marek</div>
    <div>Abstract: Crane automation requires a three-dimensional (3D) map around cranes that should be reconstructed and updated quickly.In this study, a high-precision classification method was developed to distinguish stationary objects from moving objects in moving images captured by a monocular camera to stabilize 3D reconstruction. To develop the method, a moving image was captured while the crane was slewed with a monocular camera mounted vertically downward at the tip of the crane. The boom length and angle data were output from a control device, a controller area network. For efficient development, a simulator that imitated the environment of an actual machine was developed and used. The proposed method uses optical flow to track feature points. The classification was performed successfully, independent of derricking motion. Consequently, the proposed method contributes to stable 3D mapping around cranes in construction sites.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00009;jsessionid=3wawo99a1uv3d.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Semantic Segmentation of Point Cloud Scene via Multi-Scale Feature Aggregation and Adaptive Fusion
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 553-563(11)</div>
    <div>Authors: Guo, Baoyun; Sun, Xiaokai; Li, Cailin; Sun, Na; Wang, Yue; Yao, Yukai</div>
    <div>Abstract: Point cloud semantic segmentation is a key step in 3D scene understanding and analysis. In recent years, deep learning–based point cloud semantic segmentation methods have received extensive attention from researchers. Multi-scale neighborhood feature learning methods are suitable for inhomogeneous density point clouds, but different scale branching feature learning increases the computational complexity and makes it difficult to accurately fuse different scale features to express local information. In this study, a point cloud semantic segmentation network based on RandLA-Net with multi-scale local feature aggregation and adaptive fusion is proposed. The designed structure can reduce computational complexity and accurately express local features. The mean intersection-over-union is improved by 1.1% on the SemanticKITTI data set with an inference speed of nine frames per second, while the mean intersection-over-union is improved by 0.9% on the S3DIS data set, compared with RandLA-Net. We also conduct ablation studies to validate the effectiveness of the proposed key structure.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00011;jsessionid=3wawo99a1uv3d.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Robust Star Identification Algorithm for Resident Space Object Surveillance
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 565-574(10)</div>
    <div>Authors: Wu, Liang; Hao, Pengyu; Zhang, Kaixuan; Zhang, Qian; Han, Ru; Cao, Dekun</div>
    <div>Abstract: Star identification algorithms can be applied to resident space object (RSO) surveillance, which includes a large number of stars and false stars. This paper proposes an efficient, robust star identification algorithm for RSO surveillance based on a neural network. First, a feature called equal-frequency binning radial feature (EFB-RF) is proposed for guide stars, and a superficial neural network is constructed for feature classification. Then the training set is generated based on EFB-RF. Finally, the remaining stars are identified using a residual star matching method. The simulation experiment and results show that the identification rate of our algorithm can reach 99.82% under 1 pixel position noise, and it can reach 99.54% under 5% false stars. When the percentage of missing stars is 15%, it can reach 99.40%. The algorithm is verified by RSO surveillance.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000009/art00013;jsessionid=3wawo99a1uv3d.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Wavelets for Self-Calibration of Aerial Metric Camera Systems
        </a>
    </h3>
    <div style="font-style: italic;">September 2024, pp. 575-587(13)</div>
    <div>Authors: Ye, Jun-Fu; Tsay, Jaan-Rong; Fritsch, Dieter</div>
    <div>Abstract: In this paper, wavelets are applied to develop new models for the self-calibration of aerial metric camera systems. It is well known and mathematically proven that additional parameters (APs) can compensate image distortions and remaining error sources by a rigorous photogrammetric bundle-block adjustment. Thus, kernel functions based on orthogonal wavelets (e. g., asymmetric Daubechies wave- lets, least asymmetric Daubechies wavelets, Battle-Lemarié wavelets, Meyer wavelets) are used to build the wavelets-based family of APs for self-calibrating digital frame cameras. These new APs are called wavelet APs. Its applications in rigorous tests are accomplished by using aerial images taken by an airborne digital mapping camera in situ and practical calibrations. The test results demonstrate that these orthogonal wavelet APs are applicable and largely avoid the risk of over-parameterization. Their external accuracy is evaluated using reliable and high precision check points in the calibration field.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00007;jsessionid=1upau122n1so2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Research Progress of Optical Satellite Remote Sensing Monitoring Asphalt Pavement Aging
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 471-482(12)</div>
    <div>Authors: Wang, Jingwen; Yang, Dayong; Xie, Zhiwei; Wang, Han; Hao, Zhigang; Zhou, Fanyu; Wang, Xiaona</div>
    <div>Abstract: The aging condition of asphalt pavement is an invaluable basis for traffic infrastructure evaluation. Due to the amount of time and high cost of monitoring and identifying asphalt pavement aging, many current studies focus on satellite remote sensing methods. In this paper, some methods and technologies for monitoring asphalt pavement degradation by optical satellite remote sensing are introduced as a literature review. Many researchers have developed spectrum libraries based on the actual aging of asphalt pavements, and it is possible to construct pavement health indices based on spectrum changes. Some indexes can extract different aging degrees of asphalt pavement from optical satellite images. Of course, current research can only preliminarily reflect the aging phenomenon of asphalt pavement and cannot accurately describe the distress characteristics of asphalt pavement. Future research needs to further strengthen mechanism research, develop higher resolution images, improve image processing technology, and adopt multi-means fusion analysis methods.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00008;jsessionid=1upau122n1so2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Mapping Winter Wheat Using Ensemble‐Based Positive Unlabeled Learning Approach
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 483-491(9)</div>
    <div>Authors: Wang, Hanxiang; Yu, Fan; Xie, Junwei; Wan, Huawei; Zheng, Haotian</div>
    <div>Abstract: High‐resolution remote sensing images can support machine learning methods to achieve remarkable results in agricultural monitoring. However, traditional supervised learning methods require pre-labeled training data and are unsuitable for non-fully labeled areas. Positive and Unlabeled Learning (PUL), can deal with unlabeled data. A loss function PU-Loss was proposed in this study to directly optimize the PUL evaluation metric and to address the data imbalance problem caused by unlabeled positive samples. Moreover, a hybrid normalization module Batch Instance-Layer Normalization was proposed to perform multiple normalization methods based on the resolution size and to improve the model performance further. A real‐world positive and unlabeled winter wheat data set was used to evaluate the proposed method, which outperformed widely used models such as U‐Net, DeepLabv3+, and DA‐Net. The results demonstrated the potential of PUL for winter wheat identification in remote sensing images.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00010;jsessionid=1upau122n1so2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Building Shadow Detection Based on Improved Quick Shift Algorithm in GF‐2 Images
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 493-502(10)</div>
    <div>Authors: Chen, Yunzhi; Wang, Chao; Wang, Wei; Zhang, Xiang; Chen, Nengcheng</div>
    <div>Abstract: Shadows in remote sensing images contain crucial information about various features on the ground. In this study, a method for detecting building shadows in GF‐2 images based on improved quick shift was proposed. First, six feature variables were constructed: first principal component (PC1), brightness component (I), normalized difference shadow index (NDSI), morphological shadow index (MSI), normalized difference water index (NDWI), and normalized difference vegetation index (NDVI). Then, the image was segmented to obtain homogeneous objects, which were then classified using a random forest model. Two improvements were added to the quick shift algorithm: using PC1, I, and MSI as input data instead of RGB images; and adding Canny edge constraints. Validation in six research areas yields Kappa coefficients of 0.928, 0.896, 0.89, 0.913, 0.879, and 0.909, confirming method feasibility. In addition, comparative experiments demonstrate its effectiveness and robustness across different land cover types while mitigating the segmentation scale effect.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00011;jsessionid=1upau122n1so2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Hyperspectral Reflectance Assessment for Preliminary Identification of Degraded Soil Zones in Industrial Sites, India
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 503-509(7)</div>
    <div>Authors: Dutta, Amitava; Tyagi, Rashi; Sharma, Shilpi; Datta, Manoj</div>
    <div>Abstract: The study explores the potential of next-generation satellite hyperspectral imaging systems for screening and predicting surface‐soil contamination and degradation by exploiting various spectral indices and signature‐matching techniques at a heavily industrialized area in India. The soil moisture content, desertification and salinity status, clay or fine material content, heavy metal content, vegetation health status, and stress levels were assessed from continuum-removed spectral reflectance values. Results indicated the presence of water in two tailings ponds, high salinity, and desertification values in most of the tailings ponds and dump sites, clay boundary liner along four ponds, high heavy metal indices along three ponds and all dump sites, highly stressed vegetation near all tailings ponds and coal dump sites, and pollutants in nearby water channels. The results suggest a strategy for the initial identification of priority areas for ground-based investigations and an alternative rapid methodology to monitor large industrial hubs in India.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00007;jsessionid=vgdy1hclx1ul.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            ReLAP-Net: Residual Learning and Attention Based Parallel Network for Hyperspectral and Multispectral Image Fusion
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 395-403(9)</div>
    <div>Authors: Agrawal, Aditya; SourajaKundu; Ahmad, Touseef; Bhatt, Manish</div>
    <div>Abstract: Remote sensing applications require high-resolution images to obtain precise information about the Earth???s surface. Multispectral images have high spatial resolution but low spectral resolution. Hyperspectral images have high spectral resolution but low spatial resolution. This study proposes a residual learning and attention-based parallel network based on residual network and channel attention. The network performs image fusion of a high spatial resolution multispectral image and a low spatial resolution hyperspectral image. The network training and fusion experiments are conducted on four public benchmark data sets to show the effectiveness of the proposed model. The fusion performance is compared with classical signal processing???based image fusion techniques. Four image metrics are used for the quantitative evaluation of the fused images. The proposed network improved fusion ability by reducing the root mean square error and relative dimensionless global error in synthesis and increased the peak signal-to-noise ratio when compared to other state-of-the-art models.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00011;jsessionid=vgdy1hclx1ul.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Dynamic Monitoring of Ecological Quality in Eastern Ukraine Amidst the Russia‐Ukraine Conflict
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 427-435(9)</div>
    <div>Authors: Zhang, Chaofei; Xu, Zhanghua; Yang, Yuanyao; Sun, Lei; Li, Haitao</div>
    <div>Abstract: To evaluate the spatiotemporal changes in the ecological environment of eastern Ukraine since the Russia-Ukraine conflict, this study used MODIS images from March to September 2020 and 2022 to calculate the Remote Sensing???Based Ecological Index. In 2022, compared with 2020, conflict zones exhibited reduced improvement and increased slight degradation, whereas nonconflict areas showed marginal enhancement. Through propensity score matching, the research confirmed the causal relationship between conflict and ecological trends. Pathway analysis revealed that the conflict contributed to 0.016 units increase in ecological quality while reducing the improvement rate by 0.042 units. This study provides empirical support for understanding the correlation between conflicts and specific environmental factors, offering technical references for ecological quality assessments in other conflict areas and future evaluations by the Ukrainian government.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00013;jsessionid=vgdy1hclx1ul.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            A Surface Water Extraction Method Integrating Spectral and Temporal Characteristics
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 437-450(14)</div>
    <div>Authors: Zou, Yebin</div>
    <div>Abstract: Remote sensing has been applied to observe large areas of surface water to obtain higher-resolution and long-term continuous observation records of surface water. However, limitations remain in the detection of large-scale and multi-temporal surface water mainly due to the high variability in water surface signatures in space and time. In this study, we developed a surface water remote sensing information extraction model that integrates spectral and temporal characteristics to extract surface water from multi-dimensional data of long-term Landsat scenes to explore the spatiotemporal changes in surface water over decades. The goal is to extract open water in vegetation, clouds, terrain shadows, and other land cover backgrounds from medium-resolution remote sensing images. The average overall accuracy and average kappa coefficient of the classification were verified to be 0.91 and 0.81, respectively. Experiments applied to China’s inland arid area have shown that the method is effective under complex surface environmental conditions.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00006;jsessionid=4snrbdtstgq8i.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Real-Time Semantic Segmentation of Remote Sensing Images for Land Management
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 335-343(9)</div>
    <div>Authors: Zhang, Yinsheng; Ji, Ru; Hu, Yuxiang; Yang, Yulong; Chen, Xin; Duan, Xiuxian; Shan, Huilin</div>
    <div>Abstract: Remote sensing image segmentation is a crucial technique in the field of land management. However, existing semantic segmentation networks require a large number of floating-point operations (FLOPs) and have long run times. In this paper, we propose a dual-path feature aggregation network (DPFANet) specifically designed for the low-latency operations required in land management applications. Firstly, we use four sets of spatially separable convolutions with varying dilation rates to extract spatial features. Additionally, we use an improved version of MobileNetV2 to extract semantic features. Furthermore, we use an asymmetric multi-scale fusion module and dual-path feature aggregation module to enhance feature extraction and fusion. Finally, a decoder is constructed to enable progressive up-sampling. Experimental results on the Potsdam data set and the Gaofen image data set (GID) demonstrate that DPFANet achieves overall accuracy of 92.2% and 89.3%, respectively. The FLOPs are 6.72 giga and the number of parameters is 2.067 million.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00007;jsessionid=4snrbdtstgq8i.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Land Use Change in the Yangtze River Economic Belt during 2010 to 2020 and Future Comprehensive Prediction Based on Markov and ARIMA Models
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 345-354(10)</div>
    <div>Authors: Zheng, Haotian; Yu, Fan; Wan, Huawei; Shi, Peirong; Wang, Haonan</div>
    <div>Abstract: The key data for accurate prediction is of great significance to accurately carry out the next step of sustainable land use development plan according to the demand of China. Consequently, the main purposes of our study are: (1) to delineate the characteristics of land use transitions within the Yangtze River Economic Belt; (2) to use the Markov model and the autoregressive integrated moving average (ARIMA) model for comparative analysis and prediction of land use distribution. This study analyzes land use/cover change (LUCC) data from 2010 and 2020 using the land use transition matrix, dynamic degree, and comprehensive index model and predicts 2025 land use by the Markov model. The study identifies a reduction in land usage over 11 years, particularly in grassland. The Markov and ARIMA models' significance is 0.002 (P < 0.01), showing arable land and woodland dominance, with varying changes in other land types.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00009;jsessionid=4snrbdtstgq8i.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            An Improved YOLO Network for Insulator and Insulator Defect Detection in UAV Images
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 355-361(7)</div>
    <div>Authors: Zhou, Fangrong; Liu, Lifeng; Hu, Hao; Jin, Weishi; Zheng, Zezhong; Li, Zhongnian; Ma, Yi; Wang, Qun</div>
    <div>Abstract: The power grid plays a vital role in the construction of livelihood projects by transmitting electrical energy. In the event of insulator explosions on power grid towers, these insulators may detach, presenting potential safety risks to transmission lines. The identification of such failures relies on the examination of images captured by unmanned aerial vehicles (UAVs). However, accurately detecting insulator defects remains challenging, particularly when dealing with variations in size. Existing methods exhibit limited accuracy in detecting small objects. In this paper, we propose a novel detection method that incorporates the convolutional block attention module (CBAM) as an attention mechanism into the backbone of the "you only look once" version 5 (YOLOv5) model. Additionally, we integrate a residual structure into the model to learn additional information and features related to insulators, thereby enhancing detection efficiency. Experimental results demonstrate that our proposed method achieved F1 scores of 0.87 for insulator detection and 0.89 for insulator defect detection. The improved YOLOv5 network shows promise in detecting insulators and their defects in UAV images.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00007;jsessionid=1b3ce8siah6k2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Pixel Texture Index Algorithm and Its Application
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 277-292(16)</div>
    <div>Authors: Sun, Xiaodan; Sun, Xiaofang</div>
    <div>Abstract: Image segmentation is essential for object-oriented analysis, and classification is a critical parameter influencing analysis accuracy. However, image classification and segmentation based on spectral features are easily perturbed by the high-frequency information of a high spatial resolution remotely sensed (HSRRS) image, degrading its classification and segmentation quality. This article first presents a pixel texture index (PTI) by describing the texture and edge in a local area surrounding a pixel. Indeed.. The experimental results highlight that the HSRRS image classification and segmentation quality can be effectively improved by combining it with the PTI image. Indeed, the overall accuracy improved from 7% to 14%, and the kappa can be increased from 11% to 24%, respectively.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00008;jsessionid=1b3ce8siah6k2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Parcel-Level Crop Classification in Plain Fragmented Regions Based on Multi-Source Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 293-302(10)</div>
    <div>Authors: Zhang, Qiao; Luo, Ziyi; Shen, Yang; Wang, Zhoufeng</div>
    <div>Abstract: Accurately obtaining crop cultivation extent and estimating the cultivated area are significant for adjusting regional planting structure. This article proposes a parcel-level crop classification method using time-series, medium-resolution, remote sensing images and single-phase, high-spatial-resolution, remote sensing images. The deep learning semantic segmentation network feature pyramid network with squeeze-and-excitation network (FPN???SENet) and multi-scale segmentation were used to extract cultivated land parcels from Gaofen-2 imagery, while the pixel-level crop types were classified by using support vector machine algorithms from time-series Sentinel-2 images. Then, the parcel-level crop classification was obtained from the pixel-level crop types and land parcels.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00009;jsessionid=1b3ce8siah6k2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Evaluation of SMAP and CYGNSS Soil Moistures in Drought Prediction Using Multiple Linear Regression and GLDAS Product
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 303-312(10)</div>
    <div>Authors: Edokossi, Komi; Jin, Shuanggen; Calabia, Andres; Molina, Iñigo; Mazhar, Usman</div>
    <div>Abstract: Drought is a devastating natural hazard and exerts profound effects on both the environment and society. Predicting drought occurrences is significant in aiding decision-making and implementing effective mitigation strategies. In regions characterized by limited data availability, such as Southern Africa, the use of satellite remote sensing data promises an excellent opportunity for achieving this predictive goal. In this article, we assess the effectiveness of Soil Moisture Active Passive (SMAP) and Cyclone Global Navigation Satellite System (CYGNSS) soil moisture data in predicting drought conditions using multiple linear regression???predicted data and Global Land Data Assimilation System (GLDAS) soil moisture data.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00010;jsessionid=1b3ce8siah6k2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Debris Flow Susceptibility Evaluation Based on Multi-level Feature Extraction CNN Model: A Case Study of Nujiang Prefecture, China
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 313-323(11)</div>
    <div>Authors: Wang, Xu; Wang, Baoyun; Yuan, Ruohao; Luo, Yumeng; Liu, Cunxi</div>
    <div>Abstract: Debris flow susceptibility evaluation plays a crucial role in the prevention and control of debris flow disasters. Therefore, this article proposes a convolutional neural network model named multi-level feature extraction network (MFENet). First, a dual-channel CNN architecture incorporating the Embedding Channel Attention mechanism is used to extract shallow features from both digital elevation model images and multispectral images. Subsequently, channel shuffle and feature concatenation are applied to the features from the two channels to obtain fused feature sets. Following this, a deep feature extraction is performed on the fused feature sets using a residual module improved by maximum pooling. Finally, the susceptibility index of gullies to debris flows is calculated based on the similarity scores.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00008;jsessionid=1l6gk7d113m1c.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Using Improved YOLOv5 and SegFormer to Extract Tailings Ponds from Multi-Source Data
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 223-231(9)</div>
    <div>Authors: Sun, Zhenhui; Xu, Ying; Wang, Dongchuan; Meng, Qingyan; Sun, Yunxiao</div>
    <div>Abstract: This paper proposes a framework that combines the improved "You Only Look Once" version 5 (YOLOv5) and SegFormer to extract tailings ponds from multi-source data. Points of interest (POIs) are crawled to capture potential tailings pond regions. Jeffries–Matusita distance is used to evaluate the optimal band combination. The improved YOLOv5 replaces the backbone with the PoolFormer to form a PoolFormer backbone. The neck introduces the CARAFE operator to form a CARAFE feature pyramid network neck (CRF-FPN). The head is substituted with an efficiency decoupled head. POIs and classification data optimize improved YOLOv5 results. After that, the SegFormer is used to delineate the boundaries of tailings ponds. Experimental results demonstrate that the mean average precision of the improved YOLOv5s has increased by 2.78% compared to the YOLOv5s, achieving 91.18%. The SegFormer achieves an intersection over union of 88.76% and an accuracy of 94.28%.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00009;jsessionid=1l6gk7d113m1c.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            GDP Spatialization in City of Zhengzhou Based on NPP/VIIRS Night-time Light and Socioeconomic Statistical Data Using Machine Learning
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 233-240(8)</div>
    <div>Authors: Ullah, Inam; Li, Weidong; Meng, Fanqian; Nadeem, Muhammad Imran; Ahmed, Kanwal</div>
    <div>Abstract: This article introduces a comprehensive methodology for mapping and assessing the urban built-up areas and establishing a spatial gross domestic product (GDP) model for Zhengzhou using night-time light (NTL) data, alongside socioeconomic statistical data from 2012 to 2017. Two supervised sorting algorithms, namely the support vector machine (SVM) algorithm and the deep learning (DL) algorithm, which includes the U-Net and fully convolutional neural (FCN) network models, are proposed for urban built-up area identification and image classification. Comparisons with Municipal Bureau of Statistics data highlight the U-Net neural network model exhibits superior accuracy, especially in areas with diverse characteristics. For each year from 2012 to 2017, a spatial GDP model was developed based on Zhengzhou's urban GDP and U-Net sorted images. This research provides valuable insights into urban development and economic assessment for the city.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00010;jsessionid=1l6gk7d113m1c.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Monitoring Based on InSAR for the Xinmo Village Landslide in Western Sichuan, China
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 243-249(7)</div>
    <div>Authors: Zheng, Zezhong; Yu, Shuang; Xie, Chuhang; Yang, Jiali; Zhu, Mingcang; He, Yong</div>
    <div>Abstract: A devastating landslide incident occurred on 24 June 2017, causing huge losses for Xinmo Village in western Sichuan. In this paper, we used two interferometric synthetic aperture radar (InSAR) methods, permanent scatterer (PS)-InSAR and small baseline subset (SBAS)- InSAR, to analyze deformation signals in the area in the 2 years leading up to the landslide event using Sentinel-1A ascending data. Our experimental findings from PS-InSAR and SBAS-InSAR revealed that the deformation rates in the study region ranged between –50 to 20 mm/year and –30 to 10 mm/year, respectively. Furthermore, the deformation rates of the same points, as determined by these methods, exhibited a significant increase prior to the event. We also investigated the causal relationship between rainfall and landslide events, demonstrating that deformation rates correlate with changes in rainfall, albeit with a time lag. Therefore, using time-series InSAR for landslide monitoring in Xinmo Village is a viable approach.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00006;jsessionid=35mnh0cjldnun.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Scan Angle Analysis of Airborne Lidar Data for Missing Return Approximation in Urban Areas
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 143-154(12)</div>
    <div>Authors: Gharibi, Hamid; Habib, Ayman</div>
    <div>Abstract: The density and uniformity of lidar data play crucial roles in the cor-responding data processing steps. One factor influencing point density and spacing in lidar data is the presence of empty pulses, where no return is detected. Missing returns can occur due to atmospheric absorption, specular and diffusive reflection, etc. To address this issue and enhance point density, this paper introduces a novel method for approximating missing returns in airborne lidar data collected over urban areas. This technique focuses on approximating returns for empty pulses that hit spots near abrupt slope changes on building and ground surfaces. The proposed methodology is validated through experiments using a lidar data set from downtown Dublin, Ireland. The collected data contained numerous gaps associated with wet surfaces, as well as missing returns on vertical and oblique surfaces.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00008;jsessionid=35mnh0cjldnun.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Keyframe Extraction Approach for 3D Videogrammetry Based on Baseline Constraints
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 171-180(10)</div>
    <div>Authors: Liu, Xinyi; Hu, Qingwu; Huang, Xianfeng</div>
    <div>Abstract: In this paper, we propose a novel approach for the extraction of high-quality frames to enhance the fidelity of videogrammetry by combining fuzzy frames removal and baseline constraints. We first implement a gradient-based mutual information method to filter out low-quality frames while preserving the integrity of the videos. After frame pose estimation, the geometric properties of the baseline are constrained by three aspects to extract the keyframes: quality of relative orientation, baseline direction, and base to distance ratio. The three-dimensional model is then reconstructed based on these extracted keyframes. Experimental results demonstrate that our approach maintains a strong robustness throughout the aerial triangulation, leading to high levels of reconstruction precision across diverse video scenarios. Compared to other methods, this paper improves the reconstruction accuracy by more than 0.2 mm while simultaneously maintaining the completeness.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00009;jsessionid=35mnh0cjldnun.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Extraction of Terraces in Hilly Areas from Remote Sensing Images Using DEM and Improved U-Net
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 181-188(8)</div>
    <div>Authors: Peng, Fengcan; Peng, Qiuzhi; Chen, Di; Lu, Jiating; Song, Yufei</div>
    <div>Abstract: To extract terraced fields in hilly areas on a large scale in an automated and high-precision manner, this paper proposes a terrace extraction method that combines the Digital Elevation Model (DEM), Sentinel-2 imagery, and the improved U-Net semantic segmentation model. The U-Net model is modified by introducing Attention Gate modules into its decoding modules to suppress the interference of redundant features and adding Dropout and Batch Normalization layers to improve training speed, robustness, and fitting ability. In addition, the DEM band is combined with the red, green, and blue bands of the remote sensing images to make full use of terrain information. The experimental results show that the Precision, Recall, F1 score, and Mean Intersection over Union of the proposed method for terrace extraction are improved to other mainstream advanced methods, and the internal information of the terraces extracted is more complete, with fewer false positive and false negative results.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00008;jsessionid=1uh143vt2refc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Remote Sensing Application in Water Quality of Lake Burdur, Türkiye
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 85-87(3)</div>
    <div>Authors: Kokal, Aylin Tuzcu; Kacikoc, Meltem; Musaoglu, Nebiye; Tanik, Aysegul</div>
    <div>Abstract: The advancements in space technology have facilitated water quality (WQ) monitoring of lake conditions at a spatial resolution of 10 m by freely accessible Sentinel-2 images. The main aim of this article was to elucidate the necessity of spatiotemporal WQ monitoring of the shrinking Lake Burdur in Türkiye by examining the relation between field and satellite data with a state-of-the-art machine learning- based regression algorithm. This study focuses on detection of algal blooms and WQ parameters, which are chlorophyll-a (Chl-a) and suspended solids (SS). Furthermore, this study leverages the advantage of geographic position of Lake Burdur, located at the overlap of two Sentinel-2 frames, which enables the acquisition of satellite images at a temporal resolution of 2–3 days. The findings enrich the understanding of the lake's dynamic structure by rapidly monitoring the occurrence of algal blooms. High accuracies were achieved for Chl-a (R-squared: 0.93) and SS (R-squared: 0.94) detection.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00011;jsessionid=1uh143vt2refc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Few-Shot Semi-Supervised Learning Method for Remote Sensing Image Scene Classification
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 121-125(5)</div>
    <div>Authors: Zhu, Yuxuan; Li, Erzhu; Su, Zhigang; Liu, Wei; Samat, Alim; Liu, Yu</div>
    <div>Abstract: Few-shot scene classification methods aim to obtain classification discriminative ability from few labeled samples and has recently seen substantial advancements. However, the current few-shot learning approaches still suffer from overfitting due to the scarcity of labeled samples. To this end, a few-shot semi-supervised method is proposed to address this issue. Specifically, semi-supervised learning method is used to increase target domain samples; then we train multiple classification models using the augmented samples. Finally, we perform decision fusion of the results obtained from the multiple models to accomplish the image classification task. According to the experiments conducted on two real few-shot remote sensing scene datasets, our proposed method achieves significantly higher accuracy (approximately 1.70% to 4.33%) compared to existing counterparts.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00007;jsessionid=drbllrt21gkj.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Terrain Complexity and Maximal Poisson-Disk Sampling-Based Digital Elevation Model Simplification
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 13-20(8)</div>
    <div>Authors: Dong, Jingxian; Ming, Fan; Kabika, Twaha; Jiang, Jiayao; Zhang, Siyuan; Chervan, Aliaksandr; Natallia, Zhukouskaya; Hou, Wenguang</div>
    <div>Abstract: With the rapid development of lidar, the accuracy and density of the Digital Elevation Model (DEM) point clouds have been continuously improved. However, in some applications, dense point cloud has no practical meaning. How to effectively sample from the dense points and maximize the preservation of terrain features is extremely important. This paper will propose a DEM sampling algorithm that utilizes terrain complexity and maximal Poisson-disk sampling to extract key feature points for adaptive DEM sampling. The algorithm estimates terrain complexity based on local terrain variation and prioritizes points with high complexity for sampling. The sampling radius is inversely proportional to terrain complexity, while ensuring that points within the radius of accepted samples are not considered new samples. This way makes more points of concern in the rugged regions. The results show that the proposed algorithm has higher global accuracy than the classic six sampling methods.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00008;jsessionid=drbllrt21gkj.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            I2-FaçadeNet: An Illumination-invariant Façade Recognition Network Leveraging Sparsely Gated Mixture of Multi-color Space Experts for Aerial Oblique Imagery
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 21-31(11)</div>
    <div>Authors: Huang, Shengzhi; Hu, Han; Zhu, Qing</div>
    <div>Abstract: Façade image recognition under complex illumination conditions is crucial for various applications, including urban three-dimensional modeling and building identification. Existing methods relying solely on Red-Green-Blue (RGB) images are prone to texture ambiguity in complex illumination environments. Furthermore, façades display varying orientations and camera viewing angles, resulting in performance issues within the RGB color space. In this study, we introduce an illumination-invariant façade recognition network (I2-FaçadeNet) that leverages sparsely gated multi-color space experts for enhanced façade image recognition in challenging illumination environments. First, RGB façade images are converted into multi-color spaces to eliminate the ambiguous texture in complex illumination. Second, we train expert networks using separate channels of multi-color spaces. Finally, a sparsely gated mechanism is introduced to manage the expert networks, enabling dynamic activation of expert networks and the merging of results. Experimental evaluations leveraging both the International Society for Photogrammetry and Remote Sensing benchmark data sets and the Shenzhen data sets reveal that our proposed I2-FaçadeNet surpasses various depths of ResNet in façade recognition under complex illumination conditions. Specifically, the classification accuracy for poorly illuminated façades in Zurich improves by nearly 8%, while the accuracy for over-illuminated areas in Shenzhen increases by approximately 3%. Moreover, ablation studies conducted on façade images with complex illumination indicate that compared to traditional RGB-based ResNet, the proposed network achieves an accuracy improvement of 3% to 4% up to 100% for overexposed images and an accuracy improvement of 3% to 10% for underexposed images.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00009;jsessionid=drbllrt21gkj.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Development of Soil-Suppressed Impervious Surface Area Index for Automatic Urban Mapping
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 33-43(11)</div>
    <div>Authors: Javed, Akib; Shao, Zhenfeng; Ara, Iffat; Ahmad, Muhammad Nasar; Huq, Md.Enamul; Saleem, Nayyer; Karim, Fazlul</div>
    <div>Abstract: Expanding urban impervious surface area (ISA) mapping is crucial to sustainable development, urban planning, and environmental studies. Multispectral ISA mapping is challenging because of the mixed-pixel problems with bare soil. This study presents a novel approach using spectral and temporal information to develop a Soil-Suppressed Impervious Surface Area Index (SISAI) using the Landsat Operational Land Imager (OLI) data set, which reduces the soil but enhances the ISA signature. This study mapped the top 12 populated megacities using SISAI and achieved an over-all accuracy of 0.87 with an F1-score of 0.85. It also achieved a higher Spatial Dissimilarity Index between the ISA and bare soil. However, it is limited by bare gray soil and shadows of clouds and hills. SISAI encourages urban dynamics and inter-urban compari- son studies owing to its automatic and unsupervised methodology.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00010;jsessionid=drbllrt21gkj.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Dual-branch Branch Networks Based on Contrastive Learning for Long-Tailed Remote Sensing
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 45-53(9)</div>
    <div>Authors: Zhang, Lei; Peng, Lijia; Xia, Pengfei; Wei, Chuyuan; Yang, Chengwei; Zhang, Yanyan</div>
    <div>Abstract: Deep learning has been widely used in remote sensing image classification and achieves many excellent results. These methods are all based on relatively balanced data sets. However, in real-world scenarios, many data sets belong to the long-tailed distribution, resulting in poor performance. In view of the good performance of contrastive learning in long-tailed image classification, a new dual-branch fusion learning classification model is proposed to fuse the discriminative features of remote sensing images with spatial data, making full use of valuable image representation information in imbalance data. This paper also presents a hybrid loss, which solves the problem of poor discrimination of extracted features caused by large intra-class variation and inter-class ambiguity. Extended experiments on three long-tailed remote sensing image classification data sets demonstrate the advantages of the proposed dual-branch model based on contrastive learning in long-tailed image classification.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00011;jsessionid=drbllrt21gkj.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Comparison of 3D Point Cloud Completion Networks for High Altitude Lidar Scans of Buildings
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 55-64(10)</div>
    <div>Authors: Kulawiak, Marek</div>
    <div>Abstract: High altitude lidar scans allow for rapid acquisition of big spatial data representing entire city blocks. Unfortunately, the raw point clouds acquired by this method are largely incomplete due to object occlusions and restrictions in scanning angles and sensor resolution, which can negatively affect the obtained results. In recent years, many new solutions for 3D point cloud completion have been created and tested on various objects; however, the application of these methods to high-altitude lidar point clouds of buildings has not been properly investigated yet. In the above context, this paper presents the results of applying several state-of-the-art point cloud completion networks to various building exteriors acquired by simulated airborne laser scanning. Moreover, the output point clouds generated from partial data are compared with complete ground-truth point clouds. The performed tests show that the SeedFormer network trained on the ShapeNet-55 data set provides promising shape completion results.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00006;jsessionid=1fz8yak6po6w2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            IMU and Bluetooth Data Fusion to Achieve Submeter Position Accuracy in Indoor Positioning
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 735-740(6)</div>
    <div>Authors: Acar, Ugur</div>
    <div>Abstract: Indoor navigation applications have become widespread in recent years with the ability of mobile phones which determine the position. Due to the inefficiency of global positioning system (GPS) indoors, other positioning methods have been developed based on local networks using technologies such as Bluetooth, wireless networks, ultra-wideband signals, ultrasonic signals, and radio frequency identification modules. Various technologies yield high or medium accuracy. Combining data from multiple sources via fusion enhances location precision. In this study, indoor positions were estimated using trilateration with Bluetooth devices, and the accuracy was improved by applying filters to the data from inertial measurement unit (IMU) sensors on the phone. As a result of combining Bluetooth and IMU data with data fusion, submeter accuracy was achieved. The results obtained were tested at Yildiz Technical University-Istanbul Türkiye. It was determined that 92% of the data was obtained with submeter accuracy.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00007;jsessionid=1fz8yak6po6w2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Rice Identification Under Complex Surface Conditions with CNN and Integrated Remote Sensing Spectral-Temporal-Spatial Features
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 741-752(12)</div>
    <div>Authors: Liu, Tianjiao; Duan, Sibo; Chen, Jiankui; Zhang, Li; Li, Dong; Li, Xuqing</div>
    <div>Abstract: Accurate and effective rice identification has great significance for the sustainable development of agricultural management and food security. This paper proposes an accurate rice identification method that can solve the confused problem between fragmented rice fields and the surroundings in complex surface areas. The spectral, temporal, and spatial features extracted from the created Sentinel-2 time series were integrated and collaboratively displayed in the form of visual images, and a convolutional neural network model embedded with integrated information was established to further mine the key information that distinguishes rice from other types. The results showed that the overall accuracy, precision, recall, and F1-score of the proposed method for rice identification reached 99.4%, 99.5%, 99.5%, and 99.5%, respectively, achieving a better performance than the support vector machine classifier. Therefore, the proposed method can effectively reduce the confusion between rice and other types and accurately extract rice distribution information under complex surface conditions.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00009;jsessionid=1fz8yak6po6w2.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Quantifying Impacts of Regional Multiple Factors on Spatiotemporal the Mechanisms for Spatio-temporal changes of Net Primary Vegetation Productivity and Net Ecosystem Productivity: An Example in the Jianghuai River Basin, China
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 761-771(11)</div>
    <div>Authors: Chen, Huimin; Wang, Benlin; Zheng, Liangfeng; Shahtahmassebi, ZhengAmirReza</div>
    <div>Abstract: Despite much valuable research on the mechanisms for spatio-temporal changesof net primary vegetation productivity (NPP) and net ecosystem productivity (NEP), there is a paucity of information on assessing impacts of regional multiple factors on spatiotemporal researchs of NPP and NEP in the complex environment. This study attempts to bridge this information gap using the Jianghuai Basin in China as a case study. Using a field campaign, remotely sensed imagery, socioeconomic data, and meteorological parameters, we developed a framework based on the Carnegie‐Ames‐Stanford Approach (CASA) model, correlation technique, trend analysis, and landscape metrics to measure spatiotemporal changes in NPP and NEP from 2001 to 2018. The derived changes were then linked to regional multiple factors including climate, landscape factors, human activity, and land use change. The results of the research can provide a scientific basis for vegetation evaluation, ecosystem assessment, and other aspects of the region.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000011/art00006;jsessionid=6if6ra2cbp0iq.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Identification of Critical Urban Clusters for Placating Urban Heat Island Effects over Fast-Growing Tropical City Regions: Estimating the Contribution of Different City Sizes in Escalating UHI Intensity
        </a>
    </h3>
    <div style="font-style: italic;">November 2023, pp. 667-677(11)</div>
    <div>Authors: Dutta, Kanaya; Basu, Debolina; Agrawal, Sonam</div>
    <div>Abstract: The incessant rise of artificial surfaces has increased the temperatures of cities, distressing urban health and sustainability. Fast-growing tropical cities particularly call for an understanding of this phenomenon, known as the urban heat island (UHI). The present study was conducted to detect UHI dynamics over the National Capital Region of India. Stretching over more than 32 000 km2, this region consists of urban centers of varying sizes. Landsat thermal bands were processed to extract temperature patterns between 1999 and 2019. Urban climate change was prominent, as a 2349-km2expansion in UHI area was spotted. Urban clusters of different sizes were demarcated by applying the k-nearest neighbor algorithm on the normalized difference building index maps. This empirical analysis helped to form a logarithmic relation between city size and UHI intensity. Observed results set a framework to assess the thermal environment of numerous urban centers from any tropical country. UHI intensity values for various city sizes were computed, as they were crucial to decide the outdoor comfort zones based on the base temperature conditions of other cities. Further, the critical zones in each urban cluster were identified using the vegetation index, and scopes of landscaping were suggested based on the observed building morphologies of different local climate zones.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000011/art00008;jsessionid=6if6ra2cbp0iq.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Novel Object Detection Method for Solid Waste Incorporating a Weighted Deformable Convolution
        </a>
    </h3>
    <div style="font-style: italic;">November 2023, pp. 679-689(11)</div>
    <div>Authors: Xu, Xiong; Cheng, Tao; Zhao, Beibei; Wang, Chao; Tong, Xiaohua; Feng, Yongjiu; Xie, Huan; Jin, Yanmin</div>
    <div>Abstract: Rapid detection of solid waste with remote sensing images is of great significance for environmental protection. In recent years, deep learning-based object detection methods have been widely studied. In contrast to regular objects such as airplanes or buildings, solid wastes commonly h ave arbitrary shapes with difficult‐to‐distinguish boundaries. In this study, a solid waste detection network with a weighted deformable convolution and a global context block based on Feature Pyramid Network (FPN) model was proposed. The designed feature extraction structure can help to enhance the boundary and shape features of solid waste. The effectiveness of the proposed method was verified on the well-known DetectIon in Optical Remote sensing images data set and further on a solid waste data set, which was collected by the authors manually. The experimental results show that the proposed method outperforms other traditional object detection methods and a maximum improvement of 5.27% was obtained compared to the FPN method.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000011/art00009;jsessionid=6if6ra2cbp0iq.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            An Integrated Approach for Wildfire Photography Telemetry using WRF Numerical Forecast Products
        </a>
    </h3>
    <div style="font-style: italic;">November 2023, pp. 691-701(11)</div>
    <div>Authors: Tan, Ling; Ma, Xuelan</div>
    <div>Abstract: Forest fire detection using machine vision has recently emerged as a hot research topic. However, the complexity of background information in smoke images often results in deep learning models losing crucial details while capturing smoke image features. To address this, we present a detection algorithm called Multichannel Smoke YOLOv5s (MCSYOLOv5s). This algorithm comprises a smoke flame detection module, multichannel YOLOv5s (MC‐YOLOv5s), and a smoke cloud classification module, Smoke Classification Network (SCN). MC‐YOLOv5s uses a generative confrontation structure to design a dual‐channel feature extraction network and adopts a new feature cross-fusion mechanism to enhance the smoke feature extraction ability of classic YOLOv5s. The SCN module combines Weather Research and Forecasting numerical forecast results to classify smoke and clouds to reduce false positives caused by clouds. Experimental results demonstrate that our proposed forest fire monitoring method, MCS‐YOLOv5s, achieves higher detection accuracy of 95.17%, surpassing all comparative algorithms. Moreover, it effectively reduces false alarms caused by clouds.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000011/art00010;jsessionid=6if6ra2cbp0iq.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Powerful Correspondence Selection Method for Point Cloud Registration Based on Machine Learning
        </a>
    </h3>
    <div style="font-style: italic;">November 2023, pp. 703-712(10)</div>
    <div>Authors: Tao, Wuyong; Xu, Dong; Chen, Xijiang; Tan, Ge</div>
    <div>Abstract: Correspondence selection is an indispensable process in point cloud registration. The success of point cloud registration largely depends on a good correspondence selection method. For this purpose, a novel correspondence selection method is proposed in this paper. First, two geometric constraints, one of which is proposed in this paper, are used to compute the compatibility score between two correspondences. Then, the feature vectors of the correspondences are constructed according to the compatibility scores between the correspondence and others. A support vector machine classifier is trained to classify the correct and incorrect correspondences by using the feature vectors. The experimental results demonstrate that our method can choose the right correspondences well and get high precision and F-score performance. Also, our method has the best robustness to noise, pointdensity variation, and partial overlap compared to the other methods.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000011/art00011;jsessionid=6if6ra2cbp0iq.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Self-Calibration of the Stereo Vision System on the Chang’E-5 Probe Based on Images and Robot Arm Footprints
        </a>
    </h3>
    <div style="font-style: italic;">November 2023, pp. 713-719(7)</div>
    <div>Authors: Zhang, Shuo; Zheng, Yanhong; Chen, Liping; Ma, Youqing; Hu, Bo; Gu, Zheng; Deng, Xiangjin; Liu, Shaochuang</div>
    <div>Abstract: Self-calibration method for the stereo vision system of the Chang’E-5 probe is proposed. The footprints left by the robot arm after touching the ground are regarded as the lunar control points. A stereo constraint is proposed, and a combined adjustment model is established. The accuracy of the proposed method is verified by Earth-based and lunar experiments. In the Earth-based experiment, the proposed method obtained a 3.18 mm average positioning error in 50 sets of tests, the average residual error of nine footprints was 0.45 pixels, and the unit weight mean square error of Moncam B was 0.181 pixels. In the lunar experiment, the proposed method obtained a 3.22 mm average positioning error in 50 sets of tests, and the unit weight mean-square error of Moncam B was 0.172 pixels. The experimental results show that the proposed method provides high accuracy and stability.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00006;jsessionid=3tveif6pm5nvv.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Mapping Lotus Wetland Distribution with the Phenology Normalized Lotus Index Using SAR Time-Series Imagery and the Phenology-Based Method
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 601-611(11)</div>
    <div>Authors: Wang, Sheng; Wu, Taixia; Shen, Qiang</div>
    <div>Abstract: Lotus wetland is a type of wetland that can efficiently purify water. Therefore, rapid and accurate remote sensing monitoring of the distribution of lotus wetland has great significance to their conservation and the promotion of a sustainable and healthy development of ecosystems. The phenology-based method has proven effective in mapping some different types of wetlands. However, because of the serious absence of remote sensing data caused by cloud coverage and the differences in the phenological rhythms of lotus wetlands in different areas, achieving high-precision mapping of different regions using a unified approach is a challenge. To address the issue, this article proposes a Phenology Normalized Lotus Index (PNLI) model that combines SAR time-series imagery and the phenology-based method. The results of this study demonstrate that the PNLI model shows good applicability in different areas and has high mapping accuracy. The model can map the lotus wetland distribu tion in large areas quickly and simultaneously with high precision.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00007;jsessionid=3tveif6pm5nvv.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            The FABDEM Outperforms the Global DEMs in Representing Bare Terrain Heights
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 613-624(12)</div>
    <div>Authors: Osama, Nahed; Shao, Zhenfeng; Freeshah, Mohamed</div>
    <div>Abstract: Many remote sensing and geoscience applications require a high-precision terrain model. In 2022, the Forest And Buildings removed Copernicus digital elevation model (FABDEM) was released, in which trees and buildings were removed at a 30 m resolution. Therefore, it was necessary to make a comprehensive evaluation of this model. This research aims to perform a qualitative and quantitative analysis of fabdem in comparison with the commonly used global dems. We investigated the effect of the terrain slope, aspect, roughness, and land cover types in causing errors in the topographic representation of all dems. The fabdem had the highest overall vertical accuracy of 5.56 m. It was the best dem in representing the terrain roughness. The fabdem and Copernicus dem were equally influenced by the slopes more than the other models and had the worst accuracy of slope representation. In the tree, built, and flooded vegetation areas of the fabdem, the mean errors in elevation have been reduced by approximately 3.34 m, 1.26 m and 1.55 m, respectively. Based on Welch's t-test, there was no significant difference between fabdem and Copernicus dem elevations. However, the slight improvements in the fabdem make it the best filtered dem to represent the terrain heights over different land cover types.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00008;jsessionid=3tveif6pm5nvv.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Evaluating Surface Mesh Reconstruction Using Real Data
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 625-638(14)</div>
    <div>Authors: Marchand, Yanis; Caraffa, Laurent; Sulzer, Raphael; Clédat, Emmanuel; Vallet, Bruno</div>
    <div>Abstract: Surface reconstruction has been studied thoroughly, but very little work has been done to address its evaluation. In this article, we propose new visibility-based metrics to assess the completeness and accuracy of three-dimensional meshes based on a point cloud of higher accuracy than the one from which the reconstruction has been computed. We use the position from which each high-quality point has been acquired to compute the corresponding ray of free space. Based on the intersections between each ray and the reconstructed surface, our metrics allow evaluating both the global coherency of the reconstruction and the accuracy at close range. We validate this evaluation protocol by surveying several open-source algorithms as well as a piece of licensed software on three data sets. The results confirm the relevance of assessi ng local and global accuracy separately since algorithms sometimes fail at guaranteeing both simultaneously. In addition, algorithms making use of sensor positions perform better than the ones relying only on points and normals, indicating a potentially significant added value of this piece of information. Our implementation is available at https://github.com/umrlastig/SurfaceReconEval.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00009;jsessionid=3tveif6pm5nvv.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Different Urbanization Levels Lead to Divergent Responses of Spring Phenology
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 639-651(13)</div>
    <div>Authors: Dang, Chaoya; Shao, Zhenfeng; Huang, Xiao; Cheng, Gui; Qian, Jiaxin</div>
    <div>Abstract: Urban vegetation phenology is important for understanding the relationship between human activities on urban ecosystems and carbon cycle. The relationship between urban and rural vegetation phenology and environmental and meteorological factors were studied across urban-rural gradients. However, the relationship of intra-urban urbanization intensity (UI) gradients on vegetation at the start of season (SOS) is unclear. Here, we used remote sensing data to quantitatively assess the relationship of vegetation SOS to UI gradients at mid-high latitudes in the northern hemisphere. The results showed that urban area vegetation SOS widely presented earlier than for rural area vegetation. Across the cities we investigated the extent UI gradient was prevalent as a threshold (33.2% ± 2.3%) of surface temperature to SOS advance enhancement and offset. At low urbanization enhanced surface temperature on sos advances, while at high urbanization offset surface temperature on SOS advances. Overall, UI demonstrated a nonlinear relationship with sos. The results of this study suggest that there may be thresholds of impact on vegetation SOS in future global climate and environment change processes, where opposite effects can occur below and above thresholds.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000005/art00010;jsessionid=3n3a18g7jl9hf.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Automatic Satellite Images Orthorectification Using K–Means Based Cascaded Meta-Heuristic Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">May 2023, pp. 291-299(9)</div>
    <div>Authors: Mezouar, Oussama; Meskine, Fatiha; Boukerch, Issam</div>
    <div>Abstract: Orthorectification of high-resolution satellite images using a terrain- dependent rational function model (RFM) is a difficult task requiring a well-distributed set of ground control points (GCPs), which is often time-consuming and costly operation. Further, RFM is sensitive to over-parameterization due to its many coefficients, which have no physical meaning. Optimization-based meta-heuristic algorithms ap- pear to be an efficient solution to overcome these limitations. This pa- per presents a complete automated RFM terrain-dependent orthorec- tification for satellite images. The proposed method has two parts; the first part suggests automating the GCP extraction by combing Scale- Invariant Feature Transform and Speeded Up Robust Features algo- rithms; and the second part introduces the cascaded meta-heuristic al- gorithm using genetic algorithms and particle swarm optimization. In this stage, a modified K-means clustering selection technique was used to support the proposed algorithm for finding the best combinations of GCPs and RFM coefficients. The obtained results are promising in terms of accuracy and stability compared to other literature methods.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000005/art00011;jsessionid=3n3a18g7jl9hf.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            UAS-Based Multi-Temporal Rice Plant Height Change Prediction
        </a>
    </h3>
    <div style="font-style: italic;">May 2023, pp. 301-310(10)</div>
    <div>Authors: Lin, Yuanyang; He, Jing; Liu, Gang; Mou, Biao; Wang, Bing; Fu, Rao</div>
    <div>Abstract: Analyzing rice growth is essential for examining pests, illnesses, lodging, and yield. To create a Digital Surface Model (DSM ) of three important rice breeding stages, an efficient and fast (compared to manual monitoring) Unoccupied Aerial System was used to collect data. Outliers emerge in DSM as a result of the influence of environ- ment and equipment, and the outliers related to rice not only affect the extraction of rice growth changes but are also more challenging to remove. Therefore, after using ground control points uniform geodetic level for filtering, statistical outlier removal (SOR ) and quadratic surface filtering (QSF ) are used. After that, differential operations are applied to the DSM to create a differential digital surface model that can account for the change in rice plant height. Comparing the prediction accuracy before and after filtering: R2= 0.72, RMSE = 5.13cm, nRMSE = 10.65% for the initial point cloud; after QSF, R2= 0.89, RMSE = 2.51cm, nRMSE = 5.21%; after SOR, R2= 0.92, RMSE = 3.32cm, nRMSE = 6.89%. The findings demonstrate that point cloud filtering, particularly SOR, can increase the accuracy of rice monitoring. The method is effective for monitoring, and after filtering, the accuracy is sufficiently increased to satisfy the needs of growth analysis. This has some potential for application and extension.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000005/art00012;jsessionid=3n3a18g7jl9hf.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Spherical Hough Transform for Robust Line Detection Toward a 2D–3D Integrated Mobile Mapping System
        </a>
    </h3>
    <div style="font-style: italic;">May 2023, pp. 311-320(10)</div>
    <div>Authors: Zhang, Daiwei; Xu, Bo; Hu, Han; Zhu, Qing; Wang, Qiang; Ge, Xuming; Chen, Min; Zhou, Yan</div>
    <div>Abstract: Line features are of great importance for the registration of the Vehicle-Borne Mobile Mapping System that contains both lidar and multiple-lens panoramic cameras. In this work, a spherical straight- line model is proposed to detect the unified line features in the panoramic imaging surface based on the Spherical Hough Transform. The local topological constraints and gradient image voting are also combined to register the line features between panoramic images and lidar point clouds within the Hough parameter space. Experimental results show that the proposed method can accurately extract the long strip targets on the panoramic images and avoid spurious or broken line-segments. Meanwhile, the line matching precision between point clouds and panoramic images are also improved.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000005/art00013;jsessionid=3n3a18g7jl9hf.x-ic-live-01" style="text-decoration: none; color: #1b5faa;">
            Blind and Robust Watermarking Algorithm for Remote Sensing Images Resistant to Geometric Attacks
        </a>
    </h3>
    <div style="font-style: italic;">May 2023, pp. 321-332(12)</div>
    <div>Authors: Ren, Na; Pang, Xinyan; Zhu, Changqing; Guo, Shuitao; Xiong, Ying</div>
    <div>Abstract: To address the problem of weak robustness against geometric attacks of remote sensing images' digital watermarking, a robust watermark- ing algorithm based on template watermarking is proposed in this paper, which improves the robustness of digital watermarking against geometric attacks by constructing stable geometric attack invari- ant features. In this paper, the Discrete Fourier Transform domain template watermark is used as the invariant feature against geometric attacks, and the embedding of the cyclic watermark is used to improve the watermark robustness for recovering the watermark synchroniza- tion relationship. To achieve blind extraction of the watermark, a parameter extraction method based on noise extraction is designed. The experimental results demonstrate that the proposed method can effectively improve the robustness of digital watermarking of remote sensing images against geometric attacks. Meanwhile, it can also resist common image processing attacks and compound attacks.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000004/art00008;jsessionid=5ct67or1rhv49.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            GPU-Accelerated PCG Method for the Block Adjustment of Large-Scale High-Resolution Optical Satellite Imagery Without GCPs
        </a>
    </h3>
    <div style="font-style: italic;">April 2023, pp. 211-220(10)</div>
    <div>Authors: Fu, Qing; Tong, Xiaohua; Liu, Shijie; Ye, Zhen; Jin, Yanmin; Wang, Hanyu; Hong, Zhonghua</div>
    <div>Abstract: The precise geo-positioning of high-resolution satellite imagery (HRSI) without ground control points (GCPs) is an important and fundamental step in global mapping, three-dimensional modeling, and so on. In this paper, to improve the efficiency of large-scale bundle adjustment (BA), we propose a combined Preconditioned Conjugate Gradient (PCG) and Graphic Processing Unit (GPU) parallel computing approach for the BA of large-scale HRSI without GCPs. The proposed approach consists of three main components: 1) construction of a BA model without GCPs ; 2) reduction of memory consumption using the Compressed Sparse Row sparse matrix format; and 3) improvement of the computational efficiency by the use of the combined PCG and GPU parallel computing method. The experimental results showed that the proposed method: 1) consumes less memory consumption compared to the conventional full matrix format method; 2) demonstrates higher computational efficiency than the single-core, Ceres-solver and multi-core central processing unit computing methods, with 9.48, 6.82, and 3.05 times faster than the above three methods, respectively; 3) obtains comparable BA accuracy with the above three methods, with image residuals of about 0.9 pixels; and 4) is superior to the parallel bundle adjustment method in the reprojection error.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000004/art00009;jsessionid=5ct67or1rhv49.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Identification of Drought Events in Major Basins of Africa from GRACE Total Water Storage and Modeled Products
        </a>
    </h3>
    <div style="font-style: italic;">April 2023, pp. 221-232(12)</div>
    <div>Authors: Elameen, Ayman M.; Jin, Shuanggen; Olago, Daniel</div>
    <div>Abstract: Terrestrial water storage (TWS) plays a vital role in climatological and hydrological processes. Most of the developed drought indices from the Gravity Recovery and Climate Experiment (GRACE) over Africa neglected the influencing roles of individual water storage components in calculating the drought index and thus may either underestimate or overestimate drought characteristics. In this paper, we proposed a Weighted Water Storage Deficit Index for drought assessment over the major river basins in Africa (i. e., Nile, Congo, Niger, Zambezi, and Orange) with accounting for the contribution of each TWS component on the drought signal. We coupled the GRACE data and WaterGAP Global Hydrology Model through utilizing the component contribution ratio as the weight. The results showed that water storage components demonstrated distinctly different contributions to TWS variability and thus drought signal response in onset and duration. The most severe droughts over the Nile, Congo, Niger, Zambezi, and Orange occurred in 2006, 2012, 2006, 2006, and 2003, respectively. The most prolonged drought of 84 months was observed over the Niger basin. This study suggests that considering the weight of individual components in the drought index provides more reasonable and realistic drought estimates over large basins in Africa from GRACE.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000004/art00010;jsessionid=5ct67or1rhv49.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Lightweight Parallel Octave Convolutional Neural Network for Hyperspectral Image Classification
        </a>
    </h3>
    <div style="font-style: italic;">April 2023, pp. 233-243(11)</div>
    <div>Authors: Li, Dan; Wu, Hanjie; Wang, Yujian; Li, Xiaojun; Kong, Fanqiang; Wang, Qiang</div>
    <div>Abstract: Although most deep learning-based methods have achieved excellent performance for hyperspectral image (HSI) classification, they are often limited by complex networks and require massive training samples in practical applications. Therefore, designing an efficient, lightweight model to obtain better classification results under small samples situations remains a challenging task. To alleviate this problem, a novel, lightweight parallel octave convolutional neural network (LPOCNN) for HSI classification is proposed in this paper. First, the HSI data is preprocessed to construct two three-dimensional (3D) patch cubes with different spatial and spectral scales for each central pixel, removing redundancy and focusing on extracting spatial features and spectral features, respectively. Next, two non- deep parallel branches are created for the two inputs, which design octave convolution rather than classical 3D convolution to facilitate light weighting of the model. Then two-dimensional convolutional neural network is used to extract deeper spectral-spatial features when fusing spectral-spatial features from different parallel layers. Moreover, the spectral-spatial attention is designed to promote the classification performance even further by adaptively adjusting the weights of different spectral-spatial features according to their contribution to classification. Experiments show that our suggested LPOCNN acquires a significant advantage on classification performance over other competitive methods under small sample situations.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000004/art00011;jsessionid=5ct67or1rhv49.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Model-Driven Precise Degradation Analysis Method of Highway Marking Using Mobile Laser Scanning Point Clouds
        </a>
    </h3>
    <div style="font-style: italic;">April 2023, pp. 245-258(14)</div>
    <div>Authors: Ma, Ruifeng; Ge, Xuming; Zhu, Qing; Jia, Xin; Jiang, Huiwei; Chen, Min; Liu, Tao</div>
    <div>Abstract: Highway markings (HMs) are representative elements of inventory digitalization in highway scenes. The accurate position, semantics, and maintenance information of HMs provide significant support for the intelligent management of highways. This article presents a robust and efficient approach for extracting, reconstructing, and degrading analyzing HMs in complex highway scenes. Compared with existing road marking extraction methods, not only can extract HMs in presence of wear and occlusion from point clouds, but we also perform a degradation analysis for HMs. First, the HMs candidate area is determined accurately by sophisticated image processing. Second, the prior knowledge of marking design rules and edge-based matching model that leverages the standard geometric template and radiometric appearance of HMs is used for accurately extracting and reconstructing solid lines and nonsolid markings of HMs, respectively. Finally, two degradation indicators are constructed to describe the completeness of the marking contour and consistency within the marking. Comprehensive experiments on two existing highways revealed that the proposed methods achieved an overall performance of 95.4% and 95.4% in the recall and 93.8% and 95.5% in the precision for solid line and nonsolid line markings, respectively, even with imperfect data. Meanwhile, a database can be established to facilitate agencies' efficient maintenance.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000002/art00009;jsessionid=an7tnc8qgu7p1.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            UAS Edge Computing of Energy Infrastructure Damage Assessment
        </a>
    </h3>
    <div style="font-style: italic;">February 2023, pp. 79-87(9)</div>
    <div>Authors: Bowman, Jordan; Yang, Lexie; Thomas, Orrin; Kirk, Jerry; Duncan, Andrew; Hughes, David; Meade, Shannon</div>
    <div>Abstract: Energy infrastructure assessments are needed within 72 hours of natural disasters, and previous data collection methods have proven too slow. We demonstrate a scalable end-to-end solution using a prototype unmanned aerial system that performs on-the-edge detection, classification (i.e., damaged or undamaged), and geo-location of utility poles. The prototype is suitable for disaster response because it requires no local communication infrastructure and is capable of autonomous missions. Collections before, during, and after Hurricane Ida in 2021 were used to test the system. The system delivered an F1 score of 0.65 operating with a 2.7 s/frame processing speed with the YOLOv5 large model and an F1 score of 0.55 with a 0.48 s/frame with the YOLOv5 small model. Geo-location uncertainty in the bottom half of the frame was ∼8 m, mostly driven by error in camera pointing measurement. With additional training data to improve performance and detect additional types of features, a fleet of similar drones could autonomously collect actionable post-disaster data.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000002/art00010;jsessionid=an7tnc8qgu7p1.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Apricot Tree Detection from UAV-Images Using Mask R-CNN and U-Net
        </a>
    </h3>
    <div style="font-style: italic;">February 2023, pp. 89-96(8)</div>
    <div>Authors: Erdem, Firat; Ocer, Nuri Erkin; Matci, Dilek Kucuk; Kaplan, Gordana; Avdan, Ugur</div>
    <div>Abstract: Monitoring trees is necessary to manage and take inventory of forests, monitor plants in urban areas, distribute vegetation, monitor change, and establish sensitive and renewable agricultural systems. This study aims to automatically detect, count, and map apricot trees in an orthophoto, covering an area of approximately 48 ha on the ground surface using two different algorithms based on deep learning. Here, Mask region-based convolutional neural network (Mask R-CNN) and U-Net models were run together with a dilation operator to detect apricot trees in UAV images, and the performances of the models were compared. Results show that Mask R-CNN operated in this way performs better in tree detection, counting, and mapping tasks compared to U-Net. Mask R-CNN with the dilation operator achieved a precision of 98.7%, recall of 99.7%, F1 score of 99.1%, and intersection over union (IoU) of 74.8% for the test orthophoto. U-Net, on the other hand, has achieved a recall of 93.3%, precision of 97.2%, F1 score of 95.2%, and IoU of 58.3% when run with the dilation operator. Mask R-CNN was able to produce successful results in challenging areas. U-Net, on the other hand, showed a tendency to overlook existing trees rather than generate false alarms.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000002/art00011;jsessionid=an7tnc8qgu7p1.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Comparative Analysis of Different CNN Models for Building Segmentation from Satellite and UAV Images
        </a>
    </h3>
    <div style="font-style: italic;">February 2023, pp. 97-105(9)</div>
    <div>Authors: Sariturk, Batuhan; Kumbasar, Damla; Seker, Dursun Zafer</div>
    <div>Abstract: Building segmentation has numerous application areas such as urban planning and disaster management. In this study, 12 CNN models (U-Net, FPN, and LinkNet using EfficientNet-B5 backbone, U-Net, SegNet, FCN, and six Residual U-Net models) were generated and used for building segmentation. Inria Aerial Image Labeling Data Set was used to train models, and three data sets (Inria Aerial Image Labeling Data Set, Massachusetts Buildings Data Set, and Syedra Archaeological Site Data Set) were used to evaluate trained models. On the Inria test set, Residual-2 U-Net has the highest F1 and Intersection over Union (IoU) scores with 0.824 and 0.722, respectively. On the Syedra test set, LinkNet-EfficientNet-B5 has F1 and IoU scores of 0.336 and 0.246. On the Massachusetts test set, Residual-4 U-Net has F1 and IoU scores of 0.394 and 0.259. It has been observed that, for all sets, at least two of the top three models used residual connections. Therefore, for this study, residual connections are more successful than conventional convolutional layers.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000002/art00012;jsessionid=an7tnc8qgu7p1.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Unmanned Aerial Vehicle (UAV)–Based Imaging Spectroscopy for Predicting Wheat Leaf Nitrogen
        </a>
    </h3>
    <div style="font-style: italic;">February 2023, pp. 107-116(10)</div>
    <div>Authors: Sahoo, Rabi N.; Gakhar, Shalini; Rejith, R.G.; Ranjan, Rajeev; Meena, Mahesh C.; Dey, Abir; Mukherjee, Joydeep; Dhakar, Rajkumar; Arya, Sunny; Daas, Anchal; Babu, Subhash; Upadhyay, Pravin K.; Sekhawat, Kapila; SudhirKumar; Kumar, Mahesh; Chinnusamy, Viswanathan; Khanna, Manoj</div>
    <div>Abstract: Quantitative estimation of crop nitrogen is the key to site-specific management for enhanced nitrogen (N) use efficiency and a sustainable crop production system. As an alternate to the conventional approach through wet chemistry, sensor-based noninvasive, rapid, and near-real-time assessment of crop N at the field scale has been the need for precision agriculture. The present study attempts to predict leaf N of wheat crop through spectroscopy using a field portable spectroradiometer (spectral range of 400–2500 nm) on the ground in the crop field and an imaging spectrometer (spectral range of 400–1000 nm) from an unmanned aerial vehicle (UAV) with the objectives to evaluate (1) four multivariate spectral models (i.e., artificial neural network, extreme learning machine [ELM], least absolute shrinkage and selection operator, and support vector machine regression) and (2) two sets of hyperspectral data collected from two platforms and two different sensors. In the former part of the study, ELM outperforms the other methods with maximum calibration and validation R2 of 0.99 and 0.96, respectively. Furthermore, the image data set acquired from UAV gives higher performance compared to field spectral data. Also, significant bands are identified using stepwise multiple linear regression and used for modeling to generate a wheat leaf N map of the experimental field.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000002/art00013;jsessionid=an7tnc8qgu7p1.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Car Detection from Very High-Resolution UAV Images Using Deep Learning Algorithms
        </a>
    </h3>
    <div style="font-style: italic;">February 2023, pp. 117-123(7)</div>
    <div>Authors: Kaya, Yunus; Şenol, Halil İbrahim; Yiğit, Abdurahman Yasin; Yakar, Murat</div>
    <div>Abstract: It is important to determine car density in parking lots, especially in hospitals, large enterprises, and residential areas, which are used intensively, in terms of executing existing management systems and making precise plans for the future. In this study, cars in parking lots were detected using high-resolution unmanned aerial vehicle (UAV) images with deep learning methods. We tested the performance of the two approaches by determining the number of cars in a parking lot using the You Only Look Once (YOLOv3) and Mask Region–Based Convolutional Neural Networks (Mask R-CNN) approaches as deep learning methods and the deep learning tool of Esri ArcGIS Pro. High-resolution UAV images were processed by photogrammetry and used as input products for the R-CNN and YOLOv3 algorithm. Recall, F1 score, precision ratio/uncertainty accuracy, and average producer accuracy of products automatically extracted with the algorithm were determined as 0.862/0.941, 0.874/0.946, 0.885/0.951, and 0.776/0.897 for R-CNN and YOLOv3, respectively.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000001/art00010;jsessionid=14s2l113tzzrc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Exploring the Addition of Airborne Lidar-DEM and Derived TPI for Urban Land Cover and Land Use Classification and Mapping
        </a>
    </h3>
    <div style="font-style: italic;">January 2023, pp. 19-26(8)</div>
    <div>Authors: Akumu, Clement E.; Dennis, Sam</div>
    <div>Abstract: The classification and mapping accuracy of urban land cover and land use has always been a critical topic and several auxiliary data have been used to improve the classification accuracy. However, to the best of our knowledge, there is limited knowledge of the addition of airborne Light Detection and Ranging (lidar)-Digital Elevation Model (DEM) and Topographic Position Index (TPI) for urban land cover and land use classification and mapping. The aim of this study was to explore the addition of airborne lidar-DEM and derived TPI to reflect data of Landsat Operational Land Imager (OLI) in improving the classification accuracy of urban land cover and land use map- ping. Specifically, this study explored the mapping accuracies of urban land cover and land use classifications derived using: 1) standalone Landsat OLI satellite data; 2) Landsat OLI with acquired airborne lidar-DEM ; 3) Landsat OLI with TPI ; and 4) Landsat OLI with airborne lidar-DEM and derived TPI. The results showed that the addition of airborne lidar-DEM and TPI yielded the best overall urban land cover and land use classification accuracy of about 88%. The findings in this study demonstrated that both lidar-DEM and TPI had a positive impact in improving urban land cover and land use classification.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000001/art00011;jsessionid=14s2l113tzzrc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            A Machine Learning Method for Building Height Estimation Based on Sentinel-2 Bi-Temporal Images
        </a>
    </h3>
    <div style="font-style: italic;">January 2023, pp. 27-36(10)</div>
    <div>Authors: Deng, Zhigang; Fan, Xiwei; Chen, Jian</div>
    <div>Abstract: Building height information is essential for many applications such as urban planning and population density estimation. The building shadow length varies according to seasons, which is shown as different digital number values in multi-temporal images. Thus, the bi-temporal satellite remote sensing images of Sentinel-2 are used to estimate the buildings height in this study. An area of 15 km × 15 km in Beijing, China is taken as the study area. By preprocessing the data, the remaining pixels are split into two parts: 70% as the training data set and the rest as the testing data set. Then, one classification model and three regression models are proposed with using Random Forest (RF) method. Based on the testing data, it shows that the accuracy rate of the classification model has reached 98.4% with the kappa coefficient of 0.93. And the regression models' root-mean-square error (RMSE) is 0.61 floor for 1–6 floors group, 0.41 floor for 7–12 floor group, and 0.98 floor for above 12 floor group. The final RMSE is 1.62 floor with RF models. In general, this study shows the feasibility of using satellite mid-resolution optical image to estimate the building height and provides an important reference for regional building height estimation in the future.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000001/art00012;jsessionid=14s2l113tzzrc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            Generation of High-Resolution Orthomosaics from Historical Aerial Photographs Using Structure-from-Motion and Lidar Data
        </a>
    </h3>
    <div style="font-style: italic;">January 2023, pp. 37-46(10)</div>
    <div>Authors: Suh, Ji Won; Ouimet, William</div>
    <div>Abstract: This study presents a method to generate historical orthomosaics using Structure-from-Motion (SfM ) photogrammetry, historical aerial photographs, and lidar data, and then analyzes the horizontal accuracy and factors that can affect the quality of historical orthoimagery products made with these approaches. Two sets of historical aerial photographs (1934 and 1951) were analyzed, focused on the town of Woodstock in Connecticut, U.S.A. Ground control points (GCPs) for georeferencing were obtained by overlaying multiple data sets, including lidar elevation data and derivative hillshades, and recent orthoimagery. Root-Mean-Square Error values of check points (CPs ) for 1934 and 1951 orthomosaics without extreme outliers are 0.83 m and 1.37 m, respectively. Results indicate that orthomosaics can be used for standard mapping and geographic information systems (GIS ) work according to the ASPRS 1990 accuracy standard. In addition, results emphasize that three main factors can affect the horizontal accuracy of orthomosaics: (1) types of CPs, (2) the number of tied photos, and (3) terrain.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000001/art00013;jsessionid=14s2l113tzzrc.x-ic-live-03" style="text-decoration: none; color: #1b5faa;">
            The Cellular Automata Approach in Dynamic Modelling of Land Use Change Detection and Future Simulations Based on Remote Sensing Data in Lahore Pakistan
        </a>
    </h3>
    <div style="font-style: italic;">January 2023, pp. 47-55(9)</div>
    <div>Authors: Ahmad, Muhammad Nasar; Shao, Zhenfeng; Javed, Akib; Islam, Fakhrul; Ahmad, Hafiz Haroon; Aslam, Rana Waqar</div>
    <div>Abstract: Rapid urbanization has become an immense problem in Lahore city, causing various socio-economic and environmental problems. Therefore, it is noteworthy to monitor land use/land cover (LULC) change detection and future LULC patterns in Lahore. The present study focuses on evaluating the current extent and modeling the future LULC developments in Lahore, Pakistan. Therefore, the semi-automatic classification model has been applied for the classification of Landsat satellite imagery from 2000 to 2020. And the Modules of Land Use Change Evaluation (MOLUSCE) cellular automata (CA-ANN) model was implemented to simulate future land use trends for the years 2030 and 2040. This study project made use of Landsat, Shuttle Radar Topography Mission Digital Elevation Model, and vector data. The research methodology includes three main steps: (i) semi-automatic land use classification using Landsat data from 2000 to 2020; (ii) future land use prediction using the CA-ANN (MOLUSCE) model; and (iii) monitoring change detection and interpretation of results. The research findings indicated that there was a rise in urban areas and a decline in vegetation, barren land, and water bodies for both the past and future projections. The results also revealed that about 27.41% of the urban area has been increased from 2000 to 2020 with a decrease of 42.13% in vegetation, 2.3% in barren land, and 6.51% in water bodies, respectively. The urban area is also expected to grow by 23.15% between 2020 and 2040, whereas vegetation, barren land, and water bodies will all decline by 28.05%, 1.8%, and 12.31%, respectively. Results can also aid in the long-term, sustainable planning of the city. It was also observed that the majority of the city's urban area expansion was found to have occurred in the city's eastern and southern regions. This research also suggests that decision-makers and municipal Government should reconsider city expansion strategies. Moreover, the future city master plans of 2050 must emphasize the relevance of rooftop urban planting and natural resource conservation.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000012/art00010;jsessionid=2e51tnjeh0x6f.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Automatic Registration Method of Multi-Source Point Clouds Based on Building Facades Matching in Urban Scenes
        </a>
    </h3>
    <div style="font-style: italic;">December 2022, pp. 767-782(16)</div>
    <div>Authors: Tan, Yumin; Shi, Yanzhe; Li, Yunxin; Xu, Bo</div>
    <div>Abstract: Both UAV photogrammetry and lidar have become common in deriv- ing three-dimensional models of urban scenes, and each has its own advantages and disadvantages. However, the fusion of these multi- source data is still challenging, in which registration is one of the most important stages. In this paper, we propose a method of coarse point cloud registration which consists of two steps. The first step is to extract urban building facades in both an oblique photogram- metric point cloud and a lidar point cloud. The second step is to align the two point clouds using the extracted building facades. Object Vicinity Distribution Feature (Dijkman and Van Den Heuvel 2002) is introduced to describe the distribution of building facades and register the two heterologous point clouds. This method provides a good initial state for later refined registration process and is transla - tion, rotation, and scale invariant. Experiment results show that the accuracy of this proposed automatic registration method is equiva- lent to the accuracy of manual registration with control points.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000012/art00011;jsessionid=2e51tnjeh0x6f.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            The Simulation and Prediction of Land Surface Temperature Based on SCP and CA-ANN Models Using Remote Sensing Data: A Case Study of Lahore
        </a>
    </h3>
    <div style="font-style: italic;">December 2022, pp. 783-790(8)</div>
    <div>Authors: Ahmad, Muhammad Nasar; Zhengfeng, Shao; Yaseen, Andaleeb; Khalid, Muhammad Nabeel; Javed, Akib</div>
    <div>Abstract: Over the last two decades, urban growth has become a major issue in Lahore, accelerating land surface temperature (LST) rise. The present study focused on estimating the current situation and simulating the future LST patterns in Lahore using remote sensing data and machine learning models. The semi-automated classification model was applied for the estimation of LST from 2000 to 2020. Then, the cellular automata-artificial neural networks (CA-ANN) module was implemented to predict future LST patterns for 2030 and 2040, respectively. Our research findings revealed that an average of 2.8 °C of land surface temperature has increased, with a mean LST value from 37.25 °C to 40.10 °C in Lahore during the last two decades from 2000 to 2020. Moreover, keeping CA-ANN simulations for land surface temperature, an increase of 2.2 °C is projected through 2040, and mean LST values will be increased from 40.1 °C to 42.31 °C by 2040. The CA-ANN model was validated for future LST simulation with an overall Kappa value of 0.82 and 86.2% of correctness for the years 2030 and 2040 using modules for land-use change evaluation. The study also indicates that land surface temperature is an important factor in environmental changes. Therefore, it is suggested that future urban planning should focus on urban rooftop plantations and vegetation conservation to minimize land surface temperature increases in Lahore.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000012/art00012;jsessionid=2e51tnjeh0x6f.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Permanganate Index Variations and Factors in Hongze Lake from Landsat-8 Images Based on Machine Learning
        </a>
    </h3>
    <div style="font-style: italic;">December 2022, pp. 791-802(12)</div>
    <div>Authors: Lv, Yan; Guo, Hongwei; Jin, Shuanggen; Wang, Lu; Bian, Haiyi; Liu, Haijian</div>
    <div>Abstract: The permanganate index (CODMn), defined as a comprehensive index to measure the degree of surface water pollution by organic matter and reducing inorganic matter, plays an important role in indicating water pollution and evaluating aquatic ecological health. However, remote sensing monitoring of water quality is presently focused mainly on phytoplankton, suspended particulate matter, and yellow substance, while there is still great uncertainty in the retrieval of CODMn. In this study, the Landsat-8 surface reflectance data set from Google Earth Engine and in situ CODMnmeasurements were matched. The support vector regression (SVR) machine learning model was calibrated using the matchups. With the SVR model, this study estimates the CODMnin Hongze Lake, presents the historical spatiotemporal CODMndistributions, and discusses the affecting factors of the change trend of the CODMnin Hongze Lake. The results showed that the SVR model adequately estimated CODMn, with a sum squared error of 1.49 mg2/L2, a coefficient of determination (R2) of 0.95, and a root mean square error of 0.15 mg/L. CODMnin Hongze Lake was high in general and showed a decreasing trend in the past decade. Huai River, Xinsu River, and Huaihongxin River were still the main sources of oxygen-consuming pollutants in Hongze Lake. The wetland natural reserve near Yugou had a significant effect on reducing CODMn. This study provides not only a scientific reference for the management of CODMnin Hongze Lake, but also a feasible scheme for remote sensing monitoring of CODMnin inland water.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000012/art00013;jsessionid=2e51tnjeh0x6f.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Exploring Spatiotemporal Variations and Driving Factors of Urban Comprehensive Carrying Capacity in the Yangtze River Delta Urban Agglomeration
        </a>
    </h3>
    <div style="font-style: italic;">December 2022, pp. 803-812(10)</div>
    <div>Authors: Guo, Songjing; Wu, Xueling; Niu, Ruiqing; Wu, Wenfu</div>
    <div>Abstract: The Yangtze River Delta urban agglomeration (YRDUA) is one of the most active economic development regions in China. However, the YRDUA is facing the severe test of sustainable development. Therefore, this study evaluates the urban comprehensive carrying capacity (UCCC) of cities in the YRDUA from 2009 to 2019 from natural, social, and economic perspectives, and uses the Geographically and Temporally Weighted Regression model to analyze driving factors of spatiotemporal variations of the UCCC. Besides, this study divides the UCCC into three levels: high, medium, and low. The results indicate that: 1) there is a significant spatial heterogeneity of the UCCC in the YRDUA; 2) the UCCC in the YRDUA is generally at medium level and presents a gradually increasing trend; 3) 10 driving factors significantly affect the UCCC, and the influence intensity is non-stationary in time and space. These findings can provide references for improving the UCCC in the YRDUA.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000011/art00009;jsessionid=9eer5pjqne5cm.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Development of Technique for Vehicle Specific Off-Road Trafficability Assessment Using Soil Cone Index, Water Index, and Geospatial Data
        </a>
    </h3>
    <div style="font-style: italic;">November 2022, pp. 689-697(9)</div>
    <div>Authors: Pundir, Sunil Kumar; Garg, Rahul Dev</div>
    <div>Abstract: Nowadays, the type of vehicles, either tracked or wheeled in the Army has increased considerably and every decision maker wants the current details of off-road trafficability for operation planning. Therefore, vehicle-specific trafficability maps are the need of the hour. Emphasis should be given on soils capable of bearing the moving load of a vehicle and it is an important factor to be considered. Soil variability in spatial and temporal dimensions affects the assessment of off-road trafficability. Genetically, it is assumed that similar soil types behave similarly at a regional scale to reduce the complexity due to its variability. Remolding Cone Index (RCI) of Soil is the indicator of its capability and for generic solution; its value can be related to gravimetric moisture of soil for getting a general idea. In this paper, a logics-based, new concept has been introduced to rationalize the RCI values of these moist areas. Most significantly, moisture- and water-bound areas play an important role in the assessment of off-road trafficability. Therefore, to cover larger areas, a grid-based approach was taken as a base and, to get a preliminary idea of prevailing moisture, Normalized Difference Water Index was also mapped. Every vehicle has fixed vehicle cone index based on its vehicular characteristics and can be related with RCI for trafficability purpose. This new technique will save time and field work and is immensely useful for the trafficability assessment of any specific vehicle.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000011/art00011;jsessionid=9eer5pjqne5cm.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            The Use of Indices and Modified U-Net Network in Improving the Classification of Planting Structures
        </a>
    </h3>
    <div style="font-style: italic;">November 2022, pp. 699-706(8)</div>
    <div>Authors: Li, Weidong; Meng, Fanqian; Bai, Linyan; Yu, Yongbo; Ullah, Inam; Duan, Jinlong; Zhang, Xuehai</div>
    <div>Abstract: It was difficult to accurately obtain crop planting structure by using the spectral information of high spatial resolution and low spatial resolution multispectral images of panchromatic images at the same time. In this paper, we propose a method of planting structure extraction based on indices and an improved U-Net semantic segmentation network. Based on the original band of Landsat-8, we used an image fusion algorithm to highlight the characteristics of vegetation, water, and soil respectively by three indices added, and the improved U-Net network was used to classify the type of planting structure. The results showed that the overall accuracy of classification was more than 91.6%, and the accuracy of crops was up to 93.8%. Automated water extraction index in image fusion effectively improved the classification accuracy. This method could extract a variety of information about planting structures automatically and accurately. It provided theoretical support for adjusting and optimizing regional planting structures.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000011/art00012;jsessionid=9eer5pjqne5cm.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Managing Earth Hazards Using the Deep Reinforcement Learning Algorithm for the Industrial Internet of Things Network
        </a>
    </h3>
    <div style="font-style: italic;">November 2022, pp. 707-714(8)</div>
    <div>Authors: Liu, Weiwei</div>
    <div>Abstract: Wireless networks using resource management with the enormous number of Internet of Things (IoT) users is a critical problem in developing networks for the fifth generation. The primary aim of this research is to optimize the use of IoT network resources. Earth surface features can be identified and their geo-biophysical properties estimated using radiation as the medium of interaction in remote sensing techniques (RST). Deep reinforcement learning (DRL) has significantly improved traditional resource management, which is challenging to model. The Industrial Internet of Things (IIoT) network has to be carried out in real time with excess network resources. Conventional techniques have a significant challenge because of the extensive range and complexity of wireless networks. The DRL method has been used in several areas, including management and allocation of resources, dynamic channel access, mobile downloading, unified edge computing, caching and communication, and fog radio access networks. DRL -IIoT is more successful than the Q-learning technique for a single agent. The design and analysis of the DRL -based approach in stationary base stations to solve the typical assignment of resources issues have been mostly restricted. The DRL is used as a clustering technique to construct the primary model of the system with k-means. This article discusses optical and microwave sensors in RST techniques and applications, examines the areas where there are gaps, and discusses Earth hazards. Furthermore, a comprehensive resource-based strengthening learning system is developed to ensure the best use of resources. Simulation results show that the suggested method efficiently (97.24%) allocates available spectrum, cache, and computer resources to deep deterministic policy gradient benchmarks.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000011/art00013;jsessionid=9eer5pjqne5cm.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            New Generation Hyperspectral Sensors DESIS and PRISMA Provide Improved Agricultural Crop Classifications
        </a>
    </h3>
    <div style="font-style: italic;">November 2022, pp. 715-729(15)</div>
    <div>Authors: Aneece, Itiya; Thenkabail, Prasad S.</div>
    <div>Abstract: Using new remote sensing technology to study agricultural crops will support advances in food and water security. The recently launched, new generation spaceborne hyperspectral sensors, German DLR Earth Sensing Imaging Spectrometer (DESIS) and Italian PRecursore IperSpettrale della Missione Applicativa (PRISMA), provide unprecedented data in hundreds of narrow spectral bands for the study of the Earth. Therefore, our overarching goal in this study was to use these data to explore advances that can be made in agricultural research. We selected PRISMA and DESIS images during the 2020 growing season in California's Central Valley to study seven major crops. PRISMA and DESIS images were highly correlated (R 2of 0.9–0.95). Out of the 235 DESIS bands (400–1000 nm) and 238 PRISMA bands (400–2500 nm), 26 (11%) and 45 (19%) bands, respectively, were optimal to study agricultural crops. These optimal bands provided crop type classification accuracies of 83–90%. Hyperspectral vegetation indices to estimate plant pigment content, stress, biomass, moisture, and cellulose/lignin content were also identified.</div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000011/art00014;jsessionid=9eer5pjqne5cm.x-ic-live-02" style="text-decoration: none; color: #1b5faa;">
            Foreground-Aware Refinement Network for Building Extraction from Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">November 2022, pp. 731-738(8)</div>
    <div>Authors: Yan, Zhang; Xiangyu, Wang; Zhongwei, Zhang; Yemei, Sun; Shudong, Liu</div>
    <div>Abstract: To extract buildings accurately, we propose a foreground-aware refinement network for building extraction. In particular, in order to reduce the false positive of buildings, we design the foreground-aware module using the attention gate block, which effectively suppresses the features of nonbuilding and enhances the sensitivity of the model to buildings. In addition, we introduce the reverse attention mechanism in the detail refinement module. Specifically, this module guides the network to learn to supplement the missing details of the buildings by erasing the currently predicted regions of buildings and achieves more accurate and complete building extraction. To further optimize the network, we design hybrid loss, which combines BCE loss and SSIM loss, to supervise network learning from both pixel and structure layers. Experimental results demonstrate the superiority of our network over state-of-the-art methods in terms of both quantitative metrics and visual quality.</div>
</article>
