
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 04 - Year 2025</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 04 - Year 2025</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00009;jsessionid=4er1wfoj21hut.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Sat2building: Lod-2 Building Reconstruction from Satellite Imagery Using Spatial Embeddings
        </a>
    </h3>
    <div style="font-style: italic;">202504, pp. 203-212(10)</div>
    <div>Authors: Schuegraf, Philipp; Gui, Shengxi; Qin, Rongjun; Fraundorfer, Friedrich; Bittner, Ksenia</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/04/SAT2BUILDING LoD-2 Building Reconstruction from Satellite Imagery Using Spatial Embeddings.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The reconstruction of buildings in level of detail–2, according to the CityGML standard, is an essential feature in applications such as urban planning, environmental simulations, and virtual reality. Existing methods work primarily only on aerial data, depend on an external digital terrain model, or do not accurately separate individual buildings. In this work, we present SAT2BUILDING, a method that predicts roof planes, building sections, and building heights in a single, fully convolutional neural network. The network relies on only orthorectified panchromatic imagery and a photogrammetric digital surface model. The three outputs are jointly processed in a level of detail–2 reconstruction pipeline that generates building models that are seamlessly connected, geometrically accurate and complete, and topologically correct. We use spatial embeddings that enable accurate segmentation of building sections and roof planes from satellite imagery. The model generalizes to data from Bonn, Germany, and Lyon, France, after being trained on data from Berlin, Germany. The training and test data differ in lighting conditions, architectural styles, and ground sampling distances. Thorough comparative evaluation shows the superiority of SAT2BUILDING over three baseline methods.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00011;jsessionid=4er1wfoj21hut.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Aboveground Carbon Stock of Moso Bamboo Forests Is Significantly Reduced byPantana phyllostachysaeChao Stress: Evidence from Multi-source Remote Sensing Imagery
        </a>
    </h3>
    <div style="font-style: italic;">202504, pp. 213-224(12)</div>
    <div>Authors: Yang, Yuanyao; Xu, Zhanghua; Chen, Lingyan; Shen, Wanling; Li, Haitao; Zhang, Chaofei; Sun, Lei; Guo, Xiaoyu; Guan, Fengying</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/04/The Aboveground Carbon Stock of Moso Bamboo Forests Is Significantly Reduced by Pantana phyllostachysae Chao Stress- Evidence from Multi-source Remote Sensing Imagery.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study estimated aboveground carbon stock (AGC) using field data and integrated multi-source remote sensing imagery to understand the effects of Pantana phyllostachysae Chao (P. phyllostachysae) stress. AGC remote sensing inversion was performed while accounting for P. phyllostachysae stress, and changes were analyzed. Results indicate: (1) Carbon content coefficients of Moso bamboo leaves, branches, and culms under pest stress ranged from 0.422 to 0.543 g/g, decreasing with increased stress. (2) A random forest model using multi-source data demonstrated the best performance (R2 = 0.688), estimating average AGC at 28.427 t/ha and total carbon sequestration at 913.902 MtC (Million tons of Carbon). (3) Increased pest stress resulted in gradual reductions in AGC. (4) Pest stress is estimated to result in a carbon sequestration loss of 77.443 MtC. The AGC estimation model indicates thatP. phyllostachysaesignificantly reduces AGC, providing crucial data for understanding carbon cycling and enhancing carbon sink management in Moso bamboo forests.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00012;jsessionid=4er1wfoj21hut.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Cost-Effective High-Definition Building Mapping: Box-Supervised Rooftop Delineation Using High- Resolution Remote Sensing Imagery
        </a>
    </h3>
    <div style="font-style: italic;">202504, pp. 225-239(15)</div>
    <div>Authors: He, Hongjie; Xu, Linlin; Chapman, Michael A.; Ma, Lingfei; Li, Jonathan</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/04/Cost-Effective High-Definition Building Mapping- Box-Supervised Rooftop Delineation Using High- Resolution Remote Sensing Imagery.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Deep learning–based high-definition building mapping faces challenges due to the need for extensive high-quality training data, leading to significant annotation costs. To mitigate this challenge, we introduce Box2Boundary, a novel approach using box supervision, in conjunction with the segment anything model (SAM), to achieve cost-effective rooftop delineation. Leveraging the tiny InternImage architecture for enhanced feature extraction and using the dynamic scale training strategy to tackle scale variance, Box2Boundary demonstrates superior performance compared to alternative box-supervised methods. Extensive experiments on the Wuhan University Building Data Set validate our method's effectiveness, showcasing remarkable results with an average precision of 48.7%, outperforming DiscoBox, BoxInst, and Box2Mask by 22.0%, 11.3%, and 2.0%, respectively. In semantic segmentation, our method achieved an F1score of 89.54%, an overall accuracy (OA) of 97.73%, and an intersection over union (IoU) of 81.06%, outperforming all other bounding-box-supervised methods, image tag–supervised methods, and most scribble-supervised methods. It also demonstrated competitive performance compared to fully supervised methods and scribble-supervised methods. SAM integration further boosts performance, yielding an F1score of 90.55%, OA of 97.84%, and IoU of 82.73%. Our approach's efficacy extends to the Waterloo Building and xBD Data Sets, achieving an OA of 98.48%, IoU of 84.72%, and F1score of 91.73% for the former and an OA of 97.32%, IoU of 60.10%, and F1score of 75.08% for the latter. These results underscore the method's robustness and cost-effectiveness in rooftop delineation across diverse data sets.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 04 - Year 2025</p>
        </footer>
    </body>
    </html>
    