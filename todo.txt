1. update InPress. 
- dwoanload inpress pdf from ingenta.
- put it to InPress folder
- change the file name to s13.pdf
- run python inpress_pdf2html_GPT.py
- exam: in_press_articles.csv
- exam: in_press_articles.html

2. Issues
- run python issues_generate_html.py
- exam: issues.html

3. MostCited
- fetch google scholar citation. two ways.
- use 3 request per day. from scholarly. => articles_with_citation_scholarly.csv
- use serpdog 10k per day. => articles_with_citation.csv (remember to add the apikey and remove it after use)
- run most_cite_1csv_{{method}}.py to get the csv 
- most_cited_2sort_csv_citation_descend.py => sorted_articles_with_citation.csv
- get sorted csv.
- only use the top 6 csv to generate html
- exam: top_6_articles.html

4. Most Download
- download the most recent csv with download data.
- run python: most_download_csv2html.py
- exam: most_download_articles.html

5. Recent Articles 
- run rencent_articles_1screaper.py 
it fet all the info from recent 24 issues. and collect them to the pool
- run recent_articles_2generate_html.py
it generates all the artilces in the pool to html. and the html on pers will select them randomly
exam: member_only_articles and open_access_articles html