<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000008/art00014;jsessionid=jswnr2ht6dqg.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            On the Transferability of Semantic Segmentation for Very-High-Resolution Remote Sensing Data of Multi-City Environments
        </a>
    </h3>
    <div style="font-style: italic;">August 2025, pp. 517-528(12)</div>
    <div>Authors: Qin, Rongjun; Zhang, Guixiang; Tang, Yang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Semantic segmentation of very-high-resolution remote sensing (RS) data is foundational for many RS applications in urban environments. Images from sources like Worldview-3/4 and Pleiades-Neo offer resolutions as high as 0.3 m, enabling a fine-grained understanding of urban structures. Recent deep learning‐based methods have significantly outperformed traditional approaches in RS semantic segmentation/classification tasks. However, they require large training data sets and often lack transferability due to highly disparate RS image content across different geographical regions. However, no comprehensive analysis exists on their transferability—i.e., to what extent a model trained on a source domain can be applied to a target domain in urban areas. This paper investigates the raw transferability of traditional and deep-learning models and the effectiveness of domain adaptation approaches in enhancing deep-learning model transferability (adapted transferability). Using five highly diverse RS data sets from different cities (6792 patches of 1024 × 1024 pixels each), we trained six models with and without three domain adaptation approaches to quantitatively analyze transferability between data sets. To facilitate easy assessment of model transferability, we developed a simple method to quantify transferability using spectral indices as a medium, demonstrating its effectiveness in evaluating model transferability at the target domain when labels are unavailable. Our experiments yield several important but underreported observations on raw and adapted transferability. Moreover, our proposed label-free transferability assessment method outperforms posterior model confidence and can guide model selection for urban studies globally. The models and datasets are publicly available on GitHub at: https://github.com/GDAOSU/Transferability-Remote-Sensing.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00010;jsessionid=2h2sc8f1nag5t.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Combined Use of Satellite Observations and the RIM for Assessing Recovery from Natural Disasters
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 407-417(11)</div>
    <div>Authors: Cao, Changyong; Wang, Wenhui; Bai, Yan; Shao, Xi; Uprety, Sirish; Qiu, Hong-Lie</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In this study, we explore using satellite observations to assess community recovery from natural disasters such as fires and hurricanes, supplementing the Resilience Inference Model (RIM). The RIM model has been successfully used to quantify recoveries from hurricanes along the Gulf Coast, but it relies on long-term population changes over years or decades. Our approach integrates satellite observations to enhance recovery assessment with a shorter latency of weeks or months. Using fire, vegetation, and night light data from the Visible Infrared Imaging Radiometer Suite (VIIRS) with daily global observations, Sentinel-2, Landsat-8, and Geostationary Operational Environmental Satellite/Advanced Baseline Imager, we quantitatively evaluate fire intensity, light outage, and urban greenness changes, along with subsequent recovery, focusing on the 2023 Maui fire and selected hurricane cases along the Gulf Coast. This approach complements the RIM model by introducing quantifiable physical parameters with shorter latency, particularly beneficial in areas where census data are either unavailable or unreliable.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00017;jsessionid=2h2sc8f1nag5t.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spatiotemporal Continuous Shallow Water Bathymetry from a Kriged Kalman Filter
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 463-471(9)</div>
    <div>Authors: Wang, Lei; Liu, Hongxing; Kang, Lei; Su, Haibin; Shu, Song; Wang, Jun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In GIScience, problems of missing data in space or time are nontrivial. We implemented a Kriged Kalman filter (KKF)‐based data interpolation and assimilation technique and tested it for mapping bathymetry at unsampled locations and times. This technique integrates the Kriging and Kalman filter computation frameworks to perform spatiotemporal data assimilation, which can produce spatially and temporally continuous bathymetric fields from samples that are scarce in space and time. The spatiotemporal bathymetric field over the estuary of the Yangtze River was mapped based on the four boat-based depth echo-sounding surveys conducted in 1982, 1997, 2002, and 2010. Our validation and verification analyses showed that the KKF assimilation model can predict bathymetry accurately and reliably at unsampled locations and times. This paper demonstrates that KKF is superior to traditional spatial interpolation methods because it informs the interpolator with the temporal component that also extends the prediction to the time domain. The experiments indicate that greater time intervals in conducting bathymetric surveys result in a more pronounced influence on the performance of KKF than the spatial sparsity of depth samples. The ability of space-time prediction of bathymetry allows underwater depth measurements to be accurately aligned with satellite images, which is essential for improving multispectral image inversion in bathymetry studies.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000005/art00013;jsessionid=3c38n8jinb1pj.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Improving Crop Classification by Integrating Phenology Using Random Forests: Assessing the Role of Feature Selection
        </a>
    </h3>
    <div style="font-style: italic;">May 2025, pp. 307-318(12)</div>
    <div>Authors: Jiangwei, Hu; Jingye, Shi; Jiqiang, Liu; Guolong, Guo; Jiadong, Jin</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The increase of satellite images with high spatial resolution, short revisit period, and wide spatial coverage has brought an enormous amount of data; however, limited efforts have been made in feature selection for crop classification. Furthermore, different crop types have unique spectral, spatial, and phenological characteristics that have not been well understood and fully used for the expected results. This study established a crop-classification framework using the random forest model by integrating four types of features (i. e., spectral reflectance features, vegetation index features, spatial texture features, and crop phenological features) over 15 scenarios generated from Sentinel-2 images. The random forest model performed best (overall accuracy = 92.86%; Kappa coefficient = 0.8995) by integrating the four types of features. We systematically assessed the contribution of feature combinations on individual crop classification. Specifically, different feature combinations can effectively improve the recognition accuracy of different crop types. Our findings can provide great potential in choosing optimal features for crop classifications and benefit the application of machine learning in remote sensing–based crop mapping.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00009;jsessionid=m66r7tgk1rab.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Sat2building: Lod-2 Building Reconstruction from Satellite Imagery Using Spatial Embeddings
        </a>
    </h3>
    <div style="font-style: italic;">April 2025, pp. 203-212(10)</div>
    <div>Authors: Schuegraf, Philipp; Gui, Shengxi; Qin, Rongjun; Fraundorfer, Friedrich; Bittner, Ksenia</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The reconstruction of buildings in level of detail–2, according to the CityGML standard, is an essential feature in applications such as urban planning, environmental simulations, and virtual reality. Existing methods work primarily only on aerial data, depend on an external digital terrain model, or do not accurately separate individual buildings. In this work, we present SAT2BUILDING, a method that predicts roof planes, building sections, and building heights in a single, fully convolutional neural network. The network relies on only orthorectified panchromatic imagery and a photogrammetric digital surface model. The three outputs are jointly processed in a level of detail–2 reconstruction pipeline that generates building models that are seamlessly connected, geometrically accurate and complete, and topologically correct. We use spatial embeddings that enable accurate segmentation of building sections and roof planes from satellite imagery. The model generalizes to data from Bonn, Germany, and Lyon, France, after being trained on data from Berlin, Germany. The training and test data differ in lighting conditions, architectural styles, and ground sampling distances. Thorough comparative evaluation shows the superiority of SAT2BUILDING over three baseline methods.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000003/art00011;jsessionid=1c4hdsp4bqpc8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Comparative Study of Deep Learning Methods for Automated Road Network Extraction from High-Spatial-Resolution Remotely Sensed Imagery
        </a>
    </h3>
    <div style="font-style: italic;">March 2025, pp. 163-174(12)</div>
    <div>Authors: Zhou, Haochen; He, Hongjie; Xu, Linlin; Ma, Lingfei; Zhang, Dedong; Chen, Nan; Chapman, Michael A.; Li, Jonathan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Road network data are crucial for various applications, such as road network planning, traffic control, map navigation, autonomous driving, and smart city construction. Automated road network extraction from high-spatial-resolution remotely sensed imagery has shown promise in road network data construction. In recent years, the advent of deep learning algorithms has pushed road network extraction towards auto - mation, achieving very high accuracy. However, the latest deep learning models are often less applied in the field of road network extraction and lack comparative experiments for guidance. Therefore, this research selected three recent deep learning algorithms, including dense prediction transformer (DPT), SegFormer, SEgmentation TRansformer (SETR), and the classic model fully convolutional network-8s (FCN-8s) for a comparative study. Additionally, this research paper compares three different decoder structures within the SETR model (SETR_naive, SETR_mla, SETR_pup) to investigate the effect of different decoders on the road network extraction task. The experiment is conducted on three commonly used datasets: the DeepGlobe Dataset, the Massachusetts Dataset, and Road Datasets in Complex Mountain Environments (RDCME). The DPT model outperforms other models on the Massachusetts dataset with superior reliability, achieving a high accuracy of 96.31% and excelling with a precision of 81.78% and recall of 32.50%, leading to an F1 score of 46.51%. While SegFormer has a slightly higher F1 score, DPT's precision is particularly valuable for minimizing false positives, making it the most balanced and reliable choice. Similarly, for the DeepGlobe Dataset, DPT achieves an accuracy of 96.76%, precision of 66.12%, recall of 41.37%, and F1 score of 50.89%, and for RDCME, DPT achieves an accuracy of 98.94%, precision of 99.07%, recall of 99.84%, and F1 score of 99.46%, confirming its consistent performance across datasets. This paper provides valuable guidance for future studies on road network extraction techniques using deep learning algorithms.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000002/art00010;jsessionid=9qigkkeu6s1c.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Artificial Neural Network Multi-layer Perceptron Models to Classify California's Crops using Harmonized Landsat Sentinel (HLS) Data
        </a>
    </h3>
    <div style="font-style: italic;">February 2025, pp. 91-100(10)</div>
    <div>Authors: McCormick, Richard; Thenkabail, Prasad S.; Aneece, Itiya; Teluguntla, Pardhasaradhi; Oliphant, Adam J.; Foley, Daniel</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Advances in remote sensing and machine learning are enhancing cropland classification, vital for global food and water security. We used multispectral Harmonized Landsat 8 Sentinel-2 (HLS) 30-m data in an artificial neural network (ANN) multi-layer perceptron (MLP) model to classify five crop classes (cotton, alfalfa, tree crops, grapes, and others) in California's Central Valley. The ANN MLP model, trained on 2021 data from the United States Department of Agriculture's Cropland Data Layer, was validated by classifying crops for an independent year, 2022. Across the five crop classes, the overall accuracy was 74%. Producer's and user's accuracies ranged from 65% to 87%, with cotton achieving the highest accuracies. The study highlights the potential of using deep learning with HLS time series data for accurate global crop classification.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00010;jsessionid=9rot9lobdm4bm.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring LULC Changes in Babil Province for Sustainable Development Purposes Within the Period 2004–2023
        </a>
    </h3>
    <div style="font-style: italic;">December 2024, pp. 745-753(9)</div>
    <div>Authors: Jassoom, Hayder Hameed; Abdoon, Rabab Saadoon</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Land use and land cover studies are fundamental to achieving sustainable development goals by providing the information necessary for informed decision-making in social and economic development and natural resource management. This study relied on remote sensing data to analyze and assess land use and land cover changes in Babil Province, Iraq, over the past two decades. The study focused on identifying the patterns and factors influencing these changes, using Landsat satellite imagery to create digital maps classifying land into four main categories: urban lands, bare soil lands, water bodies, and vegetation lands. The results showed a noticeable expansion of urban lands at the expense of bare soil lands, primarily attributed to population growth, economic development, and improved security conditions. This study underscores the importance of sustainable land management and urban planning in Babil Province. These results highlight the importance of sustainable land management in Babil Province, including sound urban planning considering urban expansion's environmental, social, and economic effects. The classification was implemented using a maximum likelihood classifier, and the accuracy assessment yielded satisfactory results with an overall accuracy of 93.5517%. This study encourages using artificial intelligence to track and analyze land use changes in Babil.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00012;jsessionid=9rot9lobdm4bm.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Image Fusion in Remote Sensing: An Overview and Meta-Analysis
        </a>
    </h3>
    <div style="font-style: italic;">December 2024, pp. 755-775(21)</div>
    <div>Authors: Albanwan, Hessah; Qin, Rongjun; Tang, Yang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Remote sensing image fusion is consistently used to turn raw images of different resolutions, sources, and modalities into accurate, complete, and spatiotemporally coherent images. It facilitates downstream applications such as pan sharpening, change detection, and classification. However, image fusion solutions are highly disparate to various remote sensing problems and are often narrowly defined in existing reviews as topical applications (e. g., pan sharpening). Theoretically, image fusion can be applied to any gridded data through pixel-level operations; thus, we expand its scope by comprehensively surveying relevant works. We develop a simple taxonomy for many-to-one and many-to-many image fusion, defining it as a mapping problem turning one or multiple images into another set based on desired coherence. Furthermore, we provide a meta-analysis to cover 10,420 peer-reviewed papers from the 1980s to 2023 studying various types of image fusion and their applications. Finally, we discuss image fusion's benefits and emerging challenges to provide open research directions.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00012;jsessionid=1rd99qsmrwe3m.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Machine Learning and New-Generation Spaceborne Hyperspectral Data Advance Crop Type Mapping
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 687-698(12)</div>
    <div>Authors: Aneece, Itiya; Thenkabail, Prasad S.; McCormick, Richard; Alifu, Haireti; Foley, Daniel; Oliphant, Adam J.; Teluguntla, Pardhasaradhi</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Hyperspectral sensors provide near-continuous spectral data that can facilitate advancements in agricultural crop classification and characterization, which are important for addressing global food and water security issues. We investigated two new-generation hyperspectral sensors, Germany’s Deutsches Zentrum für Luft‐ und Raumfahrt Earth Sensing Imaging Spectrometer (DESIS) and Italy’s PRecursore IperSpettrale della Missione Applicativa (PRISMA), within California's Central Valley in August 2021 focusing on five irrigated agricultural crops (alfalfa, almonds, corn, grapes, and pistachios). With reference data from the U.S. Department of Agriculture Cropland Data Layer, we developed a spectral library of the crops and classified them using three machine learning algorithms (support vector machines [SVM], random forest [RF], and spectral angle mapper [SAM]) and two philosophies: 1. Full spectral analysis (FSA) and 2. Optimal hyperspectral narrowband (OHNB) analysis. For FSA, we used 59 DESIS four-bin product bands and 207 of 238 PRISMA bands. For OHNB analysis, 9 DESIS and 16 PRISMA nonredundant OHNBs for studying crops were selected. FSA achieved only 1% to 3% higher accuracies relative to OHNB analysis in most cases. SVM provided the best results, closely followed by RF. Using both DESIS and PRISMA image OHNBs in SVM for classification led to higher accuracy than using either image alone, with an overall accuracy of 99%, producer’s accuracies of 94% to 100%, and user???s accuracies of 95% to 100%.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00013;jsessionid=fd2krp3bsnqod.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Bank Line Extraction by Integration of Orthoimages and Lidar Digital Elevation Model Using Principal Component Analysis and Alpha Matting
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 631-638(8)</div>
    <div>Authors: Deshpande, Sagar S.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Riverbank lines change over time, causing loss of land and property. Accurate mapping of riverbank lines is essential for restoration and preservation. This paper presents a method to map riverbank lines by combining georeferenced orthoimages and lidar digital elevation model (DEM). This method uses the properties that lidar can provide elevations under trees and open water edges are visible in orthoimages to extract the planimetric locations of bank lines. The orthoimage pixels with less than 0.15% slope on the DEM were replaced by water pixels. Principal component analysis (PCA) was conducted using DEM, slope, and orthoimage bands. Training data of river body and the background were identified manually on the first three component images. An alpha matting–based method was implemented using the training data to extract the bank lines. Bankline using α value of 50% probability were statistically and visually better when compared to the manual bank lines.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00014;jsessionid=6v8nnnk451qbp.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            One-Dimensional-Mixed Convolution Neural Network and Covariance Pooling Model for Mineral Mapping of Porphyry Copper Deposit Using PRISMA Hyperspectral Data
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 511-522(12)</div>
    <div>Authors: Peyghambari, Sima; Zhang, Yun; Heidarian, Hassan; Sekandari, Milad</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Mapping distribution of alterations around porphyry copper deposits (PCDs) greatly affects mineral exploration. Diverse geological processes generate irregular alteration patterns with diverse spectral characteristics in mineral deposits. Applying remotely sensed hyperspectral images (HSIs) is an appealing technology for geologic surveyors to generate alteration maps. Conventional methods mainly use shallow spectral absorption features to discriminate minerals and cannot extract their important spectral information. Deep neural networks with nonlinear layers can evoke the deep spectral and spatial information of HSIs. Deep learning-based methods include fully connected neural networks, convolutional neural networks, and hybrid convolutional networks like mixed convolution neural network and covariance pooling (MCNN‐CP) algorithms. However, each has its advantages and limitations. To significantly avoid losing important spectral features, we proposed a new method by fusing a one‐dimensional convolutional neural network (1D‐CNN) with MCNN‐CP (1D‐MCNN‐CP), achieving an overall accuracy (97.44%) of mineral mapping from PRISMA HSIs. This research deduced that 1D‐MCNN‐CP improved performance and reduced misclassification errors among minerals sharing similar spectral features.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00009;jsessionid=72ev1rnmf9m8i.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Assessing the Utility of Uncrewed Aerial System Photogrammetrically Derived Point Clouds for Land Cover Classification in the Alaska North Slope
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 405-414(10)</div>
    <div>Authors: Liu, Jung-kuan; Qin, Rongjun; Arundel, Samantha T.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Uncrewed aerial systems (UASs) have been used to collect “pseudo field plot” data in the form of large-scale stereo imagery to supplement and bolster direct field observations to monitor areas in Alaska. These data supplement field data that is difficult to collect in such a vast landscape with a relatively short field season. Dense photogrammetrically derived point clouds are created and are facilitated to extract land cover data using a support vector machine (SVM) classifier in this study. We test our approach using point clouds derived from 1-cm stereo imagery of plots in the Alaska North Slope region and compare the results to field observations. The results show that the overall accuracy of six land cover classes (bare soil, shrub, grass, forb/herb, rock, and litter) is 96.8% from classified patches. Shrub had the highest accuracy (>99%) and forb/herb achieved the lowest (<48%). This study reveals that the approach could be used as reference data to check field observations in remote areas.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00010;jsessionid=72ev1rnmf9m8i.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Enhancing Forest‐Steppe Ecotone Mapping Accuracy through Synthetic ApertureRadar‐Optical Remote Sensing Data Fusion and Object-based Analysis
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 415-426(12)</div>
    <div>Authors: Wang, Ruilin; Wang, Meng; Sun, Xiaofang; Wang, Junbang; Li, Guicai</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In ecologically vulnerable regions with intricate land use dynamics, such as ecotones, frequent and intense land use transitions unfold. Therefore, the precise and timely mapping of land use becomes imperative. With that goal, by using principal component analysis, we integrated Sentinel-1 and Sentinel-2 data, using an object-oriented methodology to craft a 10-meter-resolution land use map for the forest‐grassland ecological zone of the Greater Khingan Mountains spanning the years 2019 to 2021. Our research reveals a substantial enhancement in classification accuracy achieved through the integration of synthetic aperture radar‐optical remote sensing data. Notably, our products outperformed other land use/land cover data sets, excelling particularly in delineating intricate riverine wetlands. The 10-meter land use product stands as a pivotal guide, offering indispensable support for sustainable development, ecological assessment, and conservation endeavors in the Greater Khingan Mountains region.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00011;jsessionid=p3kupcwais3p.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring an Ecosystem in Crisis: Measuring Seagrass Meadow Loss Using Deep Learning in Mosquito Lagoon, Florida
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 363-370(8)</div>
    <div>Authors: Insalaco, Stephanie A.; Herrero, Hannah V.; Limber, Russ; Oliver, Clancy; Wolfson, William B.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The ecosystem of Mosquito Lagoon, Florida, has been rapidly deteriorating since the 2010s, with a notable decline in keystone seagrass species. Seagrass is vital for many species in the lagoon, but nutrient overloading, algal blooms, boating, manatee grazing, and other factors have led to its loss. To understand this decline, a deep neural network analyzed Landsat imagery from 2000 to 2020. Results showed significant seagrass loss post-2013, coinciding with the 2011–2013 super algal bloom. Seagrass abundance varied annually, with the model performing best in years with higher seagrass coverage. While the deep learning method successfully identified seagrass, it also revealed that recent seagrass coverage is almost non-existent. This monitoring approach could aid in ecosystem recovery if coupled with appropriate policies for Mosquito Lagoon's restoration.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00012;jsessionid=p3kupcwais3p.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Real-Time Cross-View Image Matching and Camera Pose Determination for Unmanned Aerial Vehicles
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 371-381(11)</div>
    <div>Authors: Chen, Long; Wu, Bo; Duan, Ran; Chen, Zeyu</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In global navigation satellite systems (GNSS)-denied environments, vision-based methods are commonly used for the positioning and navigation of aerial robots. However, traditional methods often suffer from accumulative estimation errors over time, leading to trajectory drift and lack real-time performance, particularly in large-scale scenarios. This article presents novel approaches, including feature-based cross-view image matching and the integration of visual odometry and photogrammetric space resection for camera pose determination in real-time. Experimental evaluation with real UAV datasets demonstrated that the proposed method reliably matches features in cross-view images with large differences in spatial resolution, coverage, and perspective views, achieving a root-mean-square error of 4.7 m for absolute position error and 0.33° for rotation error, and delivering real-time performance of 12 frames per second (FPS) when implemented in a lightweight edge device onboard UAV. This approach offters potential for diverse intelligent UAV applications in GNSS-denied environments based on real-time feedback control.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00011;jsessionid=2egcj9ysx4uiw.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Investigation of Underwater Photogrammetry Method with Cost-Effective Action Cameras and Comparative Analysis between Reconstructed 3D Point Clouds
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 251-259(9)</div>
    <div>Authors: Hamal, Seda Nur Gamze; Ulvi, Ali</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Currently, digital cameras and equipment used underwater are often inaccessible to the general public due to their professional-grade quality and high cost. Therefore alternative solutions have been sought that are both cost-effective and suitable for nonprofessional use. A review of the literature shows that researchers primarily use GoPro action cameras, while other action cameras with similar capabilities are rarely used. This study thus examines underwater photogrammetry methods using a widely recognized action camera as a reference and compares it with another camera of similar characteristics as a potential alternative. For a comprehensive temporal analysis in underwater studies, both cameras were used to capture photographic and video imagery, and the resulting 3D point clouds were compared. Comparison criteria included data collection and processing times, point cloud densities, cloud-to-cloud analysis, and assessments of surface density and roughness. Having analysed, the study concluded that the proposed alternative action camera can feasibly be used in underwater photogrammetry.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00007;jsessionid=46jfkbfpu3h30.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Assessment, Specification, and Validation of a Geolocation System's Accuracy and Predicted Accuracy
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 157-168(12)</div>
    <div>Authors: Dolloff, John; Theiss, Henry; Bollin, Brian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This article presents recommendations and corresponding detailed procedures for the assessment of a geolocation system's accuracy, as well as the specification of accuracy requirements and their subsequent validation when they are available. Applicable metrics and related processing are based on samples of corresponding geolocation errors. This article also presents similar recommendations for the predicted accuracy of a geolocation system, based on samples of geolocation error, as well as corresponding predicted error covariance matrices associated with the geolocations. Reliable error covariance matrices enable optimal use of a geolocation system's products, such as the optimal fusion of multiple geolocations or multiple products for higher confidence and increased accuracy. The recommendations presented in this article enable reliable estimates of accuracy and reliable predicted accuracies, both of which are critical to many geolocation-based applications. The recommendations associated with predicted accuracy are also relatively new and innovative.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00009;jsessionid=2dhwhih9prlq0.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Sight-Aesthetic Value of the Underwater Landscapes of Lakes in the Context of Exploration Tourism
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 89-97(9)</div>
    <div>Authors: Dynowski, Piotr; Źróbek-Sokolnik, Anna; Czaplicka, Marta; Senetra, Adam</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The aim of the study is to identify factors affecting the sight-aesthetic value of the underwater landscapes of lakes for the purposes of exploration tourism. The reason for undertaking this topic is the lack of such studies for inland water bodies. The results will contribute to expanding and supplementing the knowledge on the assessment of the sight-aesthetic attractiveness of landscapes and fill gaps in knowledge about the underwater landscapes of lakes. The questionnaire survey implemented the direct comparison method described by Kendall (Kendall, M. G. 1970.Rank Correlation Methods. Charles Griffin and Co: Glasgow, Scotland). According to respondents, animals and submerged anthropogenic elements are the most visually attractive in an aquatic environment The results obtained are the reason for conducting further research and developing the methodology for the assessment of the sight-aesthetic value of inland bodies of water based on the experience of terrestrial landscape researchers.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00010;jsessionid=2dhwhih9prlq0.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Crop Monitoring System Using MODIS Time-Series Data for Within-Season Prediction of Yield and Production of US Corn and Soybeans
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 99-119(21)</div>
    <div>Authors: Sakamoto, Toshihiro</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In terms of contribution to global food security, this study aimed to build a crop monitoring system for within-season yield prediction of US corn and soybeans by using the Moderate Resolution Imaging Spectroradiometer (time-series data, which consists of three essential core algorithms (crop phenology detection, early crop classification, and crop yield prediction methods)). Within-season predictions for 2018–2022 were then made to evaluate the perfor- mance of the proposed system by comparing it with the United States Department of Agriculture's (USDA's) monthly forecasts and the fixed statistical data. The absolute percentage errors of the proposed system for predicting national-level yield and production were less than 5% for all simulation years as of day of year (DOY) 279. The prediction accuracy as of DOY 247 and DOY 279 were comparable to the USDA's forecasts. The proposed system would enable us to make a comprehensive understanding about overview of US corn and soybean crop condition by visualizing detail spatial pattern of good- or poor harvest regions on a within-season basis.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00008;jsessionid=18n7ind53d5f5.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Combination of Terrestrial Laser Scanning and Unmanned Aerial Vehicle Photogrammetry for Heritage Building Information Modeling: A Case Study of Tarsus St. Paul Church
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 753-760(8)</div>
    <div>Authors: Fidan, Şafak; Ulvi, Ali; Yiğit, Abdurahman Yasin; Hamal, Seda Nur Gamze; Yakar, Murat</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Cultural heritage building information modeling (HBIM) is an emerging process allowing us to reconstruct built heritage virtually. The data of a digitally documented cultural heritage building offers significant advantages as it is accessible and modifiable by all professionals involved in the same or different projects. The most important factor affecting the accuracy and precision of the HBIM model is the ability to collect complete and accurate information about the physical structure. Combining terrestrial laser scanning (TLS) and unmanned aerial vehicle (UAV) photogrammetry point clouds is one of the most efficient ways to capture accurate digital data on the building. This study provides the foundation for creating an HBIM model for cultural heritage the coupling of spatial data with TLS and UAV. This paper aims to generate synergy between TLS and UAV point cloud data and ensure that the spatial database contains sufficient data to model historical objects with HBIM tendencies.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00006;jsessionid=18nw75l096fsl.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Lotus Wetland Distribution with the Phenology Normalized Lotus Index Using SAR Time-Series Imagery and the Phenology-Based Method
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 601-611(11)</div>
    <div>Authors: Wang, Sheng; Wu, Taixia; Shen, Qiang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Lotus wetland is a type of wetland that can efficiently purify water. Therefore, rapid and accurate remote sensing monitoring of the distribution of lotus wetland has great significance to their conservation and the promotion of a sustainable and healthy development of ecosystems. The phenology-based method has proven effective in mapping some different types of wetlands. However, because of the serious absence of remote sensing data caused by cloud coverage and the differences in the phenological rhythms of lotus wetlands in different areas, achieving high-precision mapping of different regions using a unified approach is a challenge. To address the issue, this article proposes a Phenology Normalized Lotus Index (PNLI) model that combines SAR time-series imagery and the phenology-based method. The results of this study demonstrate that the PNLI model shows good applicability in different areas and has high mapping accuracy. The model can map the lotus wetland distribu tion in large areas quickly and simultaneously with high precision.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00007;jsessionid=18nw75l096fsl.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The FABDEM Outperforms the Global DEMs in Representing Bare Terrain Heights
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 613-624(12)</div>
    <div>Authors: Osama, Nahed; Shao, Zhenfeng; Freeshah, Mohamed</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Many remote sensing and geoscience applications require a high-precision terrain model. In 2022, the Forest And Buildings removed Copernicus digital elevation model (FABDEM) was released, in which trees and buildings were removed at a 30 m resolution. Therefore, it was necessary to make a comprehensive evaluation of this model. This research aims to perform a qualitative and quantitative analysis of fabdem in comparison with the commonly used global dems. We investigated the effect of the terrain slope, aspect, roughness, and land cover types in causing errors in the topographic representation of all dems. The fabdem had the highest overall vertical accuracy of 5.56 m. It was the best dem in representing the terrain roughness. The fabdem and Copernicus dem were equally influenced by the slopes more than the other models and had the worst accuracy of slope representation. In the tree, built, and flooded vegetation areas of the fabdem, the mean errors in elevation have been reduced by approximately 3.34 m, 1.26 m and 1.55 m, respectively. Based on Welch's t-test, there was no significant difference between fabdem and Copernicus dem elevations. However, the slight improvements in the fabdem make it the best filtered dem to represent the terrain heights over different land cover types.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00008;jsessionid=18nw75l096fsl.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Evaluating Surface Mesh Reconstruction Using Real Data
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 625-638(14)</div>
    <div>Authors: Marchand, Yanis; Caraffa, Laurent; Sulzer, Raphael; Clédat, Emmanuel; Vallet, Bruno</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Surface reconstruction has been studied thoroughly, but very little work has been done to address its evaluation. In this article, we propose new visibility-based metrics to assess the completeness and accuracy of three-dimensional meshes based on a point cloud of higher accuracy than the one from which the reconstruction has been computed. We use the position from which each high-quality point has been acquired to compute the corresponding ray of free space. Based on the intersections between each ray and the reconstructed surface, our metrics allow evaluating both the global coherency of the reconstruction and the accuracy at close range. We validate this evaluation protocol by surveying several open-source algorithms as well as a piece of licensed software on three data sets. The results confirm the relevance of assessi ng local and global accuracy separately since algorithms sometimes fail at guaranteeing both simultaneously. In addition, algorithms making use of sensor positions perform better than the ones relying only on points and normals, indicating a potentially significant added value of this piece of information. Our implementation is available at https://github.com/umrlastig/SurfaceReconEval.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000010/art00009;jsessionid=18nw75l096fsl.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Different Urbanization Levels Lead to Divergent Responses of Spring Phenology
        </a>
    </h3>
    <div style="font-style: italic;">October 2023, pp. 639-651(13)</div>
    <div>Authors: Dang, Chaoya; Shao, Zhenfeng; Huang, Xiao; Cheng, Gui; Qian, Jiaxin</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Urban vegetation phenology is important for understanding the relationship between human activities on urban ecosystems and carbon cycle. The relationship between urban and rural vegetation phenology and environmental and meteorological factors were studied across urban-rural gradients. However, the relationship of intra-urban urbanization intensity (UI) gradients on vegetation at the start of season (SOS) is unclear. Here, we used remote sensing data to quantitatively assess the relationship of vegetation SOS to UI gradients at mid-high latitudes in the northern hemisphere. The results showed that urban area vegetation SOS widely presented earlier than for rural area vegetation. Across the cities we investigated the extent UI gradient was prevalent as a threshold (33.2% ± 2.3%) of surface temperature to SOS advance enhancement and offset. At low urbanization enhanced surface temperature on sos advances, while at high urbanization offset surface temperature on SOS advances. Overall, UI demonstrated a nonlinear relationship with sos. The results of this study suggest that there may be thresholds of impact on vegetation SOS in future global climate and environment change processes, where opposite effects can occur below and above thresholds.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000009/art00005;jsessionid=2p4xbisuchewb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Effect of Latitude As a Significant Element on the Results of Direct UTM Coordinates Transformation Method
        </a>
    </h3>
    <div style="font-style: italic;">September 2023, pp. 533-536(4)</div>
    <div>Authors: Jassim, Mohammed Anwer; Mohammed, Darin Mohammed Tofiq</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The transformation of global navigation satellite systems coordi- nates between any two datums represents a vital procedure. Although the geocentric coordinates (X, Y, Z) of two datums can be trans- formed using the 7-parameters method, the conversion of Universal Transverse Mercator (UTM) projected coordinates (E, N) between two systems cannot be applied with the same procedure. However, see Jassim (2022), which discusses a method that allows the transformation between any two datums using the utm projected coordinates directly regarding the variation of the datum's semi-major axis and the eccentricity. The results of the evaluation of this method show that there is a significant shift in the transformed coordinates due to the imperfection of the used algorithm. While this research suggests a modification in the previous algorithm by adding the latitude's variation as a third significant factor besides the other two variations (∂a, ∂e2, and Δ), the suggested modification gives a high decline in the uncertainty of the position values. Furthermore, it takes a homogenous fixed limit for different places over Iraqi territory.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000009/art00006;jsessionid=2p4xbisuchewb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            CFAR Edge Detection Using Hysteresis Thresholding for Polarimetric SAR Imagery
        </a>
    </h3>
    <div style="font-style: italic;">September 2023, pp. 537-545(9)</div>
    <div>Authors: Niu, Chaoyang; Lu, Wanjie; Liu, Wei; Hu, Tao; Wang, Shiju; Wu, Yajie</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Edge detection is highly susceptible to streaking caused by speckles in polarimetric synthetic aperture radar (PolSAR) imagery. In this article, we address hysteresis thresholding for suppress streaking in PolSAR's edge detection. As an example, an approach is suggested by combining the constant false alarm ratio (CFAR) detector and the hysteresis thresholding. After thinning edges obtained by the CFAR detector, the hysteresis thresholding is employed to reduce edge streaking, which is caused by abundant speckles. A ratio of the high to the low threshold Pfain the hysteresis thresholding is pointed out for linking edges. Experiments are carried out on both simulated and real PolSAR data sets, and the results reveal that hysteresis thresh- olding obviously promotes the performance of the CFAR detector.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000009/art00007;jsessionid=2p4xbisuchewb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Leveraging NAIP Imagery for Accurate Large-Area Land Use/land Cover Mapping: A Case Study in Central Texas
        </a>
    </h3>
    <div style="font-style: italic;">September 2023, pp. 547-560(14)</div>
    <div>Authors: Subedi, Mukti Ram; Portillo-Quintero, Carlos; Kahl, Samantha S.; McIntyre, Nancy E.; Cox, Robert D.; Perry, Gad</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Large-area land use land cover (LULC) mapping using high-resolution imagery remains challenging due to radiometric differences between scenes, the low spectral depth of the imagery, landscape heterogeneity, and computational limitations. Using a random forest (RF)- supervised machine-learning algorithm, we present a geographic object-based image analysis approach to classifying a large mosaic of 220 National Agriculture Imagery Program orthoimagery into lulc categories. The approach was applied in central Texas, USA, covering over 6000 km2. We generated 36 variables for each object and accounted for spatial structures of sample data to determine the distance at which samples were spatially independent. The final rf model produced 94.8% accuracy on independent stratified random samples. In addition, vegetation and water indices, the mean and standard deviation of principal components, and texture features improved classification accuracy. This study demonstrates a cost-effective way of producing an accurate multi-class land use/land cover map using high-spatial/low-spectral resolution orthoimagery.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000009/art00008;jsessionid=2p4xbisuchewb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            DORSL-FIN: A Self-supervised Neural Network for Recovering Missing Bathymetry from ICESat-2
        </a>
    </h3>
    <div style="font-style: italic;">September 2023, pp. 561-575(15)</div>
    <div>Authors: Corcoran, Forrest; Parrish, Christopher E.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Bathymetric data, comprising elevations of submerged surfaces (e. g., seafloor or lake bed), constitute a critical need for a wide range of science and application focus areas, such as safety of marine navi- gation, benthic habitat mapping, flood inundation modeling, and coastal engineering. Over the past decade, the availability of near- shore bathymetric data has increased dramatically due to advances in satellite-derived bathymetry (SDB). One notable advance occurred with the 2018 launch of NASA's Ice, Cloud, and land Elevation Satellite 2 (ICESat-2), carrying the Advanced Topographic Laser Altimeter System (ATLAS). However, much like other Earth observing satellites, ATLAS is often hampered by obstructions, such as clouds, which block the sensor's view of the Earth's surface. In this study, we introduce the Deep Occlusion Recovery of Satellite Lidar From ICESat-2 Network (DORSL-FIN) to recover partially occluded bathymetric profiles. We show that DORSL-FIN is able to accurately recover occluded bathymetry and outperforms other methods of interpolation.
        </details>
    </div>
</article>
