<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000011/art00012;jsessionid=1dpb9j1r9kuki.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Landsat-Derived Rainfed and Irrigated-Area Product for Conterminous United States for the Year 2020 (LRIP30 CONUS 2020) Using Supervised and Unsupervised Machine Learning on the Cloud
        </a>
    </h3>
    <div style="font-style: italic;">November 2025, pp. 703-714(12)</div>
    <div>Authors: Teluguntla, Pardhasaradhi; Thenkabail, Prasad S.; Oliphant, Adam; Aneece, Itiya; Biggs, Trent; Gumma, Murali Krishna; Foley, Daniel; McCormick, Richard; Neelam, Rohitha; Long, Emerson; Lawton, Jake</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurate maps of irrigated and rainfed croplands are crucial for assessing global food and water security. Irrigated croplands yield two to four times more grain and biomass than rainfed croplands. To meet rising food demand, the proportion of cropland that is irrigated must be increased globally. Because agriculture uses 80% to 90% of global fresh water, understanding changes in cropland extent, crop type, and irrigation is critical for meeting nutritional needs sustainably. The United States has one of the most productive rainfed and irrigated croplands in the world and is a leading producer and exporter of agricultural crops. Precise maps of irrigated and rainfed croplands in the United States are crucial for assessing the current and the future agricultural production capacity in supporting food security. We developed a 30-m resolution rainfed and irrigated area map for the conterminous United States derived from 2019 to 2021 multi-date Landsat-8 data (LRIP30 CONUS 2020). A total of 96 harmonized spectral bands comprising monthly median value composites of eight bands (blue, green, red, NIR, SWIR1, SWIR2, TIR, and enhanced vegetation index [EVI]) were used. A cropland mask was then applied, and reference data were sourced from various sources. A pixel based supervised random forest classifier, and pixel based unsupervised ISODATA clustering classifier were implemented on Google Earth Engine and the ERDAS Imagine workstation to classify, identify, map, and assess accuracies of irrigated and rainfed cropland areas. The LRIP30 CONUS 2020 product achieved an overall accuracy of 93.9%. The irrigated and rainfed classes had producer's accuracies of 90.2% and 95.7%, respectively, and user's accuracies of 90.8% and 95.4%, respectively. The total net cropland area was estimated at 139.4 million hectares (Mha), of which 94.9 Mha (68%) was classified as rainfed and 44.5 Mha (32%) was classified as irrigated. State level summaries highlight regional differences and their implications for national and global food and water security.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00010;jsessionid=vaqc17161sia.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            MRTD-Based Effective Range Analysis of Airborne Infrared Imaging Systems for Ship Detection: Optimization of the Calculation for Operational Range Through an Improved MRTD Model
        </a>
    </h3>
    <div style="font-style: italic;">October 2025, pp. 623-630(8)</div>
    <div>Authors: Yan, Peng; Tian, Yuyang; Ling, Xiao; Zhu, Kaikai; Sheng, Qinghong; Wang, Bo; Li, Jun; Liu, Xiang; Xu, Xiao</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            When the airborne infrared imaging system detects ships, significant variations in environmental temperature are often observed. In the existing calculation models for the operating range, the factor of environmental temperature has not been taken into account. However, when the environmental temperature changes, it will affect the variation of the minimum resolvable temperature difference (MRTD) of the system, resulting in a relatively large deviation in the prediction of the operating range of the airborne infrared imaging system. To address this crucial technical challenge, this study systematically established the relationship formula of the MRTD under different temperatures. By integrating with the improved theoretical model of MRTD, a calculation method for the operating range that takes environmental temperature into consideration was developed to accurately determine the operating range of the airborne infrared imaging system. Comparative experimental studies focusing on ships show that, compared with traditional methods, the prediction deviation of the proposed method is significantly reduced, with an average reduction of 10.1%.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00011;jsessionid=vaqc17161sia.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Convolutional Neural Networks for Land Use and Land Cover Multi-class Maps from Historical Aerial Photographs
        </a>
    </h3>
    <div style="font-style: italic;">October 2025, pp. 631-645(15)</div>
    <div>Authors: Kostrzewa, Adam</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Historical maps that describe past land use and land cover (LULC) forms can be a precious source of information in many scientific fields studying long-term spatial and temporal changes in the landscape. Such repositories were created manually in small areas in the past, which was a time-consuming and labor-intensive task. Recently, there has been a growing tendency to use machine learning models for this purpose, along with deep learning methods. However, having a massive amount of labeled data is necessary for these methods to train the networks. Training data are often manually labeled, posing a significant challenge and limiting the automation of these methods. This article presents a method that uses topographic databases to extract complex multi-class maps representing LULC from historical aerial photographs, eliminating the time-consuming data labeling step. The method uses transfer learning with a pretrained model on 2020 and 2014 data and attempts to reconstruct LULC types with the same convolutional neural network (CNN) network on archived images from 2006. The experiment covered 488 km2and included seven LULC classes. The method was tested using different CNN architectures (U-Net, Pyramid Scene Parsing Network [PSPNet], and LinkNet) with backbones (ResNeXt+SE, EfficientNet, and Inception). The PSPNet‐EfficientNet‐b7 network model achieved the best results, with 90% overall accuracy for predicting LULC classes based on the 2006 archived aerial images.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00013;jsessionid=vaqc17161sia.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Thirty Years of the U.S. National Land Cover Database: Impacts and Future Direction
        </a>
    </h3>
    <div style="font-style: italic;">October 2025, pp. 647-659(13)</div>
    <div>Authors: Sohl, Terry; Jin, Suming; Dewitz, Jon; Wickham, James; Brown, Jesslyn; Stehman, Stephen; Herold, Nathaniel; Schleeweis, Karen; Tollerud, Heather; Deering, Carol</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The National Land Cover Database (NLCD), developed through the Multi-Resolution Land Characteristics Consortium, was initiated 30 years ago and has continually provided critical, Landsat-based landcover and land-change information for the United States. Originally launched to address the lack of national-scale, moderate-resolution land-cover data, NLCD has evolved from the pioneering 1992 dataset into a comprehensive, annually updated product suite. Key innovations include the introduction of impervious surface mapping, forest canopy mapping, standardized Landsat mosaics, national-scale accuracy assessments, continual evolution of deep learning and artificial intelligence methodologies, and a transition toward operational, change-focused monitoring. The NLCD has become an essential resource for scientific research, land management, and policy development, with extensive adoption across federal, state, and local agencies; academia; and the private sector. The NLCD data underpin a wide array of applications, including biodiversity conservation, urban planning, hydrology, human health studies, and natural hazard assessment. As new global and high-resolution commercial land-cover products emerge, the NLCD continues to distinguish itself through its temporal depth, federal backing, and thematic consistency. Moving forward, the NLCD will maintain its niche as the leading, moderate-resolution, long-term land-cover and land-change dataset for the United States, ensuring continued support for broad national applications while complementing higher-resolution and global-mapping efforts.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000008/art00013;jsessionid=6t82m5f3bdte.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Efficient Coral Survey Using Aerial Remote Sensing and Multi-modal Segmentation for Large-Scale Ecological Assessment
        </a>
    </h3>
    <div style="font-style: italic;">August 2025, pp. 509-516(8)</div>
    <div>Authors: Qin, Jiangying; Li, Ming; Armin, Gruen; Gong, Jianya; Zhong, Jiageng; Liao, Xuan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Due to the ecological pressures of global warming and human activities in coastal regions, coral reef ecosystems, predominantly located in shallow marine areas, are facing severe threats to their survival. Scientists and governmental managers are eager to leverage novel aerial remote sensing technologies to address the challenges of acquiring accurate, comprehensive, and timely data on coral reef health, structural complexity, and spatial distribution. This study aims to tackle these challenges by using precise and accurate aerial remote sensing data to support the restoration and sustainable prosperity of coral reef systems. Specifically, this study develops and applies an efficient coral survey method based on aerial remote sensing. The method integrates aerial imagery and bathymetric lidar (light detection and ranging) point cloud data and uses advanced photogrammetric computer vision and deep learning algorithms. Using a state-of-the-art multi-modal neural network segmentation technique, the proposed method enables high-precision and intelligent identification of coral reefs, facilitating detailed habitat mapping. Furthermore, by accurately delineating the habitat range and geometric structures of reefs, this approach allows for precise measurements of coral biomass production and skeletal calcification. These metrics help assess coral reef structural complexity and their adaptability to environmental stressors, providing robust scientific data for conservation strategies and policy making. The use of advanced multi-modal aerial remote sensing data not only enhances monitoring reliability and accuracy but also offers a cost-effective and flexible tool for coral reef ecological mapping. This approach effectively addresses challenges encountered in coastal ecological surveys, particularly in areas where direct human access or boat entry is difficult.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000008/art00014;jsessionid=6t82m5f3bdte.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            On the Transferability of Semantic Segmentation for Very-High-Resolution Remote Sensing Data of Multi-City Environments
        </a>
    </h3>
    <div style="font-style: italic;">August 2025, pp. 517-528(12)</div>
    <div>Authors: Qin, Rongjun; Zhang, Guixiang; Tang, Yang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Semantic segmentation of very-high-resolution remote sensing (RS) data is foundational for many RS applications in urban environments. Images from sources like Worldview-3/4 and Pleiades-Neo offer resolutions as high as 0.3 m, enabling a fine-grained understanding of urban structures. Recent deep learning‐based methods have significantly outperformed traditional approaches in RS semantic segmentation/classification tasks. However, they require large training data sets and often lack transferability due to highly disparate RS image content across different geographical regions. However, no comprehensive analysis exists on their transferability—i.e., to what extent a model trained on a source domain can be applied to a target domain in urban areas. This paper investigates the raw transferability of traditional and deep-learning models and the effectiveness of domain adaptation approaches in enhancing deep-learning model transferability (adapted transferability). Using five highly diverse RS data sets from different cities (6792 patches of 1024 × 1024 pixels each), we trained six models with and without three domain adaptation approaches to quantitatively analyze transferability between data sets. To facilitate easy assessment of model transferability, we developed a simple method to quantify transferability using spectral indices as a medium, demonstrating its effectiveness in evaluating model transferability at the target domain when labels are unavailable. Our experiments yield several important but underreported observations on raw and adapted transferability. Moreover, our proposed label-free transferability assessment method outperforms posterior model confidence and can guide model selection for urban studies globally. The models and datasets are publicly available on GitHub at: https://github.com/GDAOSU/Transferability-Remote-Sensing.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00010;jsessionid=3n93fr74ci1up.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Combined Use of Satellite Observations and the RIM for Assessing Recovery from Natural Disasters
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 407-417(11)</div>
    <div>Authors: Cao, Changyong; Wang, Wenhui; Bai, Yan; Shao, Xi; Uprety, Sirish; Qiu, Hong-Lie</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In this study, we explore using satellite observations to assess community recovery from natural disasters such as fires and hurricanes, supplementing the Resilience Inference Model (RIM). The RIM model has been successfully used to quantify recoveries from hurricanes along the Gulf Coast, but it relies on long-term population changes over years or decades. Our approach integrates satellite observations to enhance recovery assessment with a shorter latency of weeks or months. Using fire, vegetation, and night light data from the Visible Infrared Imaging Radiometer Suite (VIIRS) with daily global observations, Sentinel-2, Landsat-8, and Geostationary Operational Environmental Satellite/Advanced Baseline Imager, we quantitatively evaluate fire intensity, light outage, and urban greenness changes, along with subsequent recovery, focusing on the 2023 Maui fire and selected hurricane cases along the Gulf Coast. This approach complements the RIM model by introducing quantifiable physical parameters with shorter latency, particularly beneficial in areas where census data are either unavailable or unreliable.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000007/art00017;jsessionid=3n93fr74ci1up.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spatiotemporal Continuous Shallow Water Bathymetry from a Kriged Kalman Filter
        </a>
    </h3>
    <div style="font-style: italic;">July 2025, pp. 463-471(9)</div>
    <div>Authors: Wang, Lei; Liu, Hongxing; Kang, Lei; Su, Haibin; Shu, Song; Wang, Jun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In GIScience, problems of missing data in space or time are nontrivial. We implemented a Kriged Kalman filter (KKF)‐based data interpolation and assimilation technique and tested it for mapping bathymetry at unsampled locations and times. This technique integrates the Kriging and Kalman filter computation frameworks to perform spatiotemporal data assimilation, which can produce spatially and temporally continuous bathymetric fields from samples that are scarce in space and time. The spatiotemporal bathymetric field over the estuary of the Yangtze River was mapped based on the four boat-based depth echo-sounding surveys conducted in 1982, 1997, 2002, and 2010. Our validation and verification analyses showed that the KKF assimilation model can predict bathymetry accurately and reliably at unsampled locations and times. This paper demonstrates that KKF is superior to traditional spatial interpolation methods because it informs the interpolator with the temporal component that also extends the prediction to the time domain. The experiments indicate that greater time intervals in conducting bathymetric surveys result in a more pronounced influence on the performance of KKF than the spatial sparsity of depth samples. The ability of space-time prediction of bathymetry allows underwater depth measurements to be accurately aligned with satellite images, which is essential for improving multispectral image inversion in bathymetry studies.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006/art00014;jsessionid=1cs6gpzx3ohxi.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A High-Quality Underwater 3D Reconstruction Solution for Coral Reef Environments Leveraging Advanced Photogrammetric Computer Vision Techniques
        </a>
    </h3>
    <div style="font-style: italic;">June 2025, pp. 361-370(10)</div>
    <div>Authors: Zhong, Jiageng; Li, Ming; Gruen, Armin; Liao, Xuan; Qin, Jiangying; Wang, Bing</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Coral reefs, with their intricate 3D structures, are vital marine ecosystems increasingly threatened by environmental stressors. Accurate 3D reconstruction of these underwater structures is essential for scientific research and conservation management. While underwater photogrammetry has emerged as a promising tool for this purpose, technical challenges persist in capturing fine-scale features under underwater conditions, particularly the intricate morphology of coral reefs and the highly complex textures that hinder high-fidelity reconstruction. Recent breakthroughs in computer vision and deep learning have introduced new opportunities for underwater photogrammetry. This study begins by outlining a photogrammetric workflow that can integrate current advanced technologies, followed by summarizing cutting-edge methods used in the key stages, i. e., sparse and dense reconstruction. Building on previous research, we propose a hierarchical reconstruction strategy for accurate and efficient dense modeling. Our approach first performs an efficient global coarse-grained reconstruction to capture the overall scene structure, followed by fine-scale modeling in key regions of interest. Using image data collected from a coral reef site at Moorea Island, we compare and evaluate various techniques, analyzing their respective strengths and limitations. In sparse reconstruction, the classical feature method scale-invariant feature transform demonstrates competitive performance. Deep learning–based methods, such as ALIKED feature and the SuperGlue matching network, achieve superior results on certain metrics. For dense reconstruction, Neural Radiance Fields and 3D Gaussian Splatting–based methods yield high-quality reconstructions but are computationally intensive. In contrast, the deep learning–based multi-view stereo approach achieves comparable reconstruction quality with greater efficiency. Experimental results on reconstruction result fusion further validate that our approach offers a scalable and practical solution for coral reef monitoring, advancing conservation science and ecosystem management practices.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000005/art00013;jsessionid=hro50x59mege.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Improving Crop Classification by Integrating Phenology Using Random Forests: Assessing the Role of Feature Selection
        </a>
    </h3>
    <div style="font-style: italic;">May 2025, pp. 307-318(12)</div>
    <div>Authors: Jiangwei, Hu; Jingye, Shi; Jiqiang, Liu; Guolong, Guo; Jiadong, Jin</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The increase of satellite images with high spatial resolution, short revisit period, and wide spatial coverage has brought an enormous amount of data; however, limited efforts have been made in feature selection for crop classification. Furthermore, different crop types have unique spectral, spatial, and phenological characteristics that have not been well understood and fully used for the expected results. This study established a crop-classification framework using the random forest model by integrating four types of features (i. e., spectral reflectance features, vegetation index features, spatial texture features, and crop phenological features) over 15 scenarios generated from Sentinel-2 images. The random forest model performed best (overall accuracy = 92.86%; Kappa coefficient = 0.8995) by integrating the four types of features. We systematically assessed the contribution of feature combinations on individual crop classification. Specifically, different feature combinations can effectively improve the recognition accuracy of different crop types. Our findings can provide great potential in choosing optimal features for crop classifications and benefit the application of machine learning in remote sensing–based crop mapping.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000004/art00009;jsessionid=upfylc8h4xq1.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Sat2building: Lod-2 Building Reconstruction from Satellite Imagery Using Spatial Embeddings
        </a>
    </h3>
    <div style="font-style: italic;">April 2025, pp. 203-212(10)</div>
    <div>Authors: Schuegraf, Philipp; Gui, Shengxi; Qin, Rongjun; Fraundorfer, Friedrich; Bittner, Ksenia</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The reconstruction of buildings in level of detail–2, according to the CityGML standard, is an essential feature in applications such as urban planning, environmental simulations, and virtual reality. Existing methods work primarily only on aerial data, depend on an external digital terrain model, or do not accurately separate individual buildings. In this work, we present SAT2BUILDING, a method that predicts roof planes, building sections, and building heights in a single, fully convolutional neural network. The network relies on only orthorectified panchromatic imagery and a photogrammetric digital surface model. The three outputs are jointly processed in a level of detail–2 reconstruction pipeline that generates building models that are seamlessly connected, geometrically accurate and complete, and topologically correct. We use spatial embeddings that enable accurate segmentation of building sections and roof planes from satellite imagery. The model generalizes to data from Bonn, Germany, and Lyon, France, after being trained on data from Berlin, Germany. The training and test data differ in lighting conditions, architectural styles, and ground sampling distances. Thorough comparative evaluation shows the superiority of SAT2BUILDING over three baseline methods.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000003/art00011;jsessionid=4noee7c1rchp1.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Comparative Study of Deep Learning Methods for Automated Road Network Extraction from High-Spatial-Resolution Remotely Sensed Imagery
        </a>
    </h3>
    <div style="font-style: italic;">March 2025, pp. 163-174(12)</div>
    <div>Authors: Zhou, Haochen; He, Hongjie; Xu, Linlin; Ma, Lingfei; Zhang, Dedong; Chen, Nan; Chapman, Michael A.; Li, Jonathan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Road network data are crucial for various applications, such as road network planning, traffic control, map navigation, autonomous driving, and smart city construction. Automated road network extraction from high-spatial-resolution remotely sensed imagery has shown promise in road network data construction. In recent years, the advent of deep learning algorithms has pushed road network extraction towards auto - mation, achieving very high accuracy. However, the latest deep learning models are often less applied in the field of road network extraction and lack comparative experiments for guidance. Therefore, this research selected three recent deep learning algorithms, including dense prediction transformer (DPT), SegFormer, SEgmentation TRansformer (SETR), and the classic model fully convolutional network-8s (FCN-8s) for a comparative study. Additionally, this research paper compares three different decoder structures within the SETR model (SETR_naive, SETR_mla, SETR_pup) to investigate the effect of different decoders on the road network extraction task. The experiment is conducted on three commonly used datasets: the DeepGlobe Dataset, the Massachusetts Dataset, and Road Datasets in Complex Mountain Environments (RDCME). The DPT model outperforms other models on the Massachusetts dataset with superior reliability, achieving a high accuracy of 96.31% and excelling with a precision of 81.78% and recall of 32.50%, leading to an F1 score of 46.51%. While SegFormer has a slightly higher F1 score, DPT's precision is particularly valuable for minimizing false positives, making it the most balanced and reliable choice. Similarly, for the DeepGlobe Dataset, DPT achieves an accuracy of 96.76%, precision of 66.12%, recall of 41.37%, and F1 score of 50.89%, and for RDCME, DPT achieves an accuracy of 98.94%, precision of 99.07%, recall of 99.84%, and F1 score of 99.46%, confirming its consistent performance across datasets. This paper provides valuable guidance for future studies on road network extraction techniques using deep learning algorithms.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000002/art00010;jsessionid=fpl59pidi3k6.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Artificial Neural Network Multi-layer Perceptron Models to Classify California's Crops using Harmonized Landsat Sentinel (HLS) Data
        </a>
    </h3>
    <div style="font-style: italic;">February 2025, pp. 91-100(10)</div>
    <div>Authors: McCormick, Richard; Thenkabail, Prasad S.; Aneece, Itiya; Teluguntla, Pardhasaradhi; Oliphant, Adam J.; Foley, Daniel</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Advances in remote sensing and machine learning are enhancing cropland classification, vital for global food and water security. We used multispectral Harmonized Landsat 8 Sentinel-2 (HLS) 30-m data in an artificial neural network (ANN) multi-layer perceptron (MLP) model to classify five crop classes (cotton, alfalfa, tree crops, grapes, and others) in California's Central Valley. The ANN MLP model, trained on 2021 data from the United States Department of Agriculture's Cropland Data Layer, was validated by classifying crops for an independent year, 2022. Across the five crop classes, the overall accuracy was 74%. Producer's and user's accuracies ranged from 65% to 87%, with cotton achieving the highest accuracies. The study highlights the potential of using deep learning with HLS time series data for accurate global crop classification.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00010;jsessionid=qec3cqonmmho.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring LULC Changes in Babil Province for Sustainable Development Purposes Within the Period 2004–2023
        </a>
    </h3>
    <div style="font-style: italic;">December 2024, pp. 745-753(9)</div>
    <div>Authors: Jassoom, Hayder Hameed; Abdoon, Rabab Saadoon</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Land use and land cover studies are fundamental to achieving sustainable development goals by providing the information necessary for informed decision-making in social and economic development and natural resource management. This study relied on remote sensing data to analyze and assess land use and land cover changes in Babil Province, Iraq, over the past two decades. The study focused on identifying the patterns and factors influencing these changes, using Landsat satellite imagery to create digital maps classifying land into four main categories: urban lands, bare soil lands, water bodies, and vegetation lands. The results showed a noticeable expansion of urban lands at the expense of bare soil lands, primarily attributed to population growth, economic development, and improved security conditions. This study underscores the importance of sustainable land management and urban planning in Babil Province. These results highlight the importance of sustainable land management in Babil Province, including sound urban planning considering urban expansion's environmental, social, and economic effects. The classification was implemented using a maximum likelihood classifier, and the accuracy assessment yielded satisfactory results with an overall accuracy of 93.5517%. This study encourages using artificial intelligence to track and analyze land use changes in Babil.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00012;jsessionid=qec3cqonmmho.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Image Fusion in Remote Sensing: An Overview and Meta-Analysis
        </a>
    </h3>
    <div style="font-style: italic;">December 2024, pp. 755-775(21)</div>
    <div>Authors: Albanwan, Hessah; Qin, Rongjun; Tang, Yang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Remote sensing image fusion is consistently used to turn raw images of different resolutions, sources, and modalities into accurate, complete, and spatiotemporally coherent images. It facilitates downstream applications such as pan sharpening, change detection, and classification. However, image fusion solutions are highly disparate to various remote sensing problems and are often narrowly defined in existing reviews as topical applications (e. g., pan sharpening). Theoretically, image fusion can be applied to any gridded data through pixel-level operations; thus, we expand its scope by comprehensively surveying relevant works. We develop a simple taxonomy for many-to-one and many-to-many image fusion, defining it as a mapping problem turning one or multiple images into another set based on desired coherence. Furthermore, we provide a meta-analysis to cover 10,420 peer-reviewed papers from the 1980s to 2023 studying various types of image fusion and their applications. Finally, we discuss image fusion's benefits and emerging challenges to provide open research directions.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000011/art00012;jsessionid=1goqofb4r5a61.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Machine Learning and New-Generation Spaceborne Hyperspectral Data Advance Crop Type Mapping
        </a>
    </h3>
    <div style="font-style: italic;">November 2024, pp. 687-698(12)</div>
    <div>Authors: Aneece, Itiya; Thenkabail, Prasad S.; McCormick, Richard; Alifu, Haireti; Foley, Daniel; Oliphant, Adam J.; Teluguntla, Pardhasaradhi</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Hyperspectral sensors provide near-continuous spectral data that can facilitate advancements in agricultural crop classification and characterization, which are important for addressing global food and water security issues. We investigated two new-generation hyperspectral sensors, Germany’s Deutsches Zentrum für Luft‐ und Raumfahrt Earth Sensing Imaging Spectrometer (DESIS) and Italy’s PRecursore IperSpettrale della Missione Applicativa (PRISMA), within California's Central Valley in August 2021 focusing on five irrigated agricultural crops (alfalfa, almonds, corn, grapes, and pistachios). With reference data from the U.S. Department of Agriculture Cropland Data Layer, we developed a spectral library of the crops and classified them using three machine learning algorithms (support vector machines [SVM], random forest [RF], and spectral angle mapper [SAM]) and two philosophies: 1. Full spectral analysis (FSA) and 2. Optimal hyperspectral narrowband (OHNB) analysis. For FSA, we used 59 DESIS four-bin product bands and 207 of 238 PRISMA bands. For OHNB analysis, 9 DESIS and 16 PRISMA nonredundant OHNBs for studying crops were selected. FSA achieved only 1% to 3% higher accuracies relative to OHNB analysis in most cases. SVM provided the best results, closely followed by RF. Using both DESIS and PRISMA image OHNBs in SVM for classification led to higher accuracy than using either image alone, with an overall accuracy of 99%, producer’s accuracies of 94% to 100%, and user???s accuracies of 95% to 100%.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000010/art00013;jsessionid=8dkk6lodchm17.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Bank Line Extraction by Integration of Orthoimages and Lidar Digital Elevation Model Using Principal Component Analysis and Alpha Matting
        </a>
    </h3>
    <div style="font-style: italic;">October 2024, pp. 631-638(8)</div>
    <div>Authors: Deshpande, Sagar S.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Riverbank lines change over time, causing loss of land and property. Accurate mapping of riverbank lines is essential for restoration and preservation. This paper presents a method to map riverbank lines by combining georeferenced orthoimages and lidar digital elevation model (DEM). This method uses the properties that lidar can provide elevations under trees and open water edges are visible in orthoimages to extract the planimetric locations of bank lines. The orthoimage pixels with less than 0.15% slope on the DEM were replaced by water pixels. Principal component analysis (PCA) was conducted using DEM, slope, and orthoimage bands. Training data of river body and the background were identified manually on the first three component images. An alpha matting–based method was implemented using the training data to extract the bank lines. Bankline using α value of 50% probability were statistically and visually better when compared to the manual bank lines.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00007;jsessionid=3v85444i676g.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Research Progress of Optical Satellite Remote Sensing Monitoring Asphalt Pavement Aging
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 471-482(12)</div>
    <div>Authors: Wang, Jingwen; Yang, Dayong; Xie, Zhiwei; Wang, Han; Hao, Zhigang; Zhou, Fanyu; Wang, Xiaona</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The aging condition of asphalt pavement is an invaluable basis for traffic infrastructure evaluation. Due to the amount of time and high cost of monitoring and identifying asphalt pavement aging, many current studies focus on satellite remote sensing methods. In this paper, some methods and technologies for monitoring asphalt pavement degradation by optical satellite remote sensing are introduced as a literature review. Many researchers have developed spectrum libraries based on the actual aging of asphalt pavements, and it is possible to construct pavement health indices based on spectrum changes. Some indexes can extract different aging degrees of asphalt pavement from optical satellite images. Of course, current research can only preliminarily reflect the aging phenomenon of asphalt pavement and cannot accurately describe the distress characteristics of asphalt pavement. Future research needs to further strengthen mechanism research, develop higher resolution images, improve image processing technology, and adopt multi-means fusion analysis methods.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00008;jsessionid=3v85444i676g.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Winter Wheat Using Ensemble‐Based Positive Unlabeled Learning Approach
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 483-491(9)</div>
    <div>Authors: Wang, Hanxiang; Yu, Fan; Xie, Junwei; Wan, Huawei; Zheng, Haotian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            High‐resolution remote sensing images can support machine learning methods to achieve remarkable results in agricultural monitoring. However, traditional supervised learning methods require pre-labeled training data and are unsuitable for non-fully labeled areas. Positive and Unlabeled Learning (PUL), can deal with unlabeled data. A loss function PU-Loss was proposed in this study to directly optimize the PUL evaluation metric and to address the data imbalance problem caused by unlabeled positive samples. Moreover, a hybrid normalization module Batch Instance-Layer Normalization was proposed to perform multiple normalization methods based on the resolution size and to improve the model performance further. A real‐world positive and unlabeled winter wheat data set was used to evaluate the proposed method, which outperformed widely used models such as U‐Net, DeepLabv3+, and DA‐Net. The results demonstrated the potential of PUL for winter wheat identification in remote sensing images.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00010;jsessionid=3v85444i676g.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Building Shadow Detection Based on Improved Quick Shift Algorithm in GF‐2 Images
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 493-502(10)</div>
    <div>Authors: Chen, Yunzhi; Wang, Chao; Wang, Wei; Zhang, Xiang; Chen, Nengcheng</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Shadows in remote sensing images contain crucial information about various features on the ground. In this study, a method for detecting building shadows in GF‐2 images based on improved quick shift was proposed. First, six feature variables were constructed: first principal component (PC1), brightness component (I), normalized difference shadow index (NDSI), morphological shadow index (MSI), normalized difference water index (NDWI), and normalized difference vegetation index (NDVI). Then, the image was segmented to obtain homogeneous objects, which were then classified using a random forest model. Two improvements were added to the quick shift algorithm: using PC1, I, and MSI as input data instead of RGB images; and adding Canny edge constraints. Validation in six research areas yields Kappa coefficients of 0.928, 0.896, 0.89, 0.913, 0.879, and 0.909, confirming method feasibility. In addition, comparative experiments demonstrate its effectiveness and robustness across different land cover types while mitigating the segmentation scale effect.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00011;jsessionid=3v85444i676g.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Hyperspectral Reflectance Assessment for Preliminary Identification of Degraded Soil Zones in Industrial Sites, India
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 503-509(7)</div>
    <div>Authors: Dutta, Amitava; Tyagi, Rashi; Sharma, Shilpi; Datta, Manoj</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The study explores the potential of next-generation satellite hyperspectral imaging systems for screening and predicting surface‐soil contamination and degradation by exploiting various spectral indices and signature‐matching techniques at a heavily industrialized area in India. The soil moisture content, desertification and salinity status, clay or fine material content, heavy metal content, vegetation health status, and stress levels were assessed from continuum-removed spectral reflectance values. Results indicated the presence of water in two tailings ponds, high salinity, and desertification values in most of the tailings ponds and dump sites, clay boundary liner along four ponds, high heavy metal indices along three ponds and all dump sites, highly stressed vegetation near all tailings ponds and coal dump sites, and pollutants in nearby water channels. The results suggest a strategy for the initial identification of priority areas for ground-based investigations and an alternative rapid methodology to monitor large industrial hubs in India.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000008/art00014;jsessionid=3v85444i676g.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            One-Dimensional-Mixed Convolution Neural Network and Covariance Pooling Model for Mineral Mapping of Porphyry Copper Deposit Using PRISMA Hyperspectral Data
        </a>
    </h3>
    <div style="font-style: italic;">August 2024, pp. 511-522(12)</div>
    <div>Authors: Peyghambari, Sima; Zhang, Yun; Heidarian, Hassan; Sekandari, Milad</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Mapping distribution of alterations around porphyry copper deposits (PCDs) greatly affects mineral exploration. Diverse geological processes generate irregular alteration patterns with diverse spectral characteristics in mineral deposits. Applying remotely sensed hyperspectral images (HSIs) is an appealing technology for geologic surveyors to generate alteration maps. Conventional methods mainly use shallow spectral absorption features to discriminate minerals and cannot extract their important spectral information. Deep neural networks with nonlinear layers can evoke the deep spectral and spatial information of HSIs. Deep learning-based methods include fully connected neural networks, convolutional neural networks, and hybrid convolutional networks like mixed convolution neural network and covariance pooling (MCNN‐CP) algorithms. However, each has its advantages and limitations. To significantly avoid losing important spectral features, we proposed a new method by fusing a one‐dimensional convolutional neural network (1D‐CNN) with MCNN‐CP (1D‐MCNN‐CP), achieving an overall accuracy (97.44%) of mineral mapping from PRISMA HSIs. This research deduced that 1D‐MCNN‐CP improved performance and reduced misclassification errors among minerals sharing similar spectral features.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00007;jsessionid=6onbkapujahnd.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            ReLAP-Net: Residual Learning and Attention Based Parallel Network for Hyperspectral and Multispectral Image Fusion
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 395-403(9)</div>
    <div>Authors: Agrawal, Aditya; SourajaKundu; Ahmad, Touseef; Bhatt, Manish</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Remote sensing applications require high-resolution images to obtain precise information about the Earth???s surface. Multispectral images have high spatial resolution but low spectral resolution. Hyperspectral images have high spectral resolution but low spatial resolution. This study proposes a residual learning and attention-based parallel network based on residual network and channel attention. The network performs image fusion of a high spatial resolution multispectral image and a low spatial resolution hyperspectral image. The network training and fusion experiments are conducted on four public benchmark data sets to show the effectiveness of the proposed model. The fusion performance is compared with classical signal processing-based image fusion techniques. Four image metrics are used for the quantitative evaluation of the fused images. The proposed network improved fusion ability by reducing the root mean square error and relative dimensionless global error in synthesis and increased the peak signal-to-noise ratio when compared to other state-of-the-art models.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00009;jsessionid=6onbkapujahnd.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Assessing the Utility of Uncrewed Aerial System Photogrammetrically Derived Point Clouds for Land Cover Classification in the Alaska North Slope
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 405-414(10)</div>
    <div>Authors: Liu, Jung-kuan; Qin, Rongjun; Arundel, Samantha T.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Uncrewed aerial systems (UASs) have been used to collect “pseudo field plot” data in the form of large-scale stereo imagery to supplement and bolster direct field observations to monitor areas in Alaska. These data supplement field data that is difficult to collect in such a vast landscape with a relatively short field season. Dense photogrammetrically derived point clouds are created and are facilitated to extract land cover data using a support vector machine (SVM) classifier in this study. We test our approach using point clouds derived from 1-cm stereo imagery of plots in the Alaska North Slope region and compare the results to field observations. The results show that the overall accuracy of six land cover classes (bare soil, shrub, grass, forb/herb, rock, and litter) is 96.8% from classified patches. Shrub had the highest accuracy (>99%) and forb/herb achieved the lowest (<48%). This study reveals that the approach could be used as reference data to check field observations in remote areas.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00010;jsessionid=6onbkapujahnd.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Enhancing Forest‐Steppe Ecotone Mapping Accuracy through Synthetic ApertureRadar‐Optical Remote Sensing Data Fusion and Object-based Analysis
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 415-426(12)</div>
    <div>Authors: Wang, Ruilin; Wang, Meng; Sun, Xiaofang; Wang, Junbang; Li, Guicai</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In ecologically vulnerable regions with intricate land use dynamics, such as ecotones, frequent and intense land use transitions unfold. Therefore, the precise and timely mapping of land use becomes imperative. With that goal, by using principal component analysis, we integrated Sentinel-1 and Sentinel-2 data, using an object-oriented methodology to craft a 10-meter-resolution land use map for the forest‐grassland ecological zone of the Greater Khingan Mountains spanning the years 2019 to 2021. Our research reveals a substantial enhancement in classification accuracy achieved through the integration of synthetic aperture radar‐optical remote sensing data. Notably, our products outperformed other land use/land cover data sets, excelling particularly in delineating intricate riverine wetlands. The 10-meter land use product stands as a pivotal guide, offering indispensable support for sustainable development, ecological assessment, and conservation endeavors in the Greater Khingan Mountains region.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00011;jsessionid=6onbkapujahnd.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Dynamic Monitoring of Ecological Quality in Eastern Ukraine Amidst the Russia‐Ukraine Conflict
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 427-435(9)</div>
    <div>Authors: Zhang, Chaofei; Xu, Zhanghua; Yang, Yuanyao; Sun, Lei; Li, Haitao</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            To evaluate the spatiotemporal changes in the ecological environment of eastern Ukraine since the Russia-Ukraine conflict, this study used MODIS images from March to September 2020 and 2022 to calculate the Remote Sensing-Based Ecological Index. In 2022, compared with 2020, conflict zones exhibited reduced improvement and increased slight degradation, whereas nonconflict areas showed marginal enhancement. Through propensity score matching, the research confirmed the causal relationship between conflict and ecological trends. Pathway analysis revealed that the conflict contributed to 0.016 units increase in ecological quality while reducing the improvement rate by 0.042 units. This study provides empirical support for understanding the correlation between conflicts and specific environmental factors, offering technical references for ecological quality assessments in other conflict areas and future evaluations by the Ukrainian government.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000007/art00013;jsessionid=6onbkapujahnd.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Surface Water Extraction Method Integrating Spectral and Temporal Characteristics
        </a>
    </h3>
    <div style="font-style: italic;">July 2024, pp. 437-450(14)</div>
    <div>Authors: Zou, Yebin</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Remote sensing has been applied to observe large areas of surface water to obtain higher-resolution and long-term continuous observation records of surface water. However, limitations remain in the detection of large-scale and multi-temporal surface water mainly due to the high variability in water surface signatures in space and time. In this study, we developed a surface water remote sensing information extraction model that integrates spectral and temporal characteristics to extract surface water from multi-dimensional data of long-term Landsat scenes to explore the spatiotemporal changes in surface water over decades. The goal is to extract open water in vegetation, clouds, terrain shadows, and other land cover backgrounds from medium-resolution remote sensing images. The average overall accuracy and average kappa coefficient of the classification were verified to be 0.91 and 0.81, respectively. Experiments applied to China’s inland arid area have shown that the method is effective under complex surface environmental conditions.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00006;jsessionid=1hq0plffjk0bt.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Real-Time Semantic Segmentation of Remote Sensing Images for Land Management
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 335-343(9)</div>
    <div>Authors: Zhang, Yinsheng; Ji, Ru; Hu, Yuxiang; Yang, Yulong; Chen, Xin; Duan, Xiuxian; Shan, Huilin</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Remote sensing image segmentation is a crucial technique in the field of land management. However, existing semantic segmentation networks require a large number of floating-point operations (FLOPs) and have long run times. In this paper, we propose a dual-path feature aggregation network (DPFANet) specifically designed for the low-latency operations required in land management applications. Firstly, we use four sets of spatially separable convolutions with varying dilation rates to extract spatial features. Additionally, we use an improved version of MobileNetV2 to extract semantic features. Furthermore, we use an asymmetric multi-scale fusion module and dual-path feature aggregation module to enhance feature extraction and fusion. Finally, a decoder is constructed to enable progressive up-sampling. Experimental results on the Potsdam data set and the Gaofen image data set (GID) demonstrate that DPFANet achieves overall accuracy of 92.2% and 89.3%, respectively. The FLOPs are 6.72 giga and the number of parameters is 2.067 million.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00007;jsessionid=1hq0plffjk0bt.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Land Use Change in the Yangtze River Economic Belt during 2010 to 2020 and Future Comprehensive Prediction Based on Markov and ARIMA Models
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 345-354(10)</div>
    <div>Authors: Zheng, Haotian; Yu, Fan; Wan, Huawei; Shi, Peirong; Wang, Haonan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The key data for accurate prediction is of great significance to accurately carry out the next step of sustainable land use development plan according to the demand of China. Consequently, the main purposes of our study are: (1) to delineate the characteristics of land use transitions within the Yangtze River Economic Belt; (2) to use the Markov model and the autoregressive integrated moving average (ARIMA) model for comparative analysis and prediction of land use distribution. This study analyzes land use/cover change (LUCC) data from 2010 and 2020 using the land use transition matrix, dynamic degree, and comprehensive index model and predicts 2025 land use by the Markov model. The study identifies a reduction in land usage over 11 years, particularly in grassland. The Markov and ARIMA models' significance is 0.002 (P < 0.01), showing arable land and woodland dominance, with varying changes in other land types.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00009;jsessionid=1hq0plffjk0bt.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Improved YOLO Network for Insulator and Insulator Defect Detection in UAV Images
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 355-361(7)</div>
    <div>Authors: Zhou, Fangrong; Liu, Lifeng; Hu, Hao; Jin, Weishi; Zheng, Zezhong; Li, Zhongnian; Ma, Yi; Wang, Qun</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The power grid plays a vital role in the construction of livelihood projects by transmitting electrical energy. In the event of insulator explosions on power grid towers, these insulators may detach, presenting potential safety risks to transmission lines. The identification of such failures relies on the examination of images captured by unmanned aerial vehicles (UAVs). However, accurately detecting insulator defects remains challenging, particularly when dealing with variations in size. Existing methods exhibit limited accuracy in detecting small objects. In this paper, we propose a novel detection method that incorporates the convolutional block attention module (CBAM) as an attention mechanism into the backbone of the "you only look once" version 5 (YOLOv5) model. Additionally, we integrate a residual structure into the model to learn additional information and features related to insulators, thereby enhancing detection efficiency. Experimental results demonstrate that our proposed method achieved F1 scores of 0.87 for insulator detection and 0.89 for insulator defect detection. The improved YOLOv5 network shows promise in detecting insulators and their defects in UAV images.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00011;jsessionid=1hq0plffjk0bt.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring an Ecosystem in Crisis: Measuring Seagrass Meadow Loss Using Deep Learning in Mosquito Lagoon, Florida
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 363-370(8)</div>
    <div>Authors: Insalaco, Stephanie A.; Herrero, Hannah V.; Limber, Russ; Oliver, Clancy; Wolfson, William B.</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The ecosystem of Mosquito Lagoon, Florida, has been rapidly deteriorating since the 2010s, with a notable decline in keystone seagrass species. Seagrass is vital for many species in the lagoon, but nutrient overloading, algal blooms, boating, manatee grazing, and other factors have led to its loss. To understand this decline, a deep neural network analyzed Landsat imagery from 2000 to 2020. Results showed significant seagrass loss post-2013, coinciding with the 2011–2013 super algal bloom. Seagrass abundance varied annually, with the model performing best in years with higher seagrass coverage. While the deep learning method successfully identified seagrass, it also revealed that recent seagrass coverage is almost non-existent. This monitoring approach could aid in ecosystem recovery if coupled with appropriate policies for Mosquito Lagoon's restoration.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000006/art00012;jsessionid=1hq0plffjk0bt.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Real-Time Cross-View Image Matching and Camera Pose Determination for Unmanned Aerial Vehicles
        </a>
    </h3>
    <div style="font-style: italic;">June 2024, pp. 371-381(11)</div>
    <div>Authors: Chen, Long; Wu, Bo; Duan, Ran; Chen, Zeyu</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In global navigation satellite systems (GNSS)-denied environments, vision-based methods are commonly used for the positioning and navigation of aerial robots. However, traditional methods often suffer from accumulative estimation errors over time, leading to trajectory drift and lack real-time performance, particularly in large-scale scenarios. This article presents novel approaches, including feature-based cross-view image matching and the integration of visual odometry and photogrammetric space resection for camera pose determination in real-time. Experimental evaluation with real UAV datasets demonstrated that the proposed method reliably matches features in cross-view images with large differences in spatial resolution, coverage, and perspective views, achieving a root-mean-square error of 4.7 m for absolute position error and 0.33° for rotation error, and delivering real-time performance of 12 frames per second (FPS) when implemented in a lightweight edge device onboard UAV. This approach offters potential for diverse intelligent UAV applications in GNSS-denied environments based on real-time feedback control.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00007;jsessionid=5i43ke3phl443.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Pixel Texture Index Algorithm and Its Application
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 277-292(16)</div>
    <div>Authors: Sun, Xiaodan; Sun, Xiaofang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Image segmentation is essential for object-oriented analysis, and classification is a critical parameter influencing analysis accuracy. However, image classification and segmentation based on spectral features are easily perturbed by the high-frequency information of a high spatial resolution remotely sensed (HSRRS) image, degrading its classification and segmentation quality. This article first presents a pixel texture index (PTI) by describing the texture and edge in a local area surrounding a pixel. Indeed.. The experimental results highlight that the HSRRS image classification and segmentation quality can be effectively improved by combining it with the PTI image. Indeed, the overall accuracy improved from 7% to 14%, and the kappa can be increased from 11% to 24%, respectively.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00008;jsessionid=5i43ke3phl443.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Parcel-Level Crop Classification in Plain Fragmented Regions Based on Multi-Source Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 293-302(10)</div>
    <div>Authors: Zhang, Qiao; Luo, Ziyi; Shen, Yang; Wang, Zhoufeng</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurately obtaining crop cultivation extent and estimating the cultivated area are significant for adjusting regional planting structure. This article proposes a parcel-level crop classification method using time-series, medium-resolution, remote sensing images and single-phase, high-spatial-resolution, remote sensing images. The deep learning semantic segmentation network feature pyramid network with squeeze-and-excitation network (FPN-SENet) and multi-scale segmentation were used to extract cultivated land parcels from Gaofen-2 imagery, while the pixel-level crop types were classified by using support vector machine algorithms from time-series Sentinel-2 images. Then, the parcel-level crop classification was obtained from the pixel-level crop types and land parcels.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00009;jsessionid=5i43ke3phl443.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Evaluation of SMAP and CYGNSS Soil Moistures in Drought Prediction Using Multiple Linear Regression and GLDAS Product
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 303-312(10)</div>
    <div>Authors: Edokossi, Komi; Jin, Shuanggen; Calabia, Andres; Molina, Iñigo; Mazhar, Usman</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Drought is a devastating natural hazard and exerts profound effects on both the environment and society. Predicting drought occurrences is significant in aiding decision-making and implementing effective mitigation strategies. In regions characterized by limited data availability, such as Southern Africa, the use of satellite remote sensing data promises an excellent opportunity for achieving this predictive goal. In this article, we assess the effectiveness of Soil Moisture Active Passive (SMAP) and Cyclone Global Navigation Satellite System (CYGNSS) soil moisture data in predicting drought conditions using multiple linear regression-predicted data and Global Land Data Assimilation System (GLDAS) soil moisture data.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000005/art00010;jsessionid=5i43ke3phl443.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Debris Flow Susceptibility Evaluation Based on Multi-level Feature Extraction CNN Model: A Case Study of Nujiang Prefecture, China
        </a>
    </h3>
    <div style="font-style: italic;">May 2024, pp. 313-323(11)</div>
    <div>Authors: Wang, Xu; Wang, Baoyun; Yuan, Ruohao; Luo, Yumeng; Liu, Cunxi</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Debris flow susceptibility evaluation plays a crucial role in the prevention and control of debris flow disasters. Therefore, this article proposes a convolutional neural network model named multi-level feature extraction network (MFENet). First, a dual-channel CNN architecture incorporating the Embedding Channel Attention mechanism is used to extract shallow features from both digital elevation model images and multispectral images. Subsequently, channel shuffle and feature concatenation are applied to the features from the two channels to obtain fused feature sets. Following this, a deep feature extraction is performed on the fused feature sets using a residual module improved by maximum pooling. Finally, the susceptibility index of gullies to debris flows is calculated based on the similarity scores.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00008;jsessionid=aanf9q6dae9t.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Using Improved YOLOv5 and SegFormer to Extract Tailings Ponds from Multi-Source Data
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 223-231(9)</div>
    <div>Authors: Sun, Zhenhui; Xu, Ying; Wang, Dongchuan; Meng, Qingyan; Sun, Yunxiao</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This paper proposes a framework that combines the improved "You Only Look Once" version 5 (YOLOv5) and SegFormer to extract tailings ponds from multi-source data. Points of interest (POIs) are crawled to capture potential tailings pond regions. Jeffries–Matusita distance is used to evaluate the optimal band combination. The improved YOLOv5 replaces the backbone with the PoolFormer to form a PoolFormer backbone. The neck introduces the CARAFE operator to form a CARAFE feature pyramid network neck (CRF-FPN). The head is substituted with an efficiency decoupled head. POIs and classification data optimize improved YOLOv5 results. After that, the SegFormer is used to delineate the boundaries of tailings ponds. Experimental results demonstrate that the mean average precision of the improved YOLOv5s has increased by 2.78% compared to the YOLOv5s, achieving 91.18%. The SegFormer achieves an intersection over union of 88.76% and an accuracy of 94.28%.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00009;jsessionid=aanf9q6dae9t.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            GDP Spatialization in City of Zhengzhou Based on NPP/VIIRS Night-time Light and Socioeconomic Statistical Data Using Machine Learning
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 233-240(8)</div>
    <div>Authors: Ullah, Inam; Li, Weidong; Meng, Fanqian; Nadeem, Muhammad Imran; Ahmed, Kanwal</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This article introduces a comprehensive methodology for mapping and assessing the urban built-up areas and establishing a spatial gross domestic product (GDP) model for Zhengzhou using night-time light (NTL) data, alongside socioeconomic statistical data from 2012 to 2017. Two supervised sorting algorithms, namely the support vector machine (SVM) algorithm and the deep learning (DL) algorithm, which includes the U-Net and fully convolutional neural (FCN) network models, are proposed for urban built-up area identification and image classification. Comparisons with Municipal Bureau of Statistics data highlight the U-Net neural network model exhibits superior accuracy, especially in areas with diverse characteristics. For each year from 2012 to 2017, a spatial GDP model was developed based on Zhengzhou's urban GDP and U-Net sorted images. This research provides valuable insights into urban development and economic assessment for the city.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00010;jsessionid=aanf9q6dae9t.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring Based on InSAR for the Xinmo Village Landslide in Western Sichuan, China
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 243-249(7)</div>
    <div>Authors: Zheng, Zezhong; Yu, Shuang; Xie, Chuhang; Yang, Jiali; Zhu, Mingcang; He, Yong</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            A devastating landslide incident occurred on 24 June 2017, causing huge losses for Xinmo Village in western Sichuan. In this paper, we used two interferometric synthetic aperture radar (InSAR) methods, permanent scatterer (PS)-InSAR and small baseline subset (SBAS)- InSAR, to analyze deformation signals in the area in the 2 years leading up to the landslide event using Sentinel-1A ascending data. Our experimental findings from PS-InSAR and SBAS-InSAR revealed that the deformation rates in the study region ranged between –50 to 20 mm/year and –30 to 10 mm/year, respectively. Furthermore, the deformation rates of the same points, as determined by these methods, exhibited a significant increase prior to the event. We also investigated the causal relationship between rainfall and landslide events, demonstrating that deformation rates correlate with changes in rainfall, albeit with a time lag. Therefore, using time-series InSAR for landslide monitoring in Xinmo Village is a viable approach.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000004/art00011;jsessionid=aanf9q6dae9t.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Investigation of Underwater Photogrammetry Method with Cost-Effective Action Cameras and Comparative Analysis between Reconstructed 3D Point Clouds
        </a>
    </h3>
    <div style="font-style: italic;">April 2024, pp. 251-259(9)</div>
    <div>Authors: Hamal, Seda Nur Gamze; Ulvi, Ali</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Currently, digital cameras and equipment used underwater are often inaccessible to the general public due to their professional-grade quality and high cost. Therefore alternative solutions have been sought that are both cost-effective and suitable for nonprofessional use. A review of the literature shows that researchers primarily use GoPro action cameras, while other action cameras with similar capabilities are rarely used. This study thus examines underwater photogrammetry methods using a widely recognized action camera as a reference and compares it with another camera of similar characteristics as a potential alternative. For a comprehensive temporal analysis in underwater studies, both cameras were used to capture photographic and video imagery, and the resulting 3D point clouds were compared. Comparison criteria included data collection and processing times, point cloud densities, cloud-to-cloud analysis, and assessments of surface density and roughness. Having analysed, the study concluded that the proposed alternative action camera can feasibly be used in underwater photogrammetry.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00006;jsessionid=6speb4sembctb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Scan Angle Analysis of Airborne Lidar Data for Missing Return Approximation in Urban Areas
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 143-154(12)</div>
    <div>Authors: Gharibi, Hamid; Habib, Ayman</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The density and uniformity of lidar data play crucial roles in the cor-responding data processing steps. One factor influencing point density and spacing in lidar data is the presence of empty pulses, where no return is detected. Missing returns can occur due to atmospheric absorption, specular and diffusive reflection, etc. To address this issue and enhance point density, this paper introduces a novel method for approximating missing returns in airborne lidar data collected over urban areas. This technique focuses on approximating returns for empty pulses that hit spots near abrupt slope changes on building and ground surfaces. The proposed methodology is validated through experiments using a lidar data set from downtown Dublin, Ireland. The collected data contained numerous gaps associated with wet surfaces, as well as missing returns on vertical and oblique surfaces.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00007;jsessionid=6speb4sembctb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Assessment, Specification, and Validation of a Geolocation System's Accuracy and Predicted Accuracy
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 157-168(12)</div>
    <div>Authors: Dolloff, John; Theiss, Henry; Bollin, Brian</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            This article presents recommendations and corresponding detailed procedures for the assessment of a geolocation system's accuracy, as well as the specification of accuracy requirements and their subsequent validation when they are available. Applicable metrics and related processing are based on samples of corresponding geolocation errors. This article also presents similar recommendations for the predicted accuracy of a geolocation system, based on samples of geolocation error, as well as corresponding predicted error covariance matrices associated with the geolocations. Reliable error covariance matrices enable optimal use of a geolocation system's products, such as the optimal fusion of multiple geolocations or multiple products for higher confidence and increased accuracy. The recommendations presented in this article enable reliable estimates of accuracy and reliable predicted accuracies, both of which are critical to many geolocation-based applications. The recommendations associated with predicted accuracy are also relatively new and innovative.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00008;jsessionid=6speb4sembctb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Keyframe Extraction Approach for 3D Videogrammetry Based on Baseline Constraints
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 171-180(10)</div>
    <div>Authors: Liu, Xinyi; Hu, Qingwu; Huang, Xianfeng</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In this paper, we propose a novel approach for the extraction of high-quality frames to enhance the fidelity of videogrammetry by combining fuzzy frames removal and baseline constraints. We first implement a gradient-based mutual information method to filter out low-quality frames while preserving the integrity of the videos. After frame pose estimation, the geometric properties of the baseline are constrained by three aspects to extract the keyframes: quality of relative orientation, baseline direction, and base to distance ratio. The three-dimensional model is then reconstructed based on these extracted keyframes. Experimental results demonstrate that our approach maintains a strong robustness throughout the aerial triangulation, leading to high levels of reconstruction precision across diverse video scenarios. Compared to other methods, this paper improves the reconstruction accuracy by more than 0.2 mm while simultaneously maintaining the completeness.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000003/art00009;jsessionid=6speb4sembctb.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Extraction of Terraces in Hilly Areas from Remote Sensing Images Using DEM and Improved U-Net
        </a>
    </h3>
    <div style="font-style: italic;">March 2024, pp. 181-188(8)</div>
    <div>Authors: Peng, Fengcan; Peng, Qiuzhi; Chen, Di; Lu, Jiating; Song, Yufei</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            To extract terraced fields in hilly areas on a large scale in an automated and high-precision manner, this paper proposes a terrace extraction method that combines the Digital Elevation Model (DEM), Sentinel-2 imagery, and the improved U-Net semantic segmentation model. The U-Net model is modified by introducing Attention Gate modules into its decoding modules to suppress the interference of redundant features and adding Dropout and Batch Normalization layers to improve training speed, robustness, and fitting ability. In addition, the DEM band is combined with the red, green, and blue bands of the remote sensing images to make full use of terrain information. The experimental results show that the Precision, Recall, F1 score, and Mean Intersection over Union of the proposed method for terrace extraction are improved to other mainstream advanced methods, and the internal information of the terraces extracted is more complete, with fewer false positive and false negative results.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00008;jsessionid=h61h35ljsbtki.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Remote Sensing Application in Water Quality of Lake Burdur, Türkiye
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 85-87(3)</div>
    <div>Authors: Kokal, Aylin Tuzcu; Kacikoc, Meltem; Musaoglu, Nebiye; Tanik, Aysegul</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The advancements in space technology have facilitated water quality (WQ) monitoring of lake conditions at a spatial resolution of 10 m by freely accessible Sentinel-2 images. The main aim of this article was to elucidate the necessity of spatiotemporal WQ monitoring of the shrinking Lake Burdur in Türkiye by examining the relation between field and satellite data with a state-of-the-art machine learning- based regression algorithm. This study focuses on detection of algal blooms and WQ parameters, which are chlorophyll-a (Chl-a) and suspended solids (SS). Furthermore, this study leverages the advantage of geographic position of Lake Burdur, located at the overlap of two Sentinel-2 frames, which enables the acquisition of satellite images at a temporal resolution of 2–3 days. The findings enrich the understanding of the lake's dynamic structure by rapidly monitoring the occurrence of algal blooms. High accuracies were achieved for Chl-a (R-squared: 0.93) and SS (R-squared: 0.94) detection.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00009;jsessionid=h61h35ljsbtki.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Sight-Aesthetic Value of the Underwater Landscapes of Lakes in the Context of Exploration Tourism
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 89-97(9)</div>
    <div>Authors: Dynowski, Piotr; Źróbek-Sokolnik, Anna; Czaplicka, Marta; Senetra, Adam</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            The aim of the study is to identify factors affecting the sight-aesthetic value of the underwater landscapes of lakes for the purposes of exploration tourism. The reason for undertaking this topic is the lack of such studies for inland water bodies. The results will contribute to expanding and supplementing the knowledge on the assessment of the sight-aesthetic attractiveness of landscapes and fill gaps in knowledge about the underwater landscapes of lakes. The questionnaire survey implemented the direct comparison method described by Kendall (Kendall, M. G. 1970.Rank Correlation Methods. Charles Griffin and Co: Glasgow, Scotland). According to respondents, animals and submerged anthropogenic elements are the most visually attractive in an aquatic environment The results obtained are the reason for conducting further research and developing the methodology for the assessment of the sight-aesthetic value of inland bodies of water based on the experience of terrestrial landscape researchers.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00010;jsessionid=h61h35ljsbtki.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Crop Monitoring System Using MODIS Time-Series Data for Within-Season Prediction of Yield and Production of US Corn and Soybeans
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 99-119(21)</div>
    <div>Authors: Sakamoto, Toshihiro</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            In terms of contribution to global food security, this study aimed to build a crop monitoring system for within-season yield prediction of US corn and soybeans by using the Moderate Resolution Imaging Spectroradiometer (time-series data, which consists of three essential core algorithms (crop phenology detection, early crop classification, and crop yield prediction methods)). Within-season predictions for 2018–2022 were then made to evaluate the perfor- mance of the proposed system by comparing it with the United States Department of Agriculture's (USDA's) monthly forecasts and the fixed statistical data. The absolute percentage errors of the proposed system for predicting national-level yield and production were less than 5% for all simulation years as of day of year (DOY) 279. The prediction accuracy as of DOY 247 and DOY 279 were comparable to the USDA's forecasts. The proposed system would enable us to make a comprehensive understanding about overview of US corn and soybean crop condition by visualizing detail spatial pattern of good- or poor harvest regions on a within-season basis.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000002/art00011;jsessionid=h61h35ljsbtki.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Few-Shot Semi-Supervised Learning Method for Remote Sensing Image Scene Classification
        </a>
    </h3>
    <div style="font-style: italic;">February 2024, pp. 121-125(5)</div>
    <div>Authors: Zhu, Yuxuan; Li, Erzhu; Su, Zhigang; Liu, Wei; Samat, Alim; Liu, Yu</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Few-shot scene classification methods aim to obtain classification discriminative ability from few labeled samples and has recently seen substantial advancements. However, the current few-shot learning approaches still suffer from overfitting due to the scarcity of labeled samples. To this end, a few-shot semi-supervised method is proposed to address this issue. Specifically, semi-supervised learning method is used to increase target domain samples; then we train multiple classification models using the augmented samples. Finally, we perform decision fusion of the results obtained from the multiple models to accomplish the image classification task. According to the experiments conducted on two real few-shot remote sensing scene datasets, our proposed method achieves significantly higher accuracy (approximately 1.70% to 4.33%) compared to existing counterparts.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00007;jsessionid=fvwaargdn5h5.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Terrain Complexity and Maximal Poisson-Disk Sampling-Based Digital Elevation Model Simplification
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 13-20(8)</div>
    <div>Authors: Dong, Jingxian; Ming, Fan; Kabika, Twaha; Jiang, Jiayao; Zhang, Siyuan; Chervan, Aliaksandr; Natallia, Zhukouskaya; Hou, Wenguang</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            With the rapid development of lidar, the accuracy and density of the Digital Elevation Model (DEM) point clouds have been continuously improved. However, in some applications, dense point cloud has no practical meaning. How to effectively sample from the dense points and maximize the preservation of terrain features is extremely important. This paper will propose a DEM sampling algorithm that utilizes terrain complexity and maximal Poisson-disk sampling to extract key feature points for adaptive DEM sampling. The algorithm estimates terrain complexity based on local terrain variation and prioritizes points with high complexity for sampling. The sampling radius is inversely proportional to terrain complexity, while ensuring that points within the radius of accepted samples are not considered new samples. This way makes more points of concern in the rugged regions. The results show that the proposed algorithm has higher global accuracy than the classic six sampling methods.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00008;jsessionid=fvwaargdn5h5.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            I2-FaçadeNet: An Illumination-invariant Façade Recognition Network Leveraging Sparsely Gated Mixture of Multi-color Space Experts for Aerial Oblique Imagery
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 21-31(11)</div>
    <div>Authors: Huang, Shengzhi; Hu, Han; Zhu, Qing</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Façade image recognition under complex illumination conditions is crucial for various applications, including urban three-dimensional modeling and building identification. Existing methods relying solely on Red-Green-Blue (RGB) images are prone to texture ambiguity in complex illumination environments. Furthermore, façades display varying orientations and camera viewing angles, resulting in performance issues within the RGB color space. In this study, we introduce an illumination-invariant façade recognition network (I2-FaçadeNet) that leverages sparsely gated multi-color space experts for enhanced façade image recognition in challenging illumination environments. First, RGB façade images are converted into multi-color spaces to eliminate the ambiguous texture in complex illumination. Second, we train expert networks using separate channels of multi-color spaces. Finally, a sparsely gated mechanism is introduced to manage the expert networks, enabling dynamic activation of expert networks and the merging of results. Experimental evaluations leveraging both the International Society for Photogrammetry and Remote Sensing benchmark data sets and the Shenzhen data sets reveal that our proposed I2-FaçadeNet surpasses various depths of ResNet in façade recognition under complex illumination conditions. Specifically, the classification accuracy for poorly illuminated façades in Zurich improves by nearly 8%, while the accuracy for over-illuminated areas in Shenzhen increases by approximately 3%. Moreover, ablation studies conducted on façade images with complex illumination indicate that compared to traditional RGB-based ResNet, the proposed network achieves an accuracy improvement of 3% to 4% up to 100% for overexposed images and an accuracy improvement of 3% to 10% for underexposed images.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00009;jsessionid=fvwaargdn5h5.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Development of Soil-Suppressed Impervious Surface Area Index for Automatic Urban Mapping
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 33-43(11)</div>
    <div>Authors: Javed, Akib; Shao, Zhenfeng; Ara, Iffat; Ahmad, Muhammad Nasar; Huq, Md.Enamul; Saleem, Nayyer; Karim, Fazlul</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Expanding urban impervious surface area (ISA) mapping is crucial to sustainable development, urban planning, and environmental studies. Multispectral ISA mapping is challenging because of the mixed-pixel problems with bare soil. This study presents a novel approach using spectral and temporal information to develop a Soil-Suppressed Impervious Surface Area Index (SISAI) using the Landsat Operational Land Imager (OLI) data set, which reduces the soil but enhances the ISA signature. This study mapped the top 12 populated megacities using SISAI and achieved an over-all accuracy of 0.87 with an F1-score of 0.85. It also achieved a higher Spatial Dissimilarity Index between the ISA and bare soil. However, it is limited by bare gray soil and shadows of clouds and hills. SISAI encourages urban dynamics and inter-urban compari- son studies owing to its automatic and unsupervised methodology.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00010;jsessionid=fvwaargdn5h5.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Dual-branch Branch Networks Based on Contrastive Learning for Long-Tailed Remote Sensing
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 45-53(9)</div>
    <div>Authors: Zhang, Lei; Peng, Lijia; Xia, Pengfei; Wei, Chuyuan; Yang, Chengwei; Zhang, Yanyan</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Deep learning has been widely used in remote sensing image classification and achieves many excellent results. These methods are all based on relatively balanced data sets. However, in real-world scenarios, many data sets belong to the long-tailed distribution, resulting in poor performance. In view of the good performance of contrastive learning in long-tailed image classification, a new dual-branch fusion learning classification model is proposed to fuse the discriminative features of remote sensing images with spatial data, making full use of valuable image representation information in imbalance data. This paper also presents a hybrid loss, which solves the problem of poor discrimination of extracted features caused by large intra-class variation and inter-class ambiguity. Extended experiments on three long-tailed remote sensing image classification data sets demonstrate the advantages of the proposed dual-branch model based on contrastive learning in long-tailed image classification.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000001/art00011;jsessionid=fvwaargdn5h5.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Comparison of 3D Point Cloud Completion Networks for High Altitude Lidar Scans of Buildings
        </a>
    </h3>
    <div style="font-style: italic;">January 2024, pp. 55-64(10)</div>
    <div>Authors: Kulawiak, Marek</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            High altitude lidar scans allow for rapid acquisition of big spatial data representing entire city blocks. Unfortunately, the raw point clouds acquired by this method are largely incomplete due to object occlusions and restrictions in scanning angles and sensor resolution, which can negatively affect the obtained results. In recent years, many new solutions for 3D point cloud completion have been created and tested on various objects; however, the application of these methods to high-altitude lidar point clouds of buildings has not been properly investigated yet. In the above context, this paper presents the results of applying several state-of-the-art point cloud completion networks to various building exteriors acquired by simulated airborne laser scanning. Moreover, the output point clouds generated from partial data are compared with complete ground-truth point clouds. The performed tests show that the SeedFormer network trained on the ShapeNet-55 data set provides promising shape completion results.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00006;jsessionid=eibexnjpwwt4.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            IMU and Bluetooth Data Fusion to Achieve Submeter Position Accuracy in Indoor Positioning
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 735-740(6)</div>
    <div>Authors: Acar, Ugur</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Indoor navigation applications have become widespread in recent years with the ability of mobile phones which determine the position. Due to the inefficiency of global positioning system (GPS) indoors, other positioning methods have been developed based on local networks using technologies such as Bluetooth, wireless networks, ultra-wideband signals, ultrasonic signals, and radio frequency identification modules. Various technologies yield high or medium accuracy. Combining data from multiple sources via fusion enhances location precision. In this study, indoor positions were estimated using trilateration with Bluetooth devices, and the accuracy was improved by applying filters to the data from inertial measurement unit (IMU) sensors on the phone. As a result of combining Bluetooth and IMU data with data fusion, submeter accuracy was achieved. The results obtained were tested at Yildiz Technical University-Istanbul Türkiye. It was determined that 92% of the data was obtained with submeter accuracy.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00007;jsessionid=eibexnjpwwt4.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Rice Identification Under Complex Surface Conditions with CNN and Integrated Remote Sensing Spectral-Temporal-Spatial Features
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 741-752(12)</div>
    <div>Authors: Liu, Tianjiao; Duan, Sibo; Chen, Jiankui; Zhang, Li; Li, Dong; Li, Xuqing</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Accurate and effective rice identification has great significance for the sustainable development of agricultural management and food security. This paper proposes an accurate rice identification method that can solve the confused problem between fragmented rice fields and the surroundings in complex surface areas. The spectral, temporal, and spatial features extracted from the created Sentinel-2 time series were integrated and collaboratively displayed in the form of visual images, and a convolutional neural network model embedded with integrated information was established to further mine the key information that distinguishes rice from other types. The results showed that the overall accuracy, precision, recall, and F1-score of the proposed method for rice identification reached 99.4%, 99.5%, 99.5%, and 99.5%, respectively, achieving a better performance than the support vector machine classifier. Therefore, the proposed method can effectively reduce the confusion between rice and other types and accurately extract rice distribution information under complex surface conditions.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00008;jsessionid=eibexnjpwwt4.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Combination of Terrestrial Laser Scanning and Unmanned Aerial Vehicle Photogrammetry for Heritage Building Information Modeling: A Case Study of Tarsus St. Paul Church
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 753-760(8)</div>
    <div>Authors: Fidan, Şafak; Ulvi, Ali; Yiğit, Abdurahman Yasin; Hamal, Seda Nur Gamze; Yakar, Murat</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Cultural heritage building information modeling (HBIM) is an emerging process allowing us to reconstruct built heritage virtually. The data of a digitally documented cultural heritage building offers significant advantages as it is accessible and modifiable by all professionals involved in the same or different projects. The most important factor affecting the accuracy and precision of the HBIM model is the ability to collect complete and accurate information about the physical structure. Combining terrestrial laser scanning (TLS) and unmanned aerial vehicle (UAV) photogrammetry point clouds is one of the most efficient ways to capture accurate digital data on the building. This study provides the foundation for creating an HBIM model for cultural heritage the coupling of spatial data with TLS and UAV. This paper aims to generate synergy between TLS and UAV point cloud data and ensure that the spatial database contains sufficient data to model historical objects with HBIM tendencies.
        </details>
    </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2023/00000089/00000012/art00009;jsessionid=eibexnjpwwt4.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Quantifying Impacts of Regional Multiple Factors on Spatiotemporal the Mechanisms for Spatio-temporal changes of Net Primary Vegetation Productivity and Net Ecosystem Productivity: An Example in the Jianghuai River Basin, China
        </a>
    </h3>
    <div style="font-style: italic;">December 2023, pp. 761-771(11)</div>
    <div>Authors: Chen, Huimin; Wang, Benlin; Zheng, Liangfeng; Shahtahmassebi, ZhengAmirReza</div>
    <div>
        Abstract: 
        <details>
            <summary style="color: #1b5faa;">Read more...</summary>
            Despite much valuable research on the mechanisms for spatio-temporal changesof net primary vegetation productivity (NPP) and net ecosystem productivity (NEP), there is a paucity of information on assessing impacts of regional multiple factors on spatiotemporal researchs of NPP and NEP in the complex environment. This study attempts to bridge this information gap using the Jianghuai Basin in China as a case study. Using a field campaign, remotely sensed imagery, socioeconomic data, and meteorological parameters, we developed a framework based on the Carnegie‐Ames‐Stanford Approach (CASA) model, correlation technique, trend analysis, and landscape metrics to measure spatiotemporal changes in NPP and NEP from 2001 to 2018. The derived changes were then linked to regional multiple factors including climate, landscape factors, human activity, and land use change. The results of the research can provide a scientific basis for vegetation evaluation, ecosystem assessment, and other aspects of the region.
        </details>
    </div>
</article>
