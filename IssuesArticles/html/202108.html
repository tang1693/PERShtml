
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 08 - Year 2021</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 08 - Year 2021</h1>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000008/art00003;jsessionid=hxwj92064v9m.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Semi-Centennial of Landsat Observations & Pending Landsat 9 Launch
        </a>
    </h3>
    <div style="font-style: italic;">202108, pp. 533-539(7)</div>
    <div>Authors: Goward, Samuel N.; Masek, Jeffrey G.; Loveland, Thomas R.; Dwyer, John L.; Williams, Darrel L.; Arvidson, Terry; Rocchio, Laura E.P.; Irons, James R.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The first Landsat was placed in orbit on 23 July 1972, followed by a series of missions that have provided nearly continuous, two-satellite 8-day repeat image coverage of the Earth's land areas for the last half-century. These observations have substantially enhanced our understanding of the Earth's terrestrial dynamics, both as a major element of the Earth's physical system, the primary home of humans, and the major source of resources that support them. The history of Landsat is complex, reflective of the human systems that sustain it. Despite the conflicted perspectives surrounding the continuation of the program, Landsat has survived based on worldwide recognition of its critical contributions to understanding land dynamics, management of natural resources and Earth system science. Launch of Landsat 9 is anticipated in Fall 2021, and current planning for the next generation, Landsat Next is well underway. The community of Landsat data users is looking forward to another 50 years of the Landsat program.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000008/art00009;jsessionid=hxwj92064v9m.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spinor-Based Attitude Determination with Star Sensor Considering Depth
        </a>
    </h3>
    <div style="font-style: italic;">202108, pp. 551-556(6)</div>
    <div>Authors: Sheng, Qinghong; Ren, Rui; Xu, Weilan; Xiao, Hui; Wang, Bo; Hong, Ran</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A star sensor is a high-precision satellite attitude measurement device. Since its observation information has only two-dimensional direction vectors, when a star sensor is used for attitude determination the dimension of the observation information is less than the number of attitude angles determined, so mainstream algorithms usually only guarantee the accuracy of the pitch angle and the roll angle. In view of the lack of depth information in the observation's imaging geometric condition, this article proposes a spinor-based attitude determination model, which describes a straight line passing through two stars with the spinor and maps the depth information of the straight line with the pitch, to establish an imaging geometry model of the spinor coplanar condition. Experiments show that the yaw-angle attitude accuracy of the method is an order of magnitude better than that of mainstream algorithms, and the accuracy of the three attitude angles reaches the arc-second level.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000008/art00010;jsessionid=hxwj92064v9m.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Digital Building-Height Preparation from Satellite Stereo Images
        </a>
    </h3>
    <div style="font-style: italic;">202108, pp. 557-566(10)</div>
    <div>Authors: Prakash, P.S.; Aithal, Bharath H.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Buildings are considered prominent objects for understanding the pattern of growth in an urban setting. Remote sensing technology plays a vital role in facilitating data generation pertaining to various urban applications. Digital surface models represent the elevation of the earth surface features, and can be obtained from stereo images, radar, laser scanning, and so on. Photogrammetric techniques applied to optical stereo satellite images are economical and fast ways to generate height information of buildings. In this work, a quantitative and qualitative analysis of digital surface models generated from Cartosat-1 stereo images is compared with openly available data. The study finds that it is possible to acquire about 50 percent of building heights with acceptable error limits. The experimental results indicate that the quality of height information is suitable for applications to assess urban development at a macro scale, but not for individual building-level modeling.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000008/art00011;jsessionid=hxwj92064v9m.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Enhanced Lunar Topographic Mapping Using Multiple Stereo Images Taken by Yutu-2 Rover with Changing Illumination Conditions
        </a>
    </h3>
    <div style="font-style: italic;">202108, pp. 567-576(10)</div>
    <div>Authors: Wan, Wenhui; Wang, Jia; Di, Kaichang; Li, Jian; Liu, Zhaoqin; Man, Peng; Wang, Yexin; Yu, Tianyi; Liu, Chuankai; Li, Lichun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In a planetary-rover exploration mission, stereovision-based 3D reconstruction has been widely applied to topographic mapping of the planetary surface using stereo cameras onboard the rover. In this study, we propose an enhanced topographic mapping method based on multiple stereo images taken at the same rover location with changing illumination conditions. Key steps of the method include dense matching of stereo images, 3D point-cloud generation, point-cloud co-registration, and fusion. The final point cloud has more complete coverage and more details of the terrain than that conventionally generated from a single stereo pair. The effectiveness of the proposed method is verified by experiments using the Yutu-2 rover, in which two data sets were acquired by the navigation cameras at two locations and under changing illumination conditions. This method, which does not involve complex operations, has great potential for application in planetary-rover and lander missions.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000008/art00012;jsessionid=hxwj92064v9m.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Unsupervised Representation High-Resolution Remote Sensing Image Scene Classification via Contrastive Learning Convolutional Neural Network
        </a>
    </h3>
    <div style="font-style: italic;">202108, pp. 577-591(15)</div>
    <div>Authors: Li, Fengpeng; Li, Jiabao; Han, Wei; Feng, Ruyi; Wang, Lizhe</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Inspired by the outstanding achievement of deep learning, supervised deep learning representation methods for high-spatial-resolution remote sensing image scene classification obtained state-of-the-art performance. However, supervised deep learning representation methods need a considerable amount of labeled data to capture class-specific features, limiting the application of deep learning-based methods while there are a few labeled training samples. An unsupervised deep learning representation, high-resolution remote sensing image scene classification method is proposed in this work to address this issue. The proposed method, called contrastive learning, narrows the distance between positive views: color channels belonging to the same images widens the gaps between negative view pairs consisting of color channels from different images to obtain class-specific data representations of the input data without any supervised information. The classifier uses extracted features by the convolutional neural network (CNN)-based feature extractor with labeled information of training data to set space of each category and then, using linear regression, makes predictions in the testing procedure. Comparing with existing unsupervised deep learning representation high-resolution remote sensing image scene classification methods, contrastive learning CNN achieves state-of-the-art performance on three different scale benchmark data sets: small scale RSSCN7 data set, midscale aerial image data set, and large-scale NWPU-RESISC45 data set.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 08 - Year 2021</p>
        </footer>
    </body>
    </html>
    