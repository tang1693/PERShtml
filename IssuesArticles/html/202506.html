
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 06 - Year 2025</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 06 - Year 2025</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>

<!-- <div class="separator"></div><article style="padding: 15px;"> -->
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006/art00012;jsessionid=1oli2sde03kjw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Texture-Semantic Point: Registration for Point Clouds of Porcelain Relics
        </a>
    </h3>
    <div style="font-style: italic;">202506, pp. 347-360(14)</div>
    <div>Authors: Ge, Xuming; Wu, Chengze; Chen, Min; Xu, Bo; Zhu, Qing; Hu, Han</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/06/Texture-Semantic Point- Registration for Point Clouds of Porcelain Relics.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Point cloud models of porcelain are captured through the multi-registration of point clouds, which presents a challenging task. On the one hand, the smooth surface of porcelain lacks geometric feature variation, making it difficult to establish corresponding points. On the other hand, the overall geometric symmetry of most porcelain relics can easily lead to iterative calculations falling into the local minimum convergence trap. To address the difficulties in feature point selection, we propose a novel approach using texture-semantic points as features for coarse registration. We first select rich texture points as 2D candidates and establish a 2D-3D matching relationship, giving each candidate its 3D spatial location and associated texture information. Using these correspondences, we perform coarse alignment of the point clouds. However, in reality, the point clouds are not aligned, and the registration calculation fails because of geometric symmetry issues. To address this, we integrate a control net into the iterative closest point (ICP) calcula- tion to guide iterations towards the correct Special Euclidean group in 3 dimensions (SE(3)) transformation, achieving refined alignment. Finally, considering porcelain's symmetrical geometry, we introduce a pose optimization constraint using the symmetry axis as a weighted parameter to limit degrees of freedom and enhance registration accuracy. Experiments were conducted on seven porcelain datasets to evaluate the proposed approach. A qualitative analysis demonstrated successful refined alignment using the proposed approach. In addition, we performed a quantitative comparison with state-of-the-art methods. Experimental results showed that our approach outperformed others across all models when applied to the registration of geometrically symmetric porcelain; Specifically, the proposed method achieved a 50% enhancement in accuracy compared with others, measured by the distance between the labeled corresponding points.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006/art00014;jsessionid=1oli2sde03kjw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A High-Quality Underwater 3D Reconstruction Solution for Coral Reef Environments Leveraging Advanced Photogrammetric Computer Vision Techniques
        </a>
    </h3>
    <div style="font-style: italic;">202506, pp. 361-370(10)</div>
    <div>Authors: Zhong, Jiageng; Li, Ming; Gruen, Armin; Liao, Xuan; Qin, Jiangying; Wang, Bing</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/06/A High-Quality Underwater 3D Reconstruction Solution for Coral Reef Environments Leveraging Advanced Photogrammetric Computer Vision Techniques.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Coral reefs, with their intricate 3D structures, are vital marine ecosystems increasingly threatened by environmental stressors. Accurate 3D reconstruction of these underwater structures is essential for scientific research and conservation management. While underwater photogram- metry has emerged as a promising tool for this purpose, technical challenges persist in capturing fine-scale features under underwater conditions, particularly the intricate morphology of coral reefs and the highly complex textures that hinder high-fidelity reconstruction. Recent breakthroughs in computer vision and deep learning have introduced new opportunities for underwater photogrammetry. This study begins by outlining a photogrammetric workflow that can integrate current advanced technologies, followed by summarizing cutting-edge methods used in the key stages, i. e., sparse and dense reconstruction. Building on previous research, we propose a hierarchical reconstruction strategy for accurate and efficient dense modeling. Our approach first performs an efficient global coarse-grained reconstruction to capture the overall scene structure, followed by fine-scale modeling in key regions of interest. Using image data collected from a coral reef site at Moorea Island, we compare and evaluate various techniques, analyzing their respective strengths and limitations. In sparse reconstruction, the classical feature method scale-invariant feature transform demonstrates competitive performance. Deep learning–based methods, such as ALIKED feature and the SuperGlue matching network, achieve superior results on certain metrics. For dense reconstruction, Neural Radiance Fields and 3D Gaussian Splatting–based methods yield high-quality reconstructions but are computationally intensive. In contrast, the deep learning–based multi-view stereo approach achieves comparable reconstruction quality with greater efficiency. Experimental results on reconstruction result fusion further validate that our approach offers a scalable and practical solution for coral reef monitoring, advancing conservation science and ecosystem management practices.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000006/art00015;jsessionid=1oli2sde03kjw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Phase Center Extraction of Corner Reflector Points in Single-Look Complex Image
        </a>
    </h3>
    <div style="font-style: italic;">202506, pp. 371-381(11)</div>
    <div>Authors: Zhao, Ruishan; Yu, Zhi; Wang, Libo; Chen, Chunsen; Huang, Wenchao; Dai, Jiguang</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/06/Phase Center Extraction of Corner Reflector Points in Single-Look Complex Image.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The geometric calibration accuracy of the Synthetic Aperture Radar (SAR) system is affected by the extraction accuracy of Corner Reflector (CR) points in a Single-Look Complex (SLC) image. There are some problems in traditional artificial extraction methods for CR points, such as the difficulty of identifying CR points without prior knowledge, low efficiency, and limited extraction accuracy. An extraction method of the phase center for CR points without prior knowledge was proposed in this paper through the construction of a geometric error compensation model for SAR images and the study of high precision fitting methods of the phase center for CR points. The effectiveness of the proposed method was verified by the Gaofen-3 (GF-3) satellite image data. Experimental results demonstrated that the extraction accuracy of CR points could be better than 0.2 pixel for GF-3 images.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 06 - Year 2025</p>
        </footer>
    </body>
    </html>
    