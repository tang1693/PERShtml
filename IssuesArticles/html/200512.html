
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 12 - Year 2005</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 12 - Year 2005</h1>
            <p>Displaying articles from Issue 12 - Year 2005.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00001;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Probing the Relationship Between Classification Error and Class Similarity
        </a>
    </h3>
    <div style="font-style: italic;">200512, nan</div>
    <div>Authors: Ahlqvist, Ola; Gahegan, Mark</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We present a rationale and method for representing the vagueness in taxonomic class definitions in cases where classes are described by a set of characteristics, such as those sometimes used as the basis for land-cover category discrimination. We further describe methods to estimate the semantic similarity between any two classes by calculating semantic similitude metrics based on such parameterized class definitions. Our working hypothesis is that a large similitude would predict categories that will be more prone to confusion and hence image or map misclassification. We use two different existing data sets to demonstrate and evaluate the method, and the results support our original hypothesis. Consequently, we argue that classification schemes that are based on parameterized definitions could be assessed for problematic categories during their construction using our approach, and thus, enabling the identification of a thematic vagueness component to supplement the more traditional statistical measures derived from the error matrix.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00002;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automatic Camera Placement in Vision Metrology Based On A Fuzzy Inference System
        </a>
    </h3>
    <div style="font-style: italic;">200512, pp. 1375-1385(11)</div>
    <div>Authors: Saadatseresht, Mohammad; Samadzadegan, Farhad; Azizi, Ali</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Automatic determination of the camera placement for measuring complex industrial objects by vision metrology systems is a real challenge if the 3D simulated CAD models of the object along with the workspace information are not available. In such a case, several uncertain parameters such as visibility, accessibility, and camera-object distance are introduced into the camera placement decision-making that make it a non-deterministic complicated process. Hence, the uncertain behavior of the vision constraints demands the use of the fuzzy logic inference approach for the camera placement network design. In this paper, a novel method based on fuzzy logic reasoning strategy is proposed for the accuracy enhancement of an existing photogrammetric network by automatically adding new exposures. The fuzzy system is designed to make use of human type reasoning strategy by incorporating appropriate rules. The results indicate the high potential of the proposed method for automatic sensor placement in vision metrology.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00003;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Evaluation of Remote Sensing-derived Landscape Ecology Metrics for Reservoir Shoreline Environmental Monitoring
        </a>
    </h3>
    <div style="font-style: italic;">200512, pp. 1387-1397(11)</div>
    <div>Authors: Jackson, Mark W.; Jensen, John R.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The goal of this study was to determine the value of including landscape ecology patterns and structure metrics extracted from high-resolution, remotely-sensed imagery in the development of a Shoreline Environmental Impact Index (SEII). Methods of combining landscape ecology metrics to create a meaningful Shoreline Environmental Impact Index included multiple linear regression, multiple discriminant analysis, genetic neural networks, and feed-forward, back-propagation neural networks. The landscape ratings produced by the SEII’s generated using these methods were then compared to landscape ratings by experts. There was very little difference in the performance of several SEII’s generated despite differences in metrics and their weighting chosen by the different methods. The ratings from all methods showed their ability to reflect the expert ratings with moderate accuracy:≤84 percent agreement. Conclusions indicate that the contributions of landscape metrics to the ability of an SEII to discriminate between levels of shoreline degradation are variable, dependent upon the method of combination. Any of the current forms of the SEII is suitable for generating general indication of shoreline health.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00004;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automatic Segmentation of High-resolution Satellite Imagery by Integrating Texture, Intensity, and Color Features
        </a>
    </h3>
    <div style="font-style: italic;">200512, pp. 1399-1406(8)</div>
    <div>Authors: Hu, Xiangyun; Tao, C. Vincent; Prenzel, Björn</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                High spatial resolution satellite imagery has become an important source of information for geospatial applications. Automatic segmentation of high-resolution satellite imagery is useful for obtaining more timely and accurate information. In this paper, we develop a method and algorithmic framework for automatically segmenting imagery into different regions corresponding to various features of texture, intensity, and color. The central rationale of the method is that information from the three feature channels are adaptively estimated and integrated into a split-merge plus pixel-wise refinement framework. In the procedure for split-merge and refinement, segmentation is realized by comparing similarities between different features of sub-regions. The similarity measure is based on feature distributions. Withouta prioriknowledge of image content, the image can be segmented into different regions that frequently correspond to different land-use or other objects. Experimental results indicate that the method performs much better in terms of correctness and adaptation than using single feature or multiple features, but with constant weight for each feature. The method can potentially be applied within a broad range of image segmentation contexts.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00005;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Acquisition of Through-water Aerial Survey Images
        </a>
    </h3>
    <div style="font-style: italic;">200512, pp. 1407-1415(9)</div>
    <div>Authors: Mount, Richard</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The behavior of light at the air/water interface has substantial effects on the quality of vertical, or nadir-looking imagery used to interpret subsurface features for purposes such as marine habitat mapping. Reflection of the direct solar beam into the sensor by waves on the surface of the water creates bright glints, which obscure bottom features of interest. Sun angle, refraction, and reflection of the direct solar beam affect the amount of subsurface illumination and shadowing of bottom features. Simple interpretations of these sea surface effects are made with sufficient accuracy to improve planning for airborne, vertical image capture, particularly aerial photography or video imagery. The time available for image capture over shallow water is typically limited to a short period in the morning. The start time is controlled by subsurface illumination levels, which are determined by sun angle and locally variable factors, such as light attenuation by the water column, rather than surface reflection or subsurface shadowing. The end time is determined by sun glitter effects, which in this case study, are predictable from sun angle, camera field of view, and wind speed with an R2value of 0.9554.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00006;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Derivative Analysis of AVIRIS Data for Crop Stress Detection
        </a>
    </h3>
    <div style="font-style: italic;">200512, pp. 1417-1421(5)</div>
    <div>Authors: Estep, Lee; Carter, Gregory A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Low-altitude Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) hyperspectral imagery of a cornfield in Nebraska was used to determine whether derivative analysis methods provided enhanced plant stress detection compared with narrow-band ratios. The field was divided into 20 plots representing four replicates each of five nitrogen (N) fertilization treatments that ranged from 0 to 200 kg N/ha in 50 kg/ha increments. The imagery yielded a 3 m ground pixel size for 224 spectral bands. Derivative analysis provided no advantage in stress detection compared with the performance of narrow-band ratio indices derived from the literature. This result was attributed to a high leaf area index at the time of the overflight (LAI of approximately 5 to 6) and the high signal-to-noise character of the narrow AVIRIS bands.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2005/00000071/00000012/art00007;jsessionid=44726sb09sj9r.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Methodology for Spatial Uncertainty Analysis Of Remote Sensing and GIS Products
        </a>
    </h3>
    <div style="font-style: italic;">200512, pp. 1423-1432(10)</div>
    <div>Authors: Wang, Guangxing; Gertner, George Z.; Fang, Shoufan; Anderson, Alan B.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                When remote sensing and GIS products are generated, errors and uncertainties from collection, processing and analysis of image and ground data, and model development, accumulate and are propagated to the maps. The products thus possess many sources of uncertainties that vary spatially and temporally. Spatially identifying the sources of uncertainties, modeling their accumulation and propagation, and finally, quantifying them will be critical to control the quality of spatial data. This paper demonstrates a methodology and its applications for a case study in which uncertainty of predicted soil erosion is hierarchically partitioned into various primary components on a pixel-by-pixel basis. The methodology is based on a regionalized variable theory of variables. It integrates remote sensing aided co-simulation algorithms in geo-statistics, and uncertainty and error budget methods in uncertainty analysis. The simulation algorithms generate realizations that can be used to calculate local estimates, and the variances and co-variances between them. Uncertainty and error budget methods partition the uncertainty of output into various input components and quantify their relative uncertainty contributions. The results can thus suggest the main uncertainty sources and their variation spatially, and further provide a rationale to reduce errors in map generation and application.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 12 - Year 2005</p>
        </footer>
    </body>
    </html>
    