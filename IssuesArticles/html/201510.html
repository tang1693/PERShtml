<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000010/art00007;jsessionid=37kkfwr6dc0vh.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Geometric Method for Wood-Leaf Separation Using Terrestrial and Simulated Lidar Data
        </a>
    </h3>
    <div style="font-style: italic;">201510, pp. 767-776(10)</div>
    <div>Authors: Tao, Shengli; Guo, Qinghua; Xu, Shiwu; Su, Yanjun; Li, Yumei; Wu, Fangfang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Terrestrial light detection and ranging (lidar) can be used to record the three-dimensional structures of trees. Wood-leaf separation, which aims to classify lidar points into wood and leaf components, is an essential prerequisite for deriving individual tree characteristics. Previous research has tended to use intensity (including a multi-wavelength approach) and waveform information for wood-leaf separation, but use of the most fundamental information from a lidar point cloud, i.e., the x-, y-, and z- coordinates of each point, for this purpose has been poorly explored. In this study, we introduce a geometric method for wood-leaf separation using the x-, y-, and z- coordinates of each point. The separation results indicate that first-, second-, and third-order branches can be extracted from the raw point cloud by this new method, suggesting that it might provide a promising solution for wood-leaf separation.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000010/art00008;jsessionid=37kkfwr6dc0vh.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Two Dimensional Linear Discriminant Analyses for Hyperspectral Data
        </a>
    </h3>
    <div style="font-style: italic;">201510, pp. 777-786(10)</div>
    <div>Authors: Imani, Maryam; Ghassemian, Hassan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Most supervised feature extraction methods like linear discriminant analysis (LDA) suffer from the limited number of available training samples. The singularity problem causes LDA to fail in small sample size (SSS) situations. Two dimensional linear discriminant analysis (2DLDA) for feature extraction of hyperspectral images is proposed in this paper which has good efficiency with small training sample size. In this approach, the feature vector of each pixel of hyperspectral image is transformed into a feature matrix. As a result, the data matrices lie in a low-dimensional space. Then, the between-class and within-class scatter matrices are calculated using the matrix form of training samples. The proposed approach has two main advantages: it deals with the SSS problem in hyperspectral data, and also it can extract each number of features (with no limitation) from the original high dimensional data. The proposed method is tested on four widely used hyperspectral datasets. Experimental results confirm that the proposed 2DLDA feature extraction method provides better classification accuracy, with a reasonable computation time, compared to popular supervised feature extraction methods such as generalized discriminant analysis (GDA) and nonparametric weighted feature extraction (NWFE) particularly compared to the 1DLDA in the SSS situation. The experiments show that two dimensional linear discriminant analysis + support vector machine (2DLDA + SVM) is an appropriate choice for feature extraction and classification of hyperspectral images using limited training samples.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000010/art00009;jsessionid=37kkfwr6dc0vh.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Applying ASPRS Accuracy Standards to Surveys from Small Unmanned Aircraft Systems (UAS)
        </a>
    </h3>
    <div style="font-style: italic;">201510, pp. 787-793(7)</div>
    <div>Authors: Whitehead, Ken; Hugenholtz, Chris H.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We present a first assessment of UAS-derived orthoimagery and digital elevation data in the context of newly-released accuracy standards for digital geospatial data developed by the American Society for Photogrammetry and Remote Sensing. We outline results from two case studies using a commercially-available UAS, photogrammetry software, and an array of ground control and check points. Radial horizontal and vertical root-mean-square-errors (RMSE) were calculated as 0.05 m and 0.06 m, respectively, for one site, and 0.08 m and 0.03 m, respectively, for the other. Under the 1990 ASPRS standards, both surveys meet the requirements for Class 1 accuracy at the 1:500 map scale and at the 0.50 m contour interval. Under the newly-developed ASPRS standards, the reported errors fulfill the requirements for both horizontal and vertical mapping at the 10 cm RMSE level. Overall, these results provide initial direction for practitioners considering UAS surveying in the context of accuracy standards.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000010/art00010;jsessionid=37kkfwr6dc0vh.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Discriminating Saltcedar (Tamarix ramosissima) from Sparsely Distributed Cottonwood (Populus euphratica) Using a Summer Season Satellite Image
        </a>
    </h3>
    <div style="font-style: italic;">201510, pp. 795-806(12)</div>
    <div>Authors: Ji, Wenjie; Wang, Le</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Accurate mapping of saltcedar (Tamarix ramosissima) and cottonwood (Populus euphratica) using remote sensing images is required to study the dynamic relationship between these two species. Our study used pixel-based and semi-object-based methods to classify a high spatial resolution QuickBird image acquired during the summer in northern China, where both saltcedar and cottonwood are native species. The pixel-based classification results revealed that spectral bands alone were not sufficient to discriminate saltcedar from cottonwood trees due to their similar foliage reflectance in the summer. Including texture measures did not improve the result. The unique crown shapes and shadows associated with sparsely distributed cottonwood were used to facilitate the semi object-based method. The overall accuracy of the object-based classification result increased 15 percent compared to that of the pixel-based classification results and showed significant improvement in the discrimination between saltcedar and cottonwood.
            </details>
        </div>
</article>
