
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 01 - Year 2015</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 01 - Year 2015</h1>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000001/art00001;jsessionid=btjm6co5tc34o.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Correction of Distortions in YG-12 High-Resolution Panchromatic Images
        </a>
    </h3>
    <div style="font-style: italic;">201501, nan</div>
    <div>Authors: Jiang, Yonghua; Zhang, Guo; Li, Deren; Tang, Xinming; Huang, Wenchao; Li, Litao</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Design deficiencies and hardware limitations cause a number of issues with the images acquired by Chinese satellites launched before 2012, such as YG-12. The geometric quality of the images recorded by YG-12 cannot match its high resolution because of serious time-synchronization errors and interior distortions. To improve the geometric quality of YG-12 images, this paper proposes a method of interior calibration for the YG-12 panchromatic sensor. In addition, an innovative method is proposed to eliminate time-synchronization errors using parallel observations of the panchromatic sensor onboard YG-12. The experimental results indicate the interior parameters of the panchromatic sensor are determined with an accuracy of better than 0.32 pixels, and seamless mosaic images can be obtained after the elimination of distortions. Furthermore, the positioning accuracy with relatively few ground control points is shown to be better than 1.5 pixels.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000001/art00002;jsessionid=btjm6co5tc34o.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Optimal Land Cover Mapping and Change Analysis in Northeastern Oregon Using Landsat Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201501, pp. 37-47(11)</div>
    <div>Authors: Campbell, Michael; Congalton, Russell G.; Hartter, Joel; Ducey, Mark</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The necessity for the development of repeatable, efficient, and accurate monitoring of land cover change is paramount to successful management of our planetâ€™s natural resources. This study evaluated a number of remote sensing methods for classifying land cover and land cover change throughout a two-county area in northeastern Oregon (1986 to 2011). In the past three decades, this region has seen significant changes in forest management that have affected land use and land cover. This study employed an accuracy assessment-based empirical approach to test the optimality of a number of advanced digital image processing techniques that have recently emerged in the field of remote sensing. The accuracies are assessed using traditional error matrices, calculated using reference data obtained in the field. We found that, for single-time land cover classification, Bayes pixel-based classification using samples created with scale and shape segmentation parameters of 8 and 0.3, respectively, resulted in the highest overall accuracy. For land cover change detection, using Landsat-5 TM band 7 with a change threshold of 1.75 standard deviations resulted in the highest accuracy for forest harvesting and regeneration mapping.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000001/art00003;jsessionid=btjm6co5tc34o.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Reliable Spatial Relationship Constrained Feature Point Matching of Oblique Aerial Images
        </a>
    </h3>
    <div style="font-style: italic;">201501, pp. 49-58(10)</div>
    <div>Authors: Hu, Han; Zhu, Qing; Du, Zhiqiang; Zhang, Yeting; Ding, Yulin</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper proposes a reliable feature point matching method for oblique images using various spatial relationships and geometrical information for the problems resulted by the large view point changes, the image deformations, blurring, and other factors. Three spatial constraints are incorporated to filter possible outliers, including a cyclic angular ordering constraint, a local position constraint, and a neighborhood conserving constraint. Other ancillary geometric information, which includes the initial exterior orientation parameters that are obtained from the platform parameters and a rough DEM, are used to transform the oblique images geometrically and reduce the perspective deformations. Experiment results revealed that the proposed method is superior to the standard SIFT regarding both precision and correct matches using images obtained by the SWDC-5 system.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000001/art00004;jsessionid=btjm6co5tc34o.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Sub-pixel-scale Land Cover Map Updating by Integrating Change Detection and Sub-Pixel Mapping
        </a>
    </h3>
    <div style="font-style: italic;">201501, pp. 59-67(9)</div>
    <div>Authors: Li, Xiaodong; Du, Yun; Ling, Feng</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Coarse-resolution remotely sensed images are high in temporal repetition rates, but their low spatial resolution limits their application in updating land cover maps. Our proposed land cover updating method involves the use of coarse-resolution images to update fine-resolution land cover maps. The method comprises change detection and sub-pixel mapping methods. The current coarse-resolution image is unmixed, and the previous fine-resolution map is spatially degraded to produce current and previous class fraction images. A change detection method is applied to these fraction images to create a fine-resolution binary change/non-change map. Finally, a sub-pixel mapping method is applied to update the fine-resolution pixel labels that are changed in the change/non-change map. The proposed method is compared with a pixel-based classification method and two sub-pixel mapping methods. The proposed method maintains most of the spatial patterns of land cover classes that are unchanged in the previous and current images, whereas other methods cannot.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000001/art00005;jsessionid=btjm6co5tc34o.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Wetlands andPhragmitesUsing Publically Available Remotely Sensed Images
        </a>
    </h3>
    <div style="font-style: italic;">201501, pp. 69-78(10)</div>
    <div>Authors: Xie, Yichun; Zhang, Anbing; Welsh, William</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Using publically available remotely sensed images to map wetlands and invasive plants is attractive to ecologists, environmental scientists, and managers. However, wetland and invasive plant mapping on the basis of no- or low-cost images has been challenged by the variability of mapping accuracy. In this paper, we are developing an innovative wetland and invasive plant mapping technique characterized with three integrations: the integration of image interpretation with feature extraction, the integration of high spatial-resolution images with high spectral-solution images, and the integration of field reference data with interpreted and classified images. This technique advocates standard procedures for integrating NAIP (National Agriculture Imagery Program) and Landsat images with multiple processes of ground truthing, image classification, and validation. The case study conducted in the Detroit River International Wildlife Refuge concludes that the integration of NAIP and Landsat images provides sufficient spatial and spectral information for mapping coastal wetlands and Phragmites.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 01 - Year 2015</p>
        </footer>
    </body>
    </html>
    