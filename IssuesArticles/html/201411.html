
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 11 - Year 2014</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 11 - Year 2014</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000011" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000011/art00001;jsessionid=1w13g05fsy329.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Association-Matrix-Based Sample Consensus Approach for Automated Registration of Terrestrial Laser Scans Using Linear Features
        </a>
    </h3>
    <div style="font-style: italic;">201411, nan</div>
    <div>Authors: Al-Durgham, Kaleel; Habib, Ayman</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents an approach for the automatic registration of terrestrial laser scans using linear features. The main contribution here is introducing a new matching strategy that uses an association matrix to store information about candidate matches of linear features. The motivation for this work is aiding the 3D modeling of industrial sites rich with pole-like features. The proposed matching strategy aims at establishing hypotheses about potential minimal matches of linear features that could be used for the estimation of the transformation parameters relating the scans; then, quantifying the agreement between the scans using the estimated transformation parameters. We combine the association matrix and the well-known RANSAC approach for the derivation of conjugate pairs among the two scans. Rather than randomly selecting the line pairs as in the RANSAC-based registration, the association matrix guides the process of selecting the candidate matches of linear features. Experiments are conducted using laser scanning data of an electrical substation to assess the performance of the proposed association-matrix-based sample consensus approach as it compares to the traditional RANSAC-based procedure. The association-matrix-based approach showed consistent tendency of bringing up the correct matches first before the RANSAC-based registration.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000011/art00002;jsessionid=1w13g05fsy329.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Robust Image Matching Method based on Optimized BaySAC
        </a>
    </h3>
    <div style="font-style: italic;">201411, pp. 1041-1052(12)</div>
    <div>Authors: Kang, Zhizhong; Jia, Fengman; Zhang, Liqiang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper proposes a robust image-matching method, which integrates SIFT with the optimized Bayes SAmpling Consensus (BaySAC). As the point correspondences are likely contaminated by outliers, we present a novel robust estimation method involving an efficient BaySAC for eliminating falsely accepted correspondences. The key points of the proposed hypothesis testing algorithm are determining and updating the prior probabilities of pseudo-correspondences. First, we propose a strategy for prior probability determination in terms of the statistical characteristics of a deterministic mathematical model for hypothesis testing. Moreover, the inlier probability updating is simplified based on a memorable form of Bayes' Theorem. The proposed approach is validated on a variety of image pairs. The results indicate that when compared with the performance of RANdom SAmpling Consensus (RANSAC) and the original BaySAC, the proposed optimized BaySAC consumes less computation and obtains higher matching accuracy when the hypothesis set is contaminated with more outliers.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000011/art00003;jsessionid=1w13g05fsy329.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Block Adjustment of Satellite Imagery Using RPCs with Virtual Strip Scenes
        </a>
    </h3>
    <div style="font-style: italic;">201411, pp. 1053-1059(7)</div>
    <div>Authors: Zhang, Guo; Pan, Hongbo; Li, Deren; Tang, Xinming; Zhu, Xiaoyong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The increasing volume of high-resolution satellite imagery has seen the need for a large number of ground control points become a limiting factor for large-area mapping. Utilizing a shift model for adjacent scenes of the same track, this paper proposes a method based on rational polynomial coefficients with virtual strip scenes. An affine transformation in the image space is used as the adjustment model for the virtual strip scenes, and the corresponding adjustment parameters are derived from the relationship between the standard scenes and virtual strip scenes. Triplet stereo images from ZiYuan-3 are used to test the accuracy of the virtual strip scenes, and we compare the block adjustment of the long strip scene products and standard scene products. The results show that sub-pixel accuracy can be achieved in checkpoints close to the long strip scenes.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000011/art00004;jsessionid=1w13g05fsy329.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automatic Building Extraction Using a Fuzzy Active Contour Model
        </a>
    </h3>
    <div style="font-style: italic;">201411, pp. 1061-1068(8)</div>
    <div>Authors: Ebadi, Hamid; Mokhtarzade, Mehdi; Kabolizade, Mostafa</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Automatic building extraction is currently an important research topic in the field of photogrammetry. An active contour model is a well-received approach in this field. This paper proposes an improved active contour model that focuses on building extraction from aerial images and lidar data. The main research concern in this paper is the development of energy functions to the optimum use of expert human knowledge in the overall process. Based on this approach, a new fuzzy inference system for evaluating energy functions was developed by modeling the human perception of various effective parameters in the energy functions. Compared to the existing active contour models, the new algorithm is capable of directing the initial contour to building feature boundaries more quickly and robustly. Accuracy assessment showed that the proposed model is capable of achieving a shape accuracy of 98 percent and a total accuracy of 97 percent in complex urban areas.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000011/art00005;jsessionid=1w13g05fsy329.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            CityGML Implementation Specifications for a Countrywide 3D Data Set
        </a>
    </h3>
    <div style="font-style: italic;">201411, pp. 1069-1077(9)</div>
    <div>Authors: Stoter, Jantien; Vosselman, George; Dahmen, Christian; Oude Elberink, Sander; Ledoux, Hugo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper discusses and presents the specifications of a countrywide 3D data set for The Netherlands and the best practices to generate 3D data accordingly. The specifications extend the OGC 3D standard CityGML to align it to national requirements. Although CityGML offers a solid base for 3D information modeling, we have met the problems of CityGML being a generic standard resulting in too much flexibility and in some cases ambiguity when implementing it at a national level. Based on experiences and use cases, we refined and extended the CityGML specifications into implementation specifications for our Dutch context. We present a workflow to generate 3D information compliant with specifications, starting from existing 2D/3D raw data. Also, a 3D validation tool has been developed to be able to evaluate 3D information against the defined specifications. Currently these specifications have been offered to OGC as best practices.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 11 - Year 2014</p>
        </footer>
    </body>
    </html>
    