
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 06 - Year 2010</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 06 - Year 2010</h1>
            <p>Displaying articles from Issue 06 - Year 2010.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00001;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Acquisition, Orthorectification, and Object-based Classification of Unmanned Aerial Vehicle (UAV) Imagery for Rangeland Monitoring
        </a>
    </h3>
    <div style="font-style: italic;">201006, nan</div>
    <div>Authors: Laliberte, Andrea S.; Herrick, Jeffrey E.; Rango, Albert; Winters, Craig</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The use of unmanned aerial vehicles (UAVs) for natural resource applications has increased considerably in recent years due to their greater availability, the miniaturization of sensors, and the ability to deploy a UAV relatively quickly and repeatedly at low altitudes. We examine in this paper the potential of using a small UAV for rangeland inventory, assessment and monitoring. Imagery with a ground resolved distance of 8 cm was acquired over a 290 ha site in southwestern Idaho. We developed a semi-automated orthorectification procedure suitable for handling large numbers of small-footprint UAV images. The geometric accuracy of the orthorectified image mosaics ranged from 1.5 m to 2 m. We used object-based hierarchical image analysis to classify imagery of plots measured concurrently on the ground using standard rangeland monitoring procedures. Correlations between image-and ground-based estimates of percent cover resulted in r-squared values ranging from 0.86 to 0.98. Time estimates indicated a greater efficiency for the image-based method compared to ground measurements. The overall classification accuracies for the two image mosaics were 83 percent and 88 percent. Even under the current limitations of operating a UAV in the National Airspace, the results of this study show that UAVs can be used successfully to obtain imagery for rangeland monitoring, and that the remote sensing approach can either complement or replace some ground-based measurements. We discuss details of the UAV mission, image processing and analysis, and accuracy assessment.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00002;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Pixel Based Regeneration Index using Time Series Similarity and Spatial Context
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 673-682(10)</div>
    <div>Authors: Lhermitte, Stefaan; Verbesselt, Jan; Verstraeten, Willem W.; Coppin, Pol</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Although the regeneration index based on control plots provides a valuable tool to quantify fire impact and subsequent vegetation regrowth, the practical implementation at large scale levels remains limited due to the need for detailed reference maps. The objective of this research therefore was the development of an image-based selection approach for control pixels based on time series similarity (TSS). The TSS approach allows the computation of a per-pixel regeneration index on regional to global scale without the need for reference maps. Evaluation of the control plot selection approaches based on un-burnt focal pixels confirmed the validity of the TSS approach and showed optimal results for the TSSRMSDapproach with x= 4and NT= 8 due to beneficial averaging effects and minimal window size effects. As such, the effects of spatial heterogeneity and noise are minimized and a preliminary quality indicator can be derived.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00003;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Novel Approach to Terrestrial Lidar Georeferencing
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 683-690(8)</div>
    <div>Authors: Wilkinson, Benjamin E.; Mohamed, Ahmed H.; Dewitt, Bon A.; Seedahmed, Gamal H.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper describes a novel method for determining the absolute orientation of lidar point clouds using GPS measurements from two antennas firmly mounted on the optical head of a lidar scanner. The solution is linear and is derived from the non-linear georeferencing model by exploiting the properties of the skew-symmetric matrix. Simulation and real world experimentation using our prototype suggest a precision of about 0.05° ( 1 mrad) for the three Euler attitude angles. The method can help alleviate problems associated with the conventional technique and can allow for an increased number of practical applications for georeferenced terrestrial lidar.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00004;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 691-700(10)</div>
    <div>Authors: Taylor, Subhashni; Kumar, Lalit; Reid, Nick</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Fusion of panchromatic and multi-spectral QuickBird satellite imagery was carried out to evaluate the impact of fusion techniques on classification accuracies for Lantana mapping. This study compared four image fusion techniques, namely Brovey, Hue-Saturation-Value, Principal Components, and Gram-Schmidt Spectral Sharpening. Classification accuracy assessment was calculated using an error matrix for all images. Gram-Schmidt and Principal Components spectral sharpening techniques had an overall accuracy of 90.5 percent and 89.5 percent and a kappa coefficient of 0.85 and 0.84, respectively, compared to the MS image which had an overall accuracy of 86.3 percent and a kappa coefficient of 0.79. Brovey transformation and HSV performed poorly in the supervised classification with overall accuracies of 64.2 percent and 76.8 percent and kappa coefficients of 0.48 and 0.65, respectively. Visual and statistical analyses of the fused images showed that Gram- Schmidt and Principal Components spectral sharpening techniques preserved spectral quality much better than the Brovey and HSV fused images.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00005;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Effects of Topographic Variability and Lidar Sampling Density on Several DEM Interpolation Methods
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 701-712(12)</div>
    <div>Authors: Guo, Qinghua; Li, Wenkai; Yu, Hong; Alvarez, Otto</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study aims to quantify the effects of topographic variability (measured by coefficient variation of elevation, CV) and lidar (Light Detection and Ranging) sampling density on the DEM (Digital Elevation Model) accuracy derived from several interpolation methods at different spatial resolutions. Interpolation methods include natural neighbor (NN), inverse distance weighted (IDW), triangulated irregular network (TIN), spline, ordinary kriging (OK), and universal kriging (UK). This study is unique in that a comprehensive evaluation of the combined effects of three influencing factors (CV, sampling density, and spatial resolution) on lidar-derived DEM accuracy is carried out using different interpolation methods. Results indicate that simple interpolation methods, such as IDW, NN, and TIN, are more efficient at generating DEMs from lidar data, but kriging-based methods, such as OK and UK, are more reliable if accuracy is the most important consideration. Moreover, spatial resolution also plays an important role when generating DEMs from lidar data. Our results could be used to guide the choice of appropriate lidar interpolationmethods for DEM generation given the resolution, sampling density, and topographic variability.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00006;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Detecting Seasonal Changes in Crop Community Structure using Day and Night Digital Images
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 713-726(14)</div>
    <div>Authors: Sakamoto, Toshihiro; Shibayama, Michio; Takada, Eiji; Inoue, Akihiro; Morita, Kazuhiro; Takahashi, Wataru; Miura, Shigenori; Kimura, Akihiko</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study investigates a simple approach using day and night digital images to objectively measure seasonal changes in crop morphology. A paddy field in the Toyama prefecture and a barley field in the Ibaraki prefecture of Japan were observed by two commercially available digital cameras in simple waterproof cases which captured day and night images by shooting at regular intervals using an auto-flash mode. The newly developed NRBINIR(Nighttime Relative Brightness Index in Near Infra Red), based on the nighttime NIR images, had high correlations with plant length until heading (paddy; R2=0.996, barley; R2=0.996), and the total dry weight until 20 days after heading (paddy; R2=0.997). Investigating the temporal pattern of the three indexes (daytime NDVIGR, nighttime NDVIGR, and NRBINIR) coupled with field measurement data, we confirmed that the time-series data derived from inexpensive, specifically modified digital cameras are available for monitoring the seasonal changes in crop growth.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00007;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Evaluation of the RPC Model for Spaceborne SAR Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 727-733(7)</div>
    <div>Authors: Zhang, Guo; Fei, Wen-bo; Li, Zhen; Zhu, Xiaoyong; Li, De-ren</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The rational polynomial coefficient (RPC) model has raised considerable interest in the photogrammetry and remote sensing community. Much work has been done on frame camera imagery and/or push-broom scanner imagery, and it has been widely accepted that the RPC model can be taken as an alternative to rigorous sensor models for photogrammetric processing. However, there have been few publications discussing the application of the RPC model to SAR image processing. In this paper, we first review the geometric effects of SAR imagery and compare SAR imagery with optical satellite imagery. Then, the unbiased RPC estimators for a series of SAR images are derived. Based on numerous tests with the rigorous sensor model available, the modeling error of the RPC is analyzed. This study found that the RPC model is suitable for SAR imagery and can be used as a replacement for the rigorous sensor model for photogrammetric processing.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000006/art00008;jsessionid=3sptam0fup7ep.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Detecting Carbon Dioxide Emissions in Soybeans by Aerial Thermal Infrared Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201006, pp. 735-741(7)</div>
    <div>Authors: Stohr, Christopher; Darmody, R.G.; Wimmer, B.; Krapac, I.; Hackley, K.; Iranmanesh, A.; Leakey, Andrew D.B.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A remote sensing method is needed to supplement fixed point monitoring of leakage from pipelines and geologic reservoirs used for carbon dioxide (CO2) storage. An experiment tested the effectiveness of thermal infrared imagery to identify plants affected by high concentrations of CO2released beneath a soybean canopy in east-central Illinois.Carbon dioxide gas was released for four hours at 10 m3/hr through an oscillating sprinkler simulating a point release and a 2 m perforated pipe beneath a mature, closed-canopy field. Ground-based measurements showed a 2.5°C increase in radiant temperature of CO2-affected soybeans.Aerial thermal infrared imagery showed distinct plumes of elevated radiant temperatures in the soybean field downwind of the two CO2point-release sites six to eight hours after gas was released. Field measurements of atmospheric CO2concentrations taken at three heights (ground, underside, and mid-canopy) guided by an air-to-ground imagery transmitter, support aerial imagery interpretations.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 06 - Year 2010</p>
        </footer>
    </body>
    </html>
    