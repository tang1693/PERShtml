
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 01 - Year 2021</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 01 - Year 2021</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000001" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000001/art00010;jsessionid=11trqkhispj10.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            SIP-Based Inversion Model of Mining-Induced 3D Deformation
        </a>
    </h3>
    <div style="font-style: italic;">202101, pp. 21-31(11)</div>
    <div>Authors: Tang, Fuquan; Huang, Jingcai; Dong, Longkai; Li, Pengfei; Yan, Zhaocun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Underground mining causes many forms of surface deformation, including vertical subsidence as well as strike and dip horizontal displacement. Differential interferometric synthetic-aperture radar (D-InSAR) has become a widely applied technique for precise and detailed mapping of the Earth's surface deformation caused by underground mining. However, the technology can only detect a one-dimensional displacement in the satellite's line of sight. To address this deficiency, we propose an improved three-dimensional displacement inversion model based on symmetry characteristics (imDIMSC) of a mining subsidence basin by the stacking technology of multiple single-track InSAR pairs. In this study, both field-observed surface displacement and simulated data were applied to calibrate and validate the proposed imDIMSC model. A methodology and algorithm were then developed to determine the symmetrical center for the two special mining circumstances. Comparison of the field-observed data, the proposed methodology, and the imDIMSC model provided significantly more accurate 3D displacement estimations.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000001/art00011;jsessionid=11trqkhispj10.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Building Extraction from Lidar Data Using Statistical Methods
        </a>
    </h3>
    <div style="font-style: italic;">202101, pp. 33-42(10)</div>
    <div>Authors: Sadeq, Haval Abdul-Jabbar</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this article, a straightforward, intuitive method for lidar data classification and building extraction, based on statistical analysis, is presented. The classification of the point cloud into ground and nonground is begun by individually testing each point within the point cloud using the statistical mean height. In this operation, various window sizes are specified, and the mean is obtained at each size. The points that are above the mean are saved and divided by the number of windows to obtain the proportion. Points are considered non-ground if their proportion is higher than the assigned threshold, and otherwise ground. An algorithm for classifying the obtained nonground point cloud into buildings and trees is also illustrated in this article. First the nonground points are labeled, then each label is tested individually. The process begins with segmenting each label. Then comes testing of whether each segment of points can be fitted within a specific plane. The label of the point cloud is considered a building if the number of segments considered as planes is larger than those considered as nonplanes; otherwise it is classified as a tree.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000001/art00012;jsessionid=11trqkhispj10.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Georeferencing with Self-Calibration for Airborne Full-Waveform Lidar Data Using Digital Elevation Model
        </a>
    </h3>
    <div style="font-style: italic;">202101, pp. 43-52(10)</div>
    <div>Authors: Li, Qinghua; Shan, Jie</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Precise georeferencing of airborne full-waveform lidar is a complex process. On one hand, no ground control points are visible due to heavy canopy. While on the other hand, precise georeferencing relies on ground control. As an alternative, we propose to use an available digital elevation model (DEM ) as control. The mathematical framework minimizes the difference between the lidar DEM and the reference DEM. Our solution consists of two steps: initial optimization to find reliable ground points through iterative filtering and georeferencing, and fine optimization to achieve precise georeferencing and lidar system calibration. Through this approach, the wave-form-derived DEM can best fit the reference DEM, with a mean of 0.937 m and standard deviation of 0.792 m, while the time-synchronization offset and boresight angles are simultaneously determined, i.e., self-calibrated. This development provides a novel georeferencing approach with self-calibration for lidar data without using conventional ground control points.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000001/art00013;jsessionid=11trqkhispj10.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Improved Approach Based on Terrain-dependent Mathematical Models for Georeferencing Pushbroom Satellite Images
        </a>
    </h3>
    <div style="font-style: italic;">202101, pp. 53-60(8)</div>
    <div>Authors: Moradi, Behrooz; Zoej, Mohammad Javad Valadan; Yaghoobi, Sayad; Yavari, Somayeh</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Recently, linear features in remotely sensed imagery have gained much attention because of their unique characteristics compared to other control features. For georeferencing high-resolution satellite images, the observations in the mathematical equations (slope and y-intercept) of the corresponding control lines in the two spaces are considered the same based on recent studies. However, the use of such assumptions causes error and reduces the accuracy of registration. The aim of this article is to present a methodology based on a quasi-observation assumption in the mathematical equations in the process of georeferencing. Experimental results for IKONOS and GeoEye images over two different cities of Iran indicate that the quasi-observation assumption can increase the average registration accuracy up to 48.96% and 24.77% using 3D-affine and rational function models, respectively. This improvement in accuracy increases the processing time by 31.48% over traditional approaches; however, the proposed methodology can be regarded as an efficient solution.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000001/art00014;jsessionid=11trqkhispj10.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Dynamic Spatial Fusion of Cloud Vertical Phase fromCALIPSOandCloudSatSatellite Data
        </a>
    </h3>
    <div style="font-style: italic;">202101, pp. 61-67(7)</div>
    <div>Authors: Chen, Zhenting; Wang, Junfeng; Gao, Dongyang; Xu, Bing; Yu, Wenjie; Yang, Min</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Cloud phase is a core parameter of inversion of cloud characteristics. The accuracy of cloud phase affects the results of cloud optical and microphysical characteristics. In this study, we obtain the cloud vertical phase (CVP ) products of CALIPSO and CloudSat satellites, then we put forward a dynamic spatial fusion algorithm for the fusion of the two products. A series of spatial optimal CVP fusion rules are presented for dual-source data, and we realize CVP fusion using these rules. We took Typhoon Lupit in the Pacific Ocean as an experimental object. The results show that the total cloud pixel amount increased by 124.09% and 10.54%, respectively, compared to those of CALIPSO and CloudSat. The recognition of different CVP is 7.97% and 1.37%. The results show that this method can improve the accuracy of multi-source CVP inversion effectively, and provide new ways for the synergy of multi-sensor satellites.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 01 - Year 2021</p>
        </footer>
    </body>
    </html>
    