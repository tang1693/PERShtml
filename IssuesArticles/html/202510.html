
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 10 - Year 2025</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 10 - Year 2025</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00007;jsessionid=3co9c5gsl9nev.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Global Multi-Scale Fusion Self-Calibration Network for Remote Sensing Object Detection
        </a>
    </h3>
    <div style="font-style: italic;">202510, pp. 607-621(15)</div>
    <div>Authors: Chen, Yan; Shi, Xinlu; Wang, Xiaofeng; Gu, Qi; Zhang, Chen; Xu, Lixiang; Zhan, Shian; Yu, Wenle</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/10/Global Multi-Scale Fusion Self-Calibration Network for Remote Sensing Object Detection.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Applications of remote sensing images in both defense and civilian sectors have spurred substantial research interest. In the field of remote sensing, object detection confronts challenges such as complex backgrounds, scale diversity, and the presence of dense small objects. To address these issues, we propose an improved deep learning-based model, the Global Multi-scale Fusion Self-calibration Network, which is expected to contribute to alleviating the challenges. It consists of three main components: the hierarchical feature aggregation backbone, which uses improved modules such as the receptive field context-aware feature extraction module, the global information acquisition module, and the simple parameter-free attention module to extract key features and minimize the background interference. To couple multi-scale features, we enhanced the fusing component and designed the multi-scale enhanced pyramid structure integrating the proposed new modules. During the detection phase, especially when focusing on small object detection, we designed a novel convolutional attention feature fusion head. This head is constructed to integrate local and global branches for feature extraction by leveraging channel shuffling and multi-head attention mechanisms for efficient and accurate detection. Experiments on the Detection in Optical Remote Sensing Images (DIOR), Northwestern Polytechnical University Very High-Resolution‐10 (NWPU VHR‐10), remote sensing object detection (RSOD), and DOTAv1.0 data sets show that our method achieves mAP50(mean average precision at 50% intersection over union) of 69.7%, 91.3%, 94.2%, and 70.0%, respectively, outperforming existing comparative methods. The proposed network is expected to provide new perspectives for remote sensing tasks and possible solutions for relevant applications in the image domain.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00010;jsessionid=3co9c5gsl9nev.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            MRTD-Based Effective Range Analysis of Airborne Infrared Imaging Systems for Ship Detection: Optimization of the Calculation for Operational Range Through an Improved MRTD Model
        </a>
    </h3>
    <div style="font-style: italic;">202510, pp. 623-630(8)</div>
    <div>Authors: Yan, Peng; Tian, Yuyang; Ling, Xiao; Zhu, Kaikai; Sheng, Qinghong; Wang, Bo; Li, Jun; Liu, Xiang; Xu, Xiao</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/10/MRTD Based Effective Range Analysis of Airborne Infrared Imaging Systems for Ship Detection Optimization of the Calculation for Operational Range Through an Improved MRTD Model.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                When the airborne infrared imaging system detects ships, significant variations in environmental temperature are often observed. In the existing calculation models for the operating range, the factor of environmental temperature has not been taken into account. However, when the environmental temperature changes, it will affect the variation of the minimum resolvable temperature difference (MRTD) of the system, resulting in a relatively large deviation in the prediction of the operating range of the airborne infrared imaging system. To address this crucial technical challenge, this study systematically established the relationship formula of the MRTD under different temperatures. By integrating with the improved theoretical model of MRTD, a calculation method for the operating range that takes environmental temperature into consideration was developed to accurately determine the operating range of the airborne infrared imaging system. Comparative experimental studies focusing on ships show that, compared with traditional methods, the prediction deviation of the proposed method is significantly reduced, with an average reduction of 10.1%.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00011;jsessionid=3co9c5gsl9nev.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Convolutional Neural Networks for Land Use and Land Cover Multi-class Maps from Historical Aerial Photographs
        </a>
    </h3>
    <div style="font-style: italic;">202510, pp. 631-645(15)</div>
    <div>Authors: Kostrzewa, Adam</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/10/Convolutional Neural Networks for Land Use and Land Cover Multi-class Maps from Historical Aerial Photographs.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Historical maps that describe past land use and land cover (LULC) forms can be a precious source of information in many scientific fields studying long-term spatial and temporal changes in the landscape. Such repositories were created manually in small areas in the past, which was a time-consuming and labor-intensive task. Recently, there has been a growing tendency to use machine learning models for this purpose, along with deep learning methods. However, having a massive amount of labeled data is necessary for these methods to train the networks. Training data are often manually labeled, posing a significant challenge and limiting the automation of these methods. This article presents a method that uses topographic databases to extract complex multi-class maps representing LULC from historical aerial photographs, eliminating the time-consuming data labeling step. The method uses transfer learning with a pretrained model on 2020 and 2014 data and attempts to reconstruct LULC types with the same convolutional neural network (CNN) network on archived images from 2006. The experiment covered 488 km2and included seven LULC classes. The method was tested using different CNN architectures (U-Net, Pyramid Scene Parsing Network [PSPNet], and LinkNet) with backbones (ResNeXt+SE, EfficientNet, and Inception). The PSPNet‐EfficientNet‐b7 network model achieved the best results, with 90% overall accuracy for predicting LULC classes based on the 2006 archived aerial images.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <span style="background-color: gold; color: black; font-weight: bold; padding: 3px 8px; border-radius: 5px; font-size: 12px; margin-left: 0px;">
        Editor’s Choice
    </span>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2025/00000091/00000010/art00013;jsessionid=3co9c5gsl9nev.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Thirty Years of the U.S. National Land Cover Database: Impacts and Future Direction
        </a>
    </h3>
    <div style="font-style: italic;">202510, pp. 647-659(13)</div>
    <div>Authors: Sohl, Terry; Jin, Suming; Dewitz, Jon; Wickham, James; Brown, Jesslyn; Stehman, Stephen; Herold, Nathaniel; Schleeweis, Karen; Tollerud, Heather; Deering, Carol</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2025/10/Thirty Years of the US National Land Cover Database Impacts and Future Direction.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The National Land Cover Database (NLCD), developed through the Multi-Resolution Land Characteristics Consortium, was initiated 30 years ago and has continually provided critical, Landsat-based landcover and land-change information for the United States. Originally launched to address the lack of national-scale, moderate-resolution land-cover data, NLCD has evolved from the pioneering 1992 dataset into a comprehensive, annually updated product suite. Key innovations include the introduction of impervious surface mapping, forest canopy mapping, standardized Landsat mosaics, national-scale accuracy assessments, continual evolution of deep learning and artificial intelligence methodologies, and a transition toward operational, change-focused monitoring. The NLCD has become an essential resource for scientific research, land management, and policy development, with extensive adoption across federal, state, and local agencies; academia; and the private sector. The NLCD data underpin a wide array of applications, including biodiversity conservation, urban planning, hydrology, human health studies, and natural hazard assessment. As new global and high-resolution commercial land-cover products emerge, the NLCD continues to distinguish itself through its temporal depth, federal backing, and thematic consistency. Moving forward, the NLCD will maintain its niche as the leading, moderate-resolution, long-term land-cover and land-change dataset for the United States, ensuring continued support for broad national applications while complementing higher-resolution and global-mapping efforts.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 10 - Year 2025</p>
        </footer>
    </body>
    </html>
    