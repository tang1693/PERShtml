
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 11 - Year 2019</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 11 - Year 2019</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000011" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000011/art00008;jsessionid=bemtlp2nt52s0.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Soil Moisture Retrieval Using Modified Particle Swarm Optimization and Back-Propagation Neural Network
        </a>
    </h3>
    <div style="font-style: italic;">201911, pp. 789-798(10)</div>
    <div>Authors: Tao, Liangliang; Wang, Guojie; Chen, Xi; Li, Jing; Cai, Qingkong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In order to eliminate the influences of surface roughness and vegetation on radar signals in the vegetation-covered soil moisture estimation, the present paper proposes a combining method based on modified particle swarm optimization (MPSO) and back-propagation (BP) neural network algorithm. This method combines optical and radar data at the field scale and uses MPSO to optimize the weight of the neural network. An effective inertia weight is introduced in the MPSO and an implicit relationship between backscatter coefficient and soil moisture is established. Experimental results show that the combining method produces better accuracy than other inversion methods with R2of 72.2% and Root Mean Square Error (RMSE) of 0.033 cm3/cm3, respectively. Meanwhile, the estimated accuracy of surface soil moisture using radar and optical data simultaneously is much higher than that using only a single data source as input with R2of 0.827 and RMSE of 0.029 cm3/cm3. Therefore, the combining method can effectively improve the accuracy of soil moisture retrieval and provide support for large-scale agricultural monitoring.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000011/art00009;jsessionid=bemtlp2nt52s0.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Scattering-Mechanism-Based Investigation of Optimal Combinations of Polarimetric SAR Frequency Bands for Land Cover Classification
        </a>
    </h3>
    <div style="font-style: italic;">201911, pp. 799-813(15)</div>
    <div>Authors: Qi, Zhixin; Yeh, Anthony Gar-On; Li, Xia</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Aiming at steering the selection of optimal combinations of polarimetric SAR (PolSAR) frequency bands for different land cover classification schemes, this study investigates the land cover classification capabilities of all the possible combinations of L-band ALOS PALSAR fully PolSAR data, C-band RADARSAT-2 fully PolSAR data, and X-band TerraSAR-X HH SAR data. A method that integrates polarimetric decomposition, object-based image analysis, decision tree algorithms, and support vector machines is used for the classification. Polarimetric decomposition theorems are used to interpret the scattering mechanisms at the different frequency bands to reveal the effect mechanisms of PolSAR frequency variation on the classification capability. This study finds that (1) X-band HH SAR is not necessary for classifying the land cover types involved in this study when C- or L-band fully PolSAR are used; (2) C-band fully PolSAR alone is adequate for classifying primitive land cover types, namely, water, bare land, vegetation, and built-up areas; and (3) L-band fully PolSAR alone is adequate for distinguishing between various vegetation types, such as crops, banana trees, and forests.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000011/art00010;jsessionid=bemtlp2nt52s0.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            On-Orbit Calibration Approach Based on Partial Calibration-Field Coverage for the GF-1/WFV Camera
        </a>
    </h3>
    <div style="font-style: italic;">201911, pp. 815-827(13)</div>
    <div>Authors: Wang, Mi; Guo, Beibei; Zhu, Ying; Cheng, Yufeng; Nie, Chenhui</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The Gaofen-1 (GF1) optical remote sensing satellite is the first in China's series of high-resolution civilian satellites and is equipped with four wide-field-of-view cameras. The cameras work together to obtain an image 800 km wide, with a resolution of 16 m, allowing GF1 to complete a global scan in four days. To achieve high-accuracy calibration of the wide-field-of-view cameras on GF1, the calibration field should have high resolution and broad coverage based on the traditional calibration method. In this study, a GF self-calibration scheme was developed. It uses partial reference calibration data covering the selected primary charge-coupled device to achieve high-accuracy calibration of the whole image. Based on the absolute constraint of the ground control points and the relative constraint of the tie points of stereoscopic images, we present two geometric calibration models based on paired stereoscopic images and three stereoscopic images for wide-field-of-view cameras on GF1, along with corresponding stepwise internal-parameter estimation methods. Our experimental results indicate that the internal relative accuracy can be guaranteed after calibration. This article provides a new approach that enables large-field-of-view optical satellites to achieve high-accuracy calibration based on partial calibration-field coverage.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000011/art00011;jsessionid=bemtlp2nt52s0.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Semiautomatically Register MMS LiDAR Points and Panoramic Image Sequence Using Road Lamp and Lane
        </a>
    </h3>
    <div style="font-style: italic;">201911, pp. 829-840(12)</div>
    <div>Authors: Zhu, Ningning; Jia, Yonghong; Huang, Xia</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We propose using the feature points of road lamp and lane to register mobile mapping system (MMS) LiDAR points and panoramic image sequence. Road lamp and lane are the common sobjects on roads; the spatial distributions are regular, and thus our registration method has wide applicability and high precision. First, the road lamp and lane were extracted from the LiDAR points by horizontal grid and reflectance intensity and then by optimizing the endpoints as the feature points of road lamp and lane. Second, the feature points were projected onto the panoramic image by initial parameters and then by extracting corresponding feature points near the projection location. Third, the direct linear transformation method was used to solve the registration model and eliminate mismatching feature points. In the experiments, we compare the accuracy of our registration method with other registration methods by a sequence of panoramic images. The results show that our registration method is effective; the registration accuracy of our method is less than 10 pixels and averaged 5.84 pixels in all 31 panoramic images (4000 Ã— 8000 pixels), which is much less than that of the 56.24 pixels obtained by the original registration method.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000011/art00012;jsessionid=bemtlp2nt52s0.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Double-Strategy-Check Active Learning Algorithm for Hyperspectral Image Classification
        </a>
    </h3>
    <div style="font-style: italic;">201911, pp. 841-851(11)</div>
    <div>Authors: Cui, Ying; Ji, Xiaowei; Xu, Kai; Wang, Liguo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Applying limited labeled samples to improve classification results is a challenge in hyperspectral images. Active Learning (AL) and Semisupervised Learning (SSL) are two promising techniques to achieve this challenge. Combining AL with SSL is an excellent idea for hyperspectral image classification. The traditional method, such as the Collaborative Active and Semisupervised Learning algorithm (CASSL), may introduce many incorrect pseudolabels and shows premature convergence. To overcome these drawbacks, a novel framework named Double-Strategy-Check Collaborative Active and Semisupervised Learning (DSC-CASSL) is proposed in this paper. This framework combines two different AL algorithms and SSL in a collaborative mode. The double-strategy verification can gradually improve the pseudolabeling accuracy and facilitate SSL. We evaluate the performance of DSC-CASSL on four hyperspectral data sets and compare it with that of four hyperspectral image classification methods. Our results suggest that DSC-CASSL leads to consistent improvement for hyperspectral image classification.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 11 - Year 2019</p>
        </footer>
    </body>
    </html>
    