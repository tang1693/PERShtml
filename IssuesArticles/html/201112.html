<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2011/00000077/00000012/art00001;jsessionid=qb9k8dlf4gpl.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Bias Compensation in a Rigorous Sensor Model and Rational Function Model for High-Resolution Satellite Images
        </a>
    </h3>
    <div style="font-style: italic;">201112, nan</div>
    <div>Authors: Teo, Tee-Ann</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents three bias-compensated models for the geometric correction of high-resolution satellite images. The proposed models include the bias-compensated rigorous sensor model (RSM) in the orbital space, the bias-compensated RSM in the image space, and the bias-compensated rational function model (RFM) in the image space. The RSM and RFM use the on-board data and sensor-oriented rational polynomial coefficients (RPCs) provided in imagery metadata, respectively. Test images include QuickBird, WorldView-1, and WorldView-2 Basic images. Experimental results indicate that the bias-compensated RSM using the zero order polynomials function in the orbital space provides higher accuracy. A comparison of the bias-compensated RSM and RFM in the image space shows that these models behave similarly, and the maximum difference in root-mean-square error is less than 0.1 m. These results show that all the proposed methods obtain accuracy of better than 1 pixel, except for the translation in the image space.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2011/00000077/00000012/art00002;jsessionid=qb9k8dlf4gpl.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Building Feature Extraction from Airborne Lidar Data Based on Tensor Voting Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">201112, pp. 1221-1231(11)</div>
    <div>Authors: You, Rey-Jer; Lin, Bo-Cheng</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study presents a novel approach based on the tensor voting framework for extracting building features from airborne lidar data. Geometric features of lidar points are represented by a tensor field in this paper. For the extraction of roof patches, a region-growing method with principal features is developed from the properties of eigenvalues and eigenvectors of the tensor field. Additionally, three new indicators for the strength of features are presented to reduce the effect of the number of points on feature identification, and a supervised method is proposed to determine the threshold of planar feature strength for the region-growing. The extraction of ridge and edge lines from the segmented roof patches is also discussed. Experiments based on airborne lidar data are described to demonstrate the effectiveness of the proposed method, with those the results compared with the PCA method.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2011/00000077/00000012/art00003;jsessionid=qb9k8dlf4gpl.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Assessment of Internal Neural Network Parameters Affecting Image Classification Accuracy
        </a>
    </h3>
    <div style="font-style: italic;">201112, pp. 1233-1240(8)</div>
    <div>Authors: Zhou, Libin; Yang, Xiaojun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Neural networks are attractive intelligence techniques increasingly being used to classify remote sensor imagery. However, their performance is contingent upon a wide range of algorithm and non-algorithm factors. Despite significant progresses being made over the past two decades, there is no consistent guidance that has been established to automate the use of neural networks in remote sensing. The purpose of this study was to assess several internal parameters affecting image classification accuracy by multi-layer-perceptron (MLP) neural networks. The MLP networks have been considered as the most popular neural network architecture. We carefully configured and trained a set of neural network models with different internal parameter settings. Then, we used these models to classify an Enhanced Thematic Mapper Plus (ETM+) image into several major land cover categories, and the accuracy of each classified map was assessed. The results reveal that number of hidden layers, activation function, and training rate can substantially affect the classification accuracy and that a neural network with appropriate internal parameters can lead to a significant classification accuracy improvement for urban land covers when comparing to the outcome by the Gaussian Maximum Likelihood (GML) classifier. These findings can help design efficient neural network models for improved performance.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2011/00000077/00000012/art00004;jsessionid=qb9k8dlf4gpl.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Landsat-5 TM and Lidar Fusion for Sub-pixel Juniper Tree Cover Estimates in a Western Rangeland
        </a>
    </h3>
    <div style="font-style: italic;">201112, pp. 1241-1248(8)</div>
    <div>Authors: Sankey, Temuulen; Glenn, Nancy</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Pinyon-juniper woodlands comprise the third most common land-cover type in the United States and have been documented to have drastically increased both in density and extent in recent decades. We explored Landsat-5 TM and Light Detection and Ranging (lidar) data, individually and fused together, for estimating sub-pixel juniper cover. Linear spectral unmixing (LSU), Constrained Energy Minimization (CEM), and Mixture Tuned Matched Filtering (MTMF) techniques were compared along with spectral-lidar fusion approaches. None of the Landsat-5 TM-derived estimates were significantly correlated with field-measured juniper cover (n = 100), while lidar-derived estimates were strongly correlated (R2= 0.74, p-value<0.001). Fusion of these estimates produced superior results to both classifications individually (R2= 0.80, p-value<0.001). The MTMF technique performed best, while a multiple regression-based fusion was the best approach to combining the two data sources. Future studies can use the best sub-pixel classification and fusion approach to quantify changes in associated ecosystem properties such as carbon.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2011/00000077/00000012/art00005;jsessionid=qb9k8dlf4gpl.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Development of a Seamless Topographic / Bathymetric Digital Terrain Model for Tampa Bay, Florida
        </a>
    </h3>
    <div style="font-style: italic;">201112, pp. 1249-1256(8)</div>
    <div>Authors: Medeiros, Stephen C.; Ali, Tarig; Hagen, Scott C.; Raiford, John P.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This applications paper presents the methods used to create a seamless topobathy digital terrain model (DTM) at 50-foot resolution intended to support hurricane storm surge modeling in Tampa Bay, Florida. Lidar, bathymetry, and various breakline data were integrated using the Terrain Data Set structure in ArcGISÂ®. The use of the Terrain Data Set structure allowed for embedding large data sets (such as lidar points) and archiving them after DTM creation while maintaining topographic analysis capabilities. The bathy-metric data, natively referenced to Mean Sea Level (MSL), were converted to North American Vertical Datum of 1988 (NAVD88) using an inverse distance weighted average offset from the three nearest NOAA tidal benchmark stations; results of this conversion were within 6.1 centimeters of those produced by NOAA VDatum software in a quality control test area. This methodology can therefore be used in coastal regions of other countries.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2011/00000077/00000012/art00006;jsessionid=qb9k8dlf4gpl.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Scan Problems in Digital CORONA Satellite Images from USGS Archives
        </a>
    </h3>
    <div style="font-style: italic;">201112, pp. 1257-1264(8)</div>
    <div>Authors: Gheyle, Wouter; Bourgeois, Jean; Goossens, Rudi; Jacobsen, Karsten</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The scientific value and relevance of declassified CORONA satellite images has been affirmed by numerous research projects and publications. From 1996 on, duplicates of the CORONA film were available in all standard analog photographic products, including film negatives and photo prints. Since September 2004, the analog imagery is no longer available and has been replaced by digital images produced by the US Geological Survey (USGS) Earth Resources Observation and Science Center (EROS) Scanning Department. This paper points out a heretofore undetected and not negligible problem with the digital imagery. A calibration error in the Leica DSW700 photogrammetric scanner has created gaps between scan tiles. We analyzed the effects these errors have on resulting DSMs and checked the extent of the scanning problem. Part of the USGS archive, i.e. images ordered and scanned between September 2004 and November-December 2007, have comparable scan errors but are nevertheless archived and available for future orders.
            </details>
        </div>
</article>
