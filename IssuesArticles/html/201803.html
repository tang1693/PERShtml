
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 03 - Year 2018</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 03 - Year 2018</h1>
            <p>Displaying articles from Issue 03 - Year 2018.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000003/art00009;jsessionid=w0elsa4ka0a1.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Integrated Image Matching and Segmentation for 3D Surface Reconstruction in Urban Areas
        </a>
    </h3>
    <div style="font-style: italic;">201803, pp. 135-148(14)</div>
    <div>Authors: Ye, Lei; Wu, Bo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                High-resolution imagery, which features the advantages of high-quality imaging, a short revisit time, and lower costs, is an attractive option for 3D reconstruction applications. Photogrammetric 3D reconstruction requires reliable and dense image matching. In urban areas, however, image matching is particularly difficult because of the complexity of urban textures and the severe occlusion problems caused by buildings. This paper presents an integrated image matching and segmentation approach (namedSATM+) for 3D reconstruction in urban areas.SATM+ is based on our existing self-adaptive triangulation-constrained matching (SATM) framework and incorporates three novel aspects to address image matching challenges in urban areas: (1) image segmentation-based occlusion filtering, (2) segment-adaptive similarity measurement to reduce matching ambiguity, and (3) local and regional dense matching propagation to generate reliable and dense matches. We performed an experimental analysis of two sets of high-resolution urban images, and the 3D point clouds generated using the proposedSATM+ were compared with airborne light detection and ranging (lidar) data and the point clouds generated using the semi-global matching (SGM) method. The results indicate thatSATM+ can generate 3D point clouds with a geometric accuracy comparable to that of lidar data but a much higher point density.SATM+ performs similarly to SGM in relatively flat areas, but is superior in built-up areas. The proposed approach is a promising option for image-based 3D surface reconstruction in urban areas.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000003/art00010;jsessionid=w0elsa4ka0a1.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Optimizing Radiometric Fidelity to Enhance Aerial Image Change Detection Utilizing Digital Single Lens Reflex (DSLR) Cameras
        </a>
    </h3>
    <div style="font-style: italic;">201803, pp. 149-158(10)</div>
    <div>Authors: Kerr, Andrew D.; Stow, Douglas A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Our objectives are to analyze the radiometric characteristics and best practices for maximizing radiometric fidelity of digital single lens reflex (DSLR) cameras for aerial image-based change detection. Control settings, exposure values, white balance, light metering,ISO, and lens aperture are evaluated for several bi-temporal imagery datasets. These variables are compared for their effects on dynamic range, intra-frame brightness variation, acuity, temporal consistency, and detectability of simulated cracks. Testing was conducted from a terrestrial, rather than airborne platform, due to the large number of images collected, and to minimize inter-image misregistration. Results point to exposure biases in the range of –0.7 or –0.3EV (i.e., slightly less than the auto-exposure selected levels) being preferable for change detection and noise minimization, by achieving a balance between full dynamic range and high acuity.DSLRcameras exhibit high radiometric fidelity and can effectively support low-cost aerial image-based change detection, such as for post-hazard damage assessment.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000003/art00011;jsessionid=w0elsa4ka0a1.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Evaluation of Close-Range Stereo Matching Algorithms Using Stereoscopic Measurements
        </a>
    </h3>
    <div style="font-style: italic;">201803, pp. 159-167(9)</div>
    <div>Authors: Shin, Dongjoe; Tao, Yu; Muller, Jan-Peter</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The performance of binocular stereo reconstruction is highly dependent on the quality of the stereo matching result. In order to evaluate the performance of different stereo matchers, several quality metrics have been developed based on quantifying error statistics with respect to a set of independent measurements usually referred to as ground truth data. However, such data are frequently not available, particularly in practical applications or planetary data processing. To address this, we propose a ground truth independent evaluation protocol based on manual measurements. A stereo visualization tool has been specifically developed to evaluate the quality of the computed correspondences. We compare the quality of disparity maps calculated from three stereo matching algorithms, developed based on a variation ofGOTCHA, which has been used in planetary robotic rover image reconstruction atUCL-MSSL(Otto and Chau, 1989). From our evaluation tests with the images pairs from Mars Exploration Rover (MER) Pancam and the field data collected in PRoViScout 2012, it has been found that all three processing pipelines used in our test (NASA-JPL,JR,UCL-MSSL) trade off matching accuracy and completeness differently.NASA-JPL's stereo pipeline produces the most accurate but less complete disparity map, whileJR's pipeline performs best in terms of the reconstruction completeness.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 03 - Year 2018</p>
        </footer>
    </body>
    </html>
    