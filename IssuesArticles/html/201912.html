
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 12 - Year 2019</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 12 - Year 2019</h1>
            <p>Displaying articles from Issue 12 - Year 2019.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000012/art00010;jsessionid=7gipfrda5pefm.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Learning Approach to Evaluate the Quality of 3D City Models
        </a>
    </h3>
    <div style="font-style: italic;">201912, pp. 865-878(14)</div>
    <div>Authors: Ennafii, Oussama; Le Bris, Arnaud; Lafarge, Florent; Mallet, Clément</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The automatic generation of three-dimensional (3D) building models from geospatial data is now a standard procedure. An abundance of literature covers the last two decades, and several solutions are now available. However, urban areas are very complex environments. Inevitably, practitioners still have to visually assess, at a city-scale, the correctness of these models and detect frequent reconstruction errors. Such a process relies on experts and is highly time-consuming, with approximately two hours/km 2 per expert. This work proposes an approach for automatically evaluating the quality of 3D building models. Potential errors are compiled in a novel hierarchical and versatile taxonomy. This allows, for the first time, to disentangle fidelity and modeling errors, whatever the level of details of the modeled buildings. The quality of models is predicted using the geometric properties of buildings and, when available, Very High Resolution images and Digital Surface Models. A baseline of handcrafted, yet generic, features is fed into a Random Forest classifier. Both multiclass and multilabel cases are considered: due to the interdependence between classes of errors, it is possible to retrieve all errors at the same time while simply predicting correct and erroneous buildings. The proposed framework was tested on three distinct urban areas in France with more than 3000 buildings. 80%–99% F-score values are attained for the most frequent errors. For scalability purposes, the impact of the urban area composition on the error prediction was also studied, in terms of transferability, generalization, and representativeness of the classifiers. It showed the necessity of multimodal remote sensing data and mixing training samples from various cities to ensure a stability of the detection ratios, even with very limited training set sizes.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000012/art00011;jsessionid=7gipfrda5pefm.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Optimization Method for Hyperspectral Endmember Extraction Based on K-SVD
        </a>
    </h3>
    <div style="font-style: italic;">201912, pp. 879-887(9)</div>
    <div>Authors: Feng, Xiaoxiao; He, Luxiao; Zhang, Ya; Tang, Yun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Mixed pixels are common in hyperspectral imagery (HSI). Due to the complexity of the ground object distribution, some end-member extraction methods cannot obtain good results and the processes are complex. Therefore, this paper proposes an optimization method forHSIendmember extraction, which improves the accuracy of the results based on K-singular value decomposition (K-SVD). The proposed method comprises three core steps. (1) Based on the contribution value of initial endmembers, partially observed data selected according to the appropriate confidence participate in the calculation. (2) Construction of the error model to eliminate the background noise. (3) Using theK-SVDto perform column-by-column iteration on the endmembers to achieve the overall optimality. Experiments with three real images are applied, demonstrating the proposed method can improve the overall endmember accuracy by 15.1%–55.7% compared with the original methods.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000012/art00012;jsessionid=7gipfrda5pefm.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Comparative Assessment of the Photogrammetric Accuracy of Mapping Using UAVs with Smart Devices
        </a>
    </h3>
    <div style="font-style: italic;">201912, pp. 889-897(9)</div>
    <div>Authors: Jeong, Hohyun; Ahn, Hoyong; Shin, Dongyoon; Ahn, Yushin; Choi, Chuluong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This article evaluatesUAVphotogrammetry systems using smartphones and smart cameras. Image triangulation was conducted in accordance with interior orientation parameters, determined by camera self-calibration. Precise orthomosaic images and digital surface models were generated, and their accuracy was assessed using aerial and terrestrial lidar data. Digital surface models were used to estimate earthwork volumes and verify the suitability ofUAVphotogrammetry for use on construction sites. Georeferencing accuracy shows that the smart camera performs about twice as well as the smartphone with reference to checkpoints and polygon parts. Considering rolling shutter in the smartphone, it is possible to increase accuracy. Especially in inclined and rugged topography, the smartphone can benefit from applying the rolling-shutter method. Earthwork of volume error is often applied as a legal requirement for some countries, and our findings indicate that a smart camera with a drone can be effectively and economically used in earthworks.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000012/art00013;jsessionid=7gipfrda5pefm.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Cost-Effective Coastal Habitat Mapping: Detecting Intertidal Polychaete Aggregations with Low-Altitude Photogrammetry
        </a>
    </h3>
    <div style="font-style: italic;">201912, pp. 899-905(7)</div>
    <div>Authors: Alves, Renata M. S.; Van Colen, Carl; Rabaut, Marijn; De Wulf, Alain; Vincx, Magda; Stal, Cornelis</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Intertidal polychaete aggregations may be protected in the European Union under the Habitats Directive framework as reef habitats. Remote reef mapping remains challenging due to severe and dynamic conditions, as well as cover and spatial resolution requirements. This study (1) evaluated kite aerial photography and low-altitude digital photogrammetry to map and monitor intertidal aggregations of a sessile tube-building polychaete, Lanice conchilega (L. conchilega), and (2) developed a protocol for its remote identification. Monthly campaigns yielded 12 aerial image sets which were processed using structure-from-motion into high-precision digital terrain models and orthophoto mosaics. Maximum likelihood classification distinguished L. conchilega from bare sediment with an accuracy of 70% ± 23.2%. Aggregations were delineated by extracting elements of positive elevation from local difference models. The method has proven useful to detect high-value aggregations, distinguishing these consistently. Nevertheless, systematic biases were present during delineation, and further characterisation of reference aggregations may improve detection.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000012/art00014;jsessionid=7gipfrda5pefm.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Two-Stage Spatiotemporal Fusion Method for Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">201912, pp. 907-914(8)</div>
    <div>Authors: Sun, Yue; Zhang, Hua</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents a two-stage spatiotemporal fusion method for obtaining dense remote sensing images with both high spatial and temporal resolution. Considering the large resolution differences between fine- and coarse-resolution images, the proposed method is implemented in two stages. In the first stage, the input fine- and coarse-resolution images are preprocessed to the same intermediate resolution images, respectively. Then, a linear interpolation model is introduced to fuse these resampled images for predicting preliminary fusion results. In the second stage, a residual dense network is used to learn the nonlinear mapping between the preliminary fusion results and the real fine-resolution data to reconstruct the final fine-resolution data. Two data sets with different land surface types are employed to test the performance of the proposed method. Experimental results show that the proposed method is advantageous in such areas with phenological changes, and even for the data sets with land cover changes being the main type, it still has a good ability to predict spatial structure information of images.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 12 - Year 2019</p>
        </footer>
    </body>
    </html>
    