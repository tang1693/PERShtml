<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000010/art00009;jsessionid=1q28ddewuzxos.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Uncertainty of Forested Wetland Maps Derived from Aerial Photography
        </a>
    </h3>
    <div style="font-style: italic;">202010, pp. 609-617(9)</div>
    <div>Authors: Prisley, Stephen P.; Turner, Jeffery A.; Brown, Mark J.; Schilling, Erik; Lambert, Samuel G.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Forested wetlands (FWs) are economically and environmentally important, so monitoring of change is done using remote sensing by several U.S. federal programs. To better understand classification and delineation uncertainties in FW maps, we assessed agreement between National Wetlands Inventory maps based on aerial photography and field determinations at over 16 000 Forest Inventory and Analysis plots. Analyses included evaluation of temporal differences and spatial uncertainty in plot locations and wetland boundaries. User's accuracy for the wetlands map was 90% for FW and 68% for nonforested wetlands. High levels of false negatives were observed, with less than 40% of field-identified wetland plots mapped as such. Epsilon band analysis indicated that if delineation of FW boundaries in the southeastern U.S. met the data quality standards (5 meters), then the area within uncertainty bounds accounts for 15% to 30% of estimated FW area.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000010/art00010;jsessionid=1q28ddewuzxos.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Weighted Spherical Sampling of Point Clouds for Forested Scenes
        </a>
    </h3>
    <div style="font-style: italic;">202010, pp. 619-625(7)</div>
    <div>Authors: Fafard, Alex; Kargar, Ali Rouzbeh; van Aardt, Jan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Terrestrial laser scanning systems are characterized by a sampling pattern which varies in point density across the hemisphere. Additionally, close objects are over-sampled relative to objects that are farther away. These two effects compound to potentially bias the three-dimensional statistics of measured scenes. Previous methods of sampling have resulted in a loss of structural coherence. In this article, a method of sampling is proposed to optimally sample points while preserving the structure of a scene. Points are sampled along a spherical coordinate system, with probabilities modulated by elevation angle and squared distance from the origin. The proposed approach is validated through visual comparison and stem-volume assessment in a challenging mangrove forest in Micronesia. Compared to several well-known sampling techniques, the proposed approach reduces sampling bias and shows strong performance in stem-reconstruction measurement. The proposed sampling method matched or exceeded the stem-volume measurement accuracy across a variety of tested decimation levels. On average it achieved 3.0% higher accuracy at estimating stem volume than the closest competitor. This approach shows promise for improving the evaluation of terrestrial laser-scanning data in complex scenes.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000010/art00011;jsessionid=1q28ddewuzxos.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Redefining the Directional-Hemispherical Reflectance and Transmittance of Needle-Shaped Leaves to Address Issues in Their Existing Measurement Methods
        </a>
    </h3>
    <div style="font-style: italic;">202010, pp. 627-641(15)</div>
    <div>Authors: Wang, Jun; Chen, Jing M.; Feng, Lian; Xu, Jianhui; Zhang, Feifei</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The directional-hemispherical reflectance and transmittance of needle-shaped leaves are redefined in this study. We suggest that the reflected and transmitted radiation of a leaf should be distinguished by the illuminated and shaded leaf surfaces rather than the usual separation of the two hemispheres by a plane perpendicular to the incoming radiation. Through theoretical analysis, we found that needle directional-hemispherical reflectance and transmittance measured by two existing techniques, namely Daughtry's method and Harron's method, could be significantly biased. This finding was proved by ray-tracing simulations intuitively as well as by inversions of thePROSPECTmodel indirectly. We propose the following requirements for needle spectral measurement in an integrating sphere: needles should be fully exposed to the light source, the interfusion of reflected and transmitted radiation on convex needle surfaces should be avoided, and multiple scattering of radiation among needles should be minimized.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000010/art00012;jsessionid=1q28ddewuzxos.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Pavement Macrotexture Determination Using Multi-View Smartphone Images
        </a>
    </h3>
    <div style="font-style: italic;">202010, pp. 643-651(9)</div>
    <div>Authors: Tian, Xiangxi; Xu, Yong; Wei, Fulu; Gungor, Oguz; Li, Zhixin; Wang, Ce; Li, Shuo; Shan, Jie</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Pavement macrotexture contributes greatly to road surface friction, which in turn plays a vital role in reducing road accidents. Conventional methods for macrotexture measurement are either expensive, time-consuming, or of poor repeatability. Based on multi-view smartphone images collected in situ, this paper develops and evaluates an affordable and convenient alternative approach for pavement macrotexture measurement. Photogrammetric computer vision techniques are first applied to create high resolution point clouds of the pavement. Analytics are then developed to determine the macrotexture metric: mean profile depth by using the image-based point clouds. Experiments are carried out with 790 images over 25 spots on three state routes and six spots at an Indiana Department of Transportation test site. We demonstrate multi-view smartphone images can yield results comparable to the ones from the conventional laser texture scanner. It is expected that the developed approach can be adopted for large scale operational uses.
            </details>
        </div>
</article>
