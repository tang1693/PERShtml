<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000009/art00010;jsessionid=558007tlvpqlu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Gaussian Mixture Model of Ground Filtering Based on Hierarchical Curvature Constraints for Airborne Lidar Point Clouds
        </a>
    </h3>
    <div style="font-style: italic;">202109, pp. 615-630(16)</div>
    <div>Authors: Ye, Longjie; Zhang, Ka; Xiao, Wen; Sheng, Yehua; Su, Dong; Wang, Pengbo; Zhang, Shan; Zhao, Na; Chen, Hui</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper proposes a Gaussian mixture model of a ground filtering method based on hierarchical curvature constraints. Firstly, the thin plate spline function is iteratively applied to interpolate the reference surface. Secondly, gradually changing grid size and curvature threshold are used to construct hierarchical constraints. Finally, an adaptive height difference classifier based on the Gaussian mixture model is proposed. Using the latent variables obtained by the expectation-maximization algorithm, the posterior probability of each point is computed. As a result, ground and objects can be marked separately according to the calculated possibility. 15 data samples provided by the International Society for Photogrammetry and Remote Sensing are used to verify the proposed method, which is also compared with eight classical filtering algorithms. Experimental results demonstrate that the average total errors and average Cohen's kappa coefficient of the proposed method are 6.91% and 80.9%, respectively. In general, it has better performance in areas with terrain discontinuities and bridges.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000009/art00011;jsessionid=558007tlvpqlu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Detecting Geo-Positional Bias in Imagery Collected Using Small UASs
        </a>
    </h3>
    <div style="font-style: italic;">202109, pp. 631-638(8)</div>
    <div>Authors: Thayn, Jonathan B.; Paque, Aaron M.; Maher, Megan C.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Statistical methods for detecting bias in global positioning system (GPS) error are presented and applied to imagery collected using three common unmanned aerial systems (UASs). Imagery processed without ground control points (GCPs) had horizontal errors of 1.0â€“2.5 m; however, the errors had unequal variances, significant directional bias, and did not conform to the expected statistical distribution and so should be considered unreliable. WhenGCPswere used, horizontal errors decreased to less than 5 cm, and the errors had equal variances, directional uniformity, and they conformed to the expected distribution. The analysis identified a longitudinal bias in some of the reference data, which were subsequently excluded from the analysis. Had these data been retained, the estimates of positional accuracy would have been unreliable and inaccurate. These results strongly suggest that examiningGPSdata for bias should be a much more common practice.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000009/art00012;jsessionid=558007tlvpqlu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Double Adaptive Intensity-Threshold Method for Uneven Lidar Data to Extract Road Markings
        </a>
    </h3>
    <div style="font-style: italic;">202109, pp. 639-648(10)</div>
    <div>Authors: Ye, Chengming; Li, Hongfu; Wei, Ruilong; Wang, Lixuan; Sui, Tianbo; Bai, Wensen; Saied, Pirasteh</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Due to the large volume and high redundancy of point clouds, there are many dilemmas in road-marking extraction algorithms, especially from uneven lidar point clouds. To extract road markings efficiently, this study presents a novel method for handling the uneven density distribution of point clouds and the high reflection intensity of road markings. The method first segments the point-cloud data into blocks perpendicular to the vehicle trajectory. Then it applies the double adaptive intensity-threshold method to extract road markings from road surfaces. Finally, it performs an adaptive spatial density filter based on the density distribution of point-cloud data to remove false road-marking points. The average completeness, correctness, and F measure of road-marking extraction are 0.827, 0.887, and 0.854, respectively, indicating that the proposed method is efficient and robust.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000009/art00013;jsessionid=558007tlvpqlu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Estimating Regional Soil Moisture with Synergistic Use of AMSR2 and MODIS Images
        </a>
    </h3>
    <div style="font-style: italic;">202109, pp. 649-660(12)</div>
    <div>Authors: Rahimzadegan, Majid; Davari, Arash; Sayadi, Ali</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Soil moisture content (SMC), product of Advanced Microwave Scanning Radiometer 2 (AMSR2), is not at an adequate level of accuracy on a regional scale. The aim of this study is to introduce a simple method to estimate SMC while synergistically using AMSR2 and Moderate Resolution Imaging Spectroradiometer (MODIS) measurements with a higher accuracy on a regional scale. Two MODIS products, including daily reflectance (MYD021) and nighttime land surface temperature (LST) products were used. In 2015, 1442 in situ SMC measurements from six stations in Iran were used as ground-truth data. Twenty models were evaluated using combinations of polarization index (PI), index of soil wetness (ISW), normalized difference vegetation index (NDVI), and LST. The model revealed the best results using a quadratic combination of PI and ISW, a linear form of LST, and a constant value. The overall correlation coefficient, root-mean-square error, and mean absolute error were 0.59, 4.62%, and 3.01%, respectively.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000009/art00014;jsessionid=558007tlvpqlu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Optimal Regularization Method Based on the L-Curve for Solving Rational Function Model Parameters
        </a>
    </h3>
    <div style="font-style: italic;">202109, pp. 661-668(8)</div>
    <div>Authors: Zhou, Guoqing; Yuan, Man; Li, Xiaozhu; Sha, Hongjun; Xu, Jiasheng; Song, Bo; Wang, Feng</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Rational polynomial coefficients in a rational function model (RFM) have high correlation and redundancy, especially in high-orderRFMs, which results in ill-posed problems of the normal equation. For this reason, this article presents an optimal regularization method with the L-curve for solving rational polynomial coefficients. This method estimates the rational polynomial coefficients of anRFMusing the L-curve and finds the optimal regularization parameter with the minimum mean square error, then solves the parameters of theRFMby the Tikhonov method based on the optimal regularization parameter. The proposed method is validated in both terrain-dependent and terrain-independent cases using Gaofen-1 and aerial images, respectively, and compared with the least-squares method, L-curve method, and generalized cross-validation method. The experimental results demonstrate that the proposed method can solve theRFMparameters effectively, and their accuracy is increased by more than 85% on average relative to the other methods.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000009/art00015;jsessionid=558007tlvpqlu.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Scene-Change Detection Based on Multi-Feature-Fusion Latent Dirichlet Allocation Model for High-Spatial-Resolution Remote Sensing Imagery
        </a>
    </h3>
    <div style="font-style: italic;">202109, pp. 669-681(13)</div>
    <div>Authors: Li, Xiaoman; Zhong, Yanfei; Su, Yu; Ye, Richen</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                With the continuous development of high-spatial-resolution ground observation technology, it is now becoming possible to obtain more and more high-resolution images, which provide us with the possibility to understand remote sensing images at the semantic level. Compared with traditional pixel- and object-oriented methods of change detection, scene-change detection can provide us with land use change information at the semantic level, and can thus provide reliable information for urban land use change detection, urban planning, and government management. Most of the current scene-change detection methods are based on the visual-words expression of the bag-of-visual-words model and the single-feature-based latent Dirichlet allocation model. In this article, a scene-change detection method for high-spatial-resolution imagery is proposed based on a multi-feature-fusion latent Dirich- let allocation model. This method combines the spectral, textural, and spatial features of the high-spatial-resolution images, and the final scene expression is realized through the topic features extracted from the more abstract latent Dirichlet allocation model. Post-classification comparison is then used to detect changes in the scene images at different times. A series of experiments demonstrates that, compared with the traditional bag-of-words and topic models, the proposed method can obtain superior scene-change detection results.
            </details>
        </div>
</article>
