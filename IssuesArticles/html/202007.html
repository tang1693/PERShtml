
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 07 - Year 2020</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 07 - Year 2020</h1>
            <p>Displaying articles from Issue 07 - Year 2020.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000007/art00008;jsessionid=4pq5f0tfec8l5.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A History of Laser Scanning, Part 1: Space and Defense Applications
        </a>
    </h3>
    <div style="font-style: italic;">202007, pp. 419-429(11)</div>
    <div>Authors: Spring, Adam P.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This article presents the origins and evolution of midrange terrestrial laser scanning (TLS), spanning primarily from the 1950s to the time of publication. Particular attention is given to developments in hardware and software that document the physical dimensions of a scene as a point cloud. These developments include parameters for accuracy, repeatability, and resolution in the midrange—millimeter and centimeter levels when recording objects at building and landscape scales up to a kilometer away. The article is split into two parts: Part one starts with early space and defense applications, and part two examines the survey applications that formed aroundTLStechnologies in the 1990s. The origins of midrangeTLS, ironically, begin in space and defense applications, which shaped the development of sensors and information processing via autonomous vehicles. Included are planetary rovers, space shuttles, robots, and land vehicles designed for relative navigation in hostile environments like space and war zones. Key people in the midrangeTLScommunity were consulted throughout the 10-year period over which this article was written. A multilingual and multidisciplinary literature review—comprising media written or produced in Chinese, English, French, German, Japanese, Italian, and Russian—was also an integral part of this research.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000007/art00009;jsessionid=4pq5f0tfec8l5.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Improved Crop Classification with Rotation Knowledge using Sentinel-1 and -2 Time Series
        </a>
    </h3>
    <div style="font-style: italic;">202007, pp. 431-441(11)</div>
    <div>Authors: Giordano, Sébastien; Bailly, Simon; Landrieu, Loic; Chehata, Nesrine</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Leveraging the recent availability of accurate, frequent, and multimodal (radar and optical) Sentinel-1 and -2 acquisitions, this paper investigates the automation of land parcel identi- fication system (LPIS ) crop type classification. Our approach allows for the automatic integration of temporal knowledge, i.e., crop rotations using existing parcel-based land cover databases and multi-modal Sentinel-1 and -2 time series. The temporal evolution of crop types was modeled with a linear- chain conditional random field, trained with time series of multi-modal (radar and optical) satellite acquisitions and associated LPIS. Our model was tested on two study areas in France (≥1250 km2) which show different crop types, various parcel sizes, and agricultural practices: . the Seine et Marne and the Alpes de Haute-Provence classified accordingly to a fine national 25-class nomenclature. We first trained a Random Forest classifier without temporal structure to achieve 89.0% overall accuracy in Seine et Marne (10 classes) and 73% in Alpes de Haute-Provence (14 classes). We then demonstrated experimentally that taking into account the temporal structure of crop rotation with our model resulted in an increase of 3% to +5% in accuracy. This increase was especially important (+12%) for classes which were poorly classified without using the temporal structure. A stark posi- tive impact was also demonstrated on permanent crops, while it was fairly limited or even detrimental for annual crops.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000007/art00010;jsessionid=4pq5f0tfec8l5.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Improved Depth Estimation for Occlusion Scenes Using a Light-Field Camera
        </a>
    </h3>
    <div style="font-style: italic;">202007, pp. 443-456(14)</div>
    <div>Authors: Yang, Changkun; Liu, Zhaoqin; Di, Kaichang; Hu, Changqing; Wang, Yexin; Liang, Wuyang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                With the development of light-field imaging technology, depth estimation using light-field cameras has become a hot topic in recent years. Even through many algorithms have achieved good performance for depth estimation using light-field cameras, removing the influence of occlusion, especially multi-occlusion, is still a challenging task. The photo-consistency assumption does not hold in the presence of occlusions, which makes most depth estimation of light-field imaging unreliable. In this article, a novel method to handle complex occlusion in depth estimation of light-field imaging is proposed. The method can effectively identify occluded pixels using a refocusing algorithm, accurately select unoccluded views using the adaptive unoccluded-view identification algorithm, and then improve the depth estimation by computing the cost volumes in the unoccluded views. Experimental results demonstrate the advantages of our proposed algorithm compared with conventional state-of-the art algorithms on both synthetic and real light-field data sets.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 07 - Year 2020</p>
        </footer>
    </body>
    </html>
    