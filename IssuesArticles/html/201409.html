
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 09 - Year 2014</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 09 - Year 2014</h1>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000009/art00001;jsessionid=16n4af678wgiw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Generation of Pixel-Level SAR Image Time Series Using a Locally Adaptive Matching Technique
        </a>
    </h3>
    <div style="font-style: italic;">201409, nan</div>
    <div>Authors: Cheng, Liang; Wang, Yafei; Li, Manchun; Zhong, Lishan; Wang, Jiechen</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Synthetic Aperture Radar (SAR) image time series play an important role in many applications. To construct pixel-level SAR image time series, we propose a locally adaptive image matching technique for the high-precision geometric registration of SAR images. The basic idea is to adapt the local characteristics of ground objects during the process of image registration. Then, by analyzing the spatial distribution of the error of each matched pair in the previous iteration, local areas are divided based on the local clustering of pairs with large errors. A new polynomial is then used to satisfy the local geometric constraint. Based on this proposed matching technique, we introduce a pixel-level SAR image time series modeling method. The experimental results show that the average geometric error of corresponding pixels in this algorithm is 0.073 pixels, while that of the NEST software is 0.242 pixels. The Pearson correlation coefficients of 20 pixels’ time series are above 0.85, indicating that the series bears high curve similarity and geometric precision, which suggests the proposed technique can provide high-quality SAR image time series.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000009/art00002;jsessionid=16n4af678wgiw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spectral-Angle-based Laplacian Eigenmaps for Nonlinear Dimensionality Reduction of Hyperspectral Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201409, pp. 849-861(13)</div>
    <div>Authors: Yan, Lin; Niu, Xutong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In traditional manifold learning of hyperspectral imagery, distances among pixels are defined in terms of Euclidean distance, which is not necessarily the best choice because of its sensitivity to variations in spectrum magnitudes. Selecting Laplacian Eigenmaps (LE) as the test method, this paper studies the effects of distance metric selection inLEand proposes a spectral-angle-based LE method (LE-SA) to be compared against the traditional LE-based on Euclidean distance (LE-ED). LE-SA and LE-ED were applied to two airborne hyperspectral data sets and the dimensionality-reduced data were quantitatively evaluated. Experimental results demonstrated that LE-SA is able to suppress the variations within the same type of features, such as variations in vegetation and those in illuminations due to shade or orientations, and maintain a higher level of overall separability among different features than LE-ED. Further, the potential usage of a single LE-SA or LE-ED band for target detection is discussed.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000009/art00003;jsessionid=16n4af678wgiw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Generating Pit-free Canopy Height Models from Airborne Lidar
        </a>
    </h3>
    <div style="font-style: italic;">201409, pp. 863-872(10)</div>
    <div>Authors: Khosravipour, Anahita; Skidmore, Andrew K.; Isenburg, Martin; Wang, Tiejun; Hussin, Yousif A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Canopy height models (CHMs) derived from lidar data have been applied to extract forest inventory parameters. However, variations in modeled height cause data pits, which form a challenging problem as they disrupt CHM smoothness, negatively affecting tree detection and subsequent biophysical measurements. These pits appear where laser beams penetrate deeply into a tree crown, hitting a lower branch or the ground before producing the first return. In this study, we develop a new algorithm that generates a pit-free CHM raster, by using subsets of the lidar points to close pits. The algorithm operates robustly on high-density lidar data as well as on a thinned lidar dataset. The evaluation involves detecting individual trees using the pit-free CHM and comparing the findings to those achieved by using a Gaussian smoothed CHM. The results show that our pit-freeCHMsderived from high-and low-density lidar data significantly improve the accuracy of tree detection.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000009/art00004;jsessionid=16n4af678wgiw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Hierarchical Building Detection Method for Very High Resolution Remotely Sensed Images Combined with DSM Using Graph Cut Optimization
        </a>
    </h3>
    <div style="font-style: italic;">201409, pp. 873-883(11)</div>
    <div>Authors: Qin, Rongjun; Fang, Wei</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Detecting buildings in remotely sensed data plays an important role for urban analysis and geographical information systems. This study proposes a hierarchical approach for extracting buildings from very high resolution (9 cm GSD (Ground Sampling Distance)), multi-spectral aerial images and matched DSMs (Digital Surface Models). There are three steps in the proposed method: first, shadows are detected with a morphological index, and corrected for NDVI (Normalized Difference Vegetation Index) computation; second, the NDVI is incorporated using a top-hat reconstruction of the DSM to obtain the initial building mask; finally, a graph cut optimization based on modified superpixel segmentation is carried out to consolidate building segments with high probability and thus eliminates segments that have low probability to be buildings. Experiments were performed over the whole Vaihingen dataset, covering 3.4 km2with around 3000 buildings. The proposed algorithm effectively extracted 94 percent of the buildings with 87 percent correctness. This demonstrates that the proposed method achieved satisfactory results over a large dataset and has the potential for many practical applications.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000009/art00005;jsessionid=16n4af678wgiw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            WorldView-2 High Spatial Resolution Improves Desert Invasive Plant Detection
        </a>
    </h3>
    <div style="font-style: italic;">201409, pp. 885-893(9)</div>
    <div>Authors: Sankey, Temuulen; Dickson, Brett; Sesnie, Steve; Wang, Ophelia; Olsson, Aaron; Zachmann, Luke</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Sahara mustard (Brassica tournefortii) is an invasive species common to the Mojave and Sonoran Deserts in the southwestern US. Our objective was to assess WorldView-2 (WV2) satellite imagery potential to detect Sahara mustard presence, cover, and biomass. We compared WV2 images (2.4 m and 30 m resolution) to Landsat ETM+ image both classified using a mixture tuned matched filtering (MTMF). A total of 1,885 field plots (30 × 30 m) were established across a 8,715 km2study area in spring of 2012, an exceptionally dry year. Average target canopy cover (7.5 percent) and biomass (0.82 g/m2) were extremely low. The WV2 MTMF classification had a much greater overall accuracy of 88 percent, while the resampled WV2 and the Landsat ETM+ MTMF classification overall accuracies were 67 percent and 59 percent, respectively. Producer’s and user’s accuracies in target detection were 86 percent and 94 percent, respectively, although the exceptionally low canopy cover and biomass were not well correlated with image-based estimates.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000009/art00006;jsessionid=16n4af678wgiw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Very High Resolution Plant Community Mapping at High Moor, Kushiro Wetland
        </a>
    </h3>
    <div style="font-style: italic;">201409, pp. 895-905(11)</div>
    <div>Authors: Yoshino, Kunihiko; Kawaguchi, Sayuri; Kanda, Fusayuki; Kushida, Keiji; Tsai, Fuan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Frequent monitoring of the state of wetlands is important in order to sustain these valuable ecosystems. Reliable reference maps make this monitoring more effective. A very high resolution and reliable vegetation map with a nominal spatial resolution of 2 cm by 2 cm was created for a study area in the high moor in the Kushiro wetland, Japan. The reference map was created using aerial photography recorded in the summer of 1998 with a 35 mm, non-metric camera mounted on a balloon. The study site contains 40 wetland plant community types covering about 10 ha of the high moor. The resulting map shows that belt-like spatial patterns of typical wetland plant community groups can be clearly distinguished and confirmed through visual interpretation and spatial pattern analysis. The optimal spatial resolution for monitoring vegetation in this area using remote sensing is 0.3 m or smaller.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 09 - Year 2014</p>
        </footer>
    </body>
    </html>
    