<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000009/art00015;jsessionid=a3cpq4r9mhg40.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Enhanced 3D Mapping with an RGB-D Sensor via Integration of Depth Measurements and Image Sequences
        </a>
    </h3>
    <div style="font-style: italic;">201909, pp. 633-642(10)</div>
    <div>Authors: Wu, Bo; Ge, Xuming; Xie, Linfu; Chen, Wu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                State-of-the-art visual simultaneous localization and mapping (SLAM) techniques greatly facilitate three-dimensional (3D) mapping and modeling with the use of low-cost red-green-blue-depth (RGB-D) sensors. However, the effective range of such sensors is limited due to the working range of the infra-red (IR) camera, which provides depth information, and thus the practicability of such sensors in 3D mapping and modeling is limited. To address this limitation, we present a novel solution for enhanced 3D mapping using a low-cost RGB-D sensor. We carry out state-of-the-art visual SLAM to obtain 3D point clouds within the mapping range of the RGB-D sensor and implement an improved structure-from-motion (SfM) on the collected RGB image sequences with additional constraints from the depth information to produce image-based 3D point clouds. We then develop a feature-based scale-adaptive registration to merge the gained point clouds to further generate enhanced and extended 3D mapping results. We use two challenging test sites to examine the proposed method. At these two sites, the coverage of both generated 3D models increases by more than 50% with the proposed solution. Moreover, the proposed solution achieves a geometric accuracy of about 1% in a measurement range of about 20 m. These positive experimental results not only demonstrate the feasibility and practicality of the proposed solution but also its potential.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000009/art00016;jsessionid=a3cpq4r9mhg40.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Geometric Calibration for the Aerial Line Scanning Camera GFXJ
        </a>
    </h3>
    <div style="font-style: italic;">201909, pp. 643-658(16)</div>
    <div>Authors: Wang, Tao; Zhang, Yan; Zhang, Yongsheng; Jiang, Gangwu; Zhang, Zhenghao; Yu, Ying; Dou, Lijun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The Gao Fen Xiang Ji (GFXJ) is the first Chinese self–developed airborne three–line array charge-coupled devices (CCD) camera and is designed to meet 8 cm ground sample distance (GSD), 0.5 m planimetry accuracy, and 0.28 m elevation accuracy for ground three-dimensional (3D) points at a flight height of 2000 m. These values also meet the 1:1000 scale mapping requirements in China. However, the original direct geopositioning accuracy of the GFXJ is approximately 4 m in the planimetry direction and 6 m in the elevation direction. To meet the ground 3D point accuracy requirements and improve the direct geopositioning accuracy of the GFXJ, this paper carries out a deep investigation on the GFXJ geometric calibration. This geometric calibration includes two main parts: the Global Navigation Satellite System (GNSS) lever arms and inertial measurement unit (IMU) boresight misalignment calibration, and the camera lens and CCD line distortion calibration. First, a brief introduction is given on the imaging properties of the GFXJ camera. Then, the GNSS lever arms and IMU boresight misalignment calibration models are built for the GFXJ camera. Next, a piecewise self-calibration model based on the CCD viewing angle is established for the GFXJ lens and CCD line distortion calibration. Subsequently, an iterative two-step calibration scheme is proposed for the geometric calibration. Finally, experiments were implemented using multiple flight blocks obtained in the Songshan remote sensing comprehensive field and the Hegang area of Heilongjiang Province. Through calibration experiments, geometric calibration values were obtained for the GNSS lever arms and IMU boresight misalignment. Reliable CAM files were independently generated for the forward, nadir, and backward line arrays. The experiments showed that the proposed GNSS lever arms and IMU boresight misalignment calibration models and the piecewise self-calibration model had good applicability and effectiveness for the GFXJ camera. The proposed two-step calibration scheme can significantly enhance the geometric positioning accuracy of the GFXJ camera. The original direct geopositioning accuracy of the GFXJ is approximately 4 m in the planimetry direction and 6 m in the elevation direction. Using the GNSS lever arms and the IMU boresight misalignment calibration values and the CAM files, the positioning accuracy of the GFXJ camera can fulfill the 3D point accuracy requirements and the 1:1000 mapping accuracy requirements at a 2000 m flight height after aerial triangulation with only several ground control points. The planimetry accuracy is approximately 0.2 m, and the elevation accuracy is less than 0.28 m. In addition, the calibration models and calibration scheme established in this paper can provide a reference for calibration studies on other airborne linear array CCD cameras.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000009/art00017;jsessionid=a3cpq4r9mhg40.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Collaborative Sparse Coding with Smoothness Regularization for Hyperspectral-Image Classification
        </a>
    </h3>
    <div style="font-style: italic;">201909, pp. 659-672(14)</div>
    <div>Authors: Liu, Yang; Wang, Ruisheng; Ji, Xiaofei; Wang, Yangyang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Hyperspectral-image (HSI) classification plays a key role in numerous applications in remote sensing, urban planning, and environmental monitoring. Sparse-representation models have been increasingly explored for HSI classification because of their compactness, flexibility, and discriminative power. In this article, a novel HSI scheme is proposed based on collaborative sparse coding combined with smoothness regularization (CSCSR). First, based on the spatial piecewise continuity of HSIs, spectral-spatial preprocessing is performed to improve classification accuracy. Second, a collaborative sparse-coding model with smoothness regularization is proposed and applied for HSI classification. In our model, the sparsity level and smoothness regularization are tuned to improve classification performance. In addition, weighted pixel similarities are computed in pixel neighborhoods and then used to incorporate spatial information in the HSI classification scheme. A feature-sign search algorithm is used for sparse coding of feature descriptors. Experimental results on real HSI data sets demonstrate that the proposed CSCSR method effectively outperforms the current state-of-the-art HSI classifiers in terms of both qualitative and quantitative metrics.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000009/art00018;jsessionid=a3cpq4r9mhg40.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            PPD: Pyramid Patch Descriptor via Convolutional Neural Network
        </a>
    </h3>
    <div style="font-style: italic;">201909, pp. 673-686(14)</div>
    <div>Authors: Wan, Jie; Yilmaz, Alper; Yan, Lei</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Local features play an important role in remote sensing image matching, and handcrafted features have been excessively used in this area for a long time. This article proposes a pyramid convolutional neural triplet network that extracts a 128-dimensional deep descriptor that significantly improves the matching performance. The proposed approach first extracts deep descriptors of the anchor patches and corresponding positive patches in a batch using the proposed pyramid convolutional neural network. Following this step, the approaches chooses the closest negative patch for each anchor patch and corresponding positive patch pair to form the triplet sample based on the descriptor distances among all other image patches in the batch. These triplets are used to optimize the parameters of the network using a new loss function. We evaluated the proposed deep descriptors on two benchmark data sets (Brown and HPatches) as well as real image data sets. The results reveal that the proposed descriptor achieves the state-of-the-art performance on the Brown data set and a comparatively very high performance on the HPatches data set. The proposed approach finds more correct matches than the classical handcrafted feature descriptors on aerial image pairs and is observed to be robust to variations in the viewpoint and illumination.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000009/art00019;jsessionid=a3cpq4r9mhg40.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            How Did Deciduous Rubber Plantations Expand Spatially in China's Xishuangbanna Dai Autonomous Prefecture During 1991–2016?
        </a>
    </h3>
    <div style="font-style: italic;">201909, pp. 687-697(11)</div>
    <div>Authors: Xiao, Chiwei; Li, Peng; Feng, Zhiming</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Rubber plantations have experienced continuous expansion in Xishuangbanna, in southwestern China, since the 1950s. However, the question of how the establishment of adventive rubber trees has spatially expanded in the margin of the Asian tropics in recent decades is not clearly understood. Here, a robust phenology-based algorithm—namely the change rate of the Landsat-derived normalized burn ratio—was modified based on tri-windows (i.e., predefoliation, defoliation, and foliation) and then used to discriminate deciduous rubber plantations from other land cover types by applying a threshold of 1.0 and combining Landsat-based forest masks every five years during 1991–2016. Deciduous rubber plantations increased more than 6.6 times, approximately 3074 km2in 2016, or at an annual rate of about 8% (104 km2/year) in Xishuangbanna over that period, showing two typical expansion trends toward both higher (over 1000 m) and lower (below 600 m) elevations and increasingly spread to borderlands with Laos and Myanmar.
            </details>
        </div>
</article>
