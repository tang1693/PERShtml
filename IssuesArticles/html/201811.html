
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 11 - Year 2018</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 11 - Year 2018</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000011" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000011/art00009;jsessionid=6p3s1pm0hxn7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Coupling Relationship Among Scale Parameter, Segmentation Accuracy, and Classification Accuracy In GeOBIA
        </a>
    </h3>
    <div style="font-style: italic;">201811, pp. 681-693(13)</div>
    <div>Authors: Ming, Dongping; Zhou, Wen; Xu, Lu; Wang, Min; Ma, Yanni</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The quality of multi-scale segmentation mainly consists of intrasegment homogeneity and intersegment heterogeneity; however, it is difficult to synchronously get both high. It is crucial to make it clear which one of these two measures is more important and what is the coupling relationship among segmentation scale parameter, image segmentation and classification accuracy. This paper employs series of segmentation and classification to show that (1) intrasegment homogeneity is more important than intersegment heterogeneity in GeOBIA; there is always highly positive correlation between intrasegment homogeneity and classification accuracy; (2) with the increase of spectral heterogeneity parameter, both image object amount and the intrasegment homogeneity decrease; however the intersegment heterogeneity increases or increases first then decrease after the appropriate scale; and (3) the appropriate scale means there is a compromise between intrasegment homogeneity and intersegment heterogeneity. The research findings are helpful to raise awareness among practitioners who suffer from scale issues in GeOBIA.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000011/art00011;jsessionid=6p3s1pm0hxn7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Characterizing Urban Landscape by Using Fractal-based Texture Information
        </a>
    </h3>
    <div style="font-style: italic;">201811, pp. 695-710(16)</div>
    <div>Authors: Liang, Bingqing; Weng, Qihao</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study examined the potential of integrating fractal texture with spectral information on urban landscape characterization by the maximum likelihood image classifier. The fractal texture was first derived from the red band of a Landsat ETM+ image by applying the triangular prism algorithm at different window sizes. The quality of the twenty-five resultant texture bands were then analyzed by fourteen approaches at both of the pre- and post-classification stages. Results showed all evaluations employed at the pre-classification stage are useful to screen out texture bands more useful than others to facilitate the later supervised image classification. This texture information is observed useful only for classifying medium- and low- density residential categories. The window size leading to the best overall classification accuracy is identified as 31 × 31, implying this scale should be kept as a guideline for future studies if a similar methodology is adopted.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000011/art00012;jsessionid=6p3s1pm0hxn7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spatial Analysis of Two Different Urban Landscapes Using Satellite Images and Landscape Metrics
        </a>
    </h3>
    <div style="font-style: italic;">201811, pp. 711-721(11)</div>
    <div>Authors: Şimşek, Duygu; Sertel, Elif</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This research aims to compare landscape metrics of two different cities having distinct landscape characteristics by using up-to-date, very high resolution SPOT 6/7 images-derived and thematically extensive urban land cover/use (LCLU) maps produced from object based classification approach. Object based classification method was applied to 1.5 m resolution SPOT images in conjunction with some opensource geoinformation in order to create accurate urban LCLU maps. Landscape metrics were calculated using detailed land cover/use classes and comparisons were conducted for two different city landscapes; one having huge industrialized areas and another with urban sites and archeological city residences which was declared as World Cultural Heritage. Patch Density (PD), Edge Density (ED), Largest Patch Index (LPI), Euclidean Nearest Neighbor Distance Distribution (ENN_MN), Area-Weighted Mean Fractal Dimension Index (FRAC_AM) and Contagion (CONTAG) metrics were calculated for two cities using these land cover/use maps. Analyzes of urban areas with landscape metrics allowed objective evaluations to define the structure of urban areas and representation of differences or similarities in the spatial structure of different urban regions.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000011/art00013;jsessionid=6p3s1pm0hxn7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Tea Garden Detection from High-Resolution Imagery Using a Scene-Based Framework
        </a>
    </h3>
    <div style="font-style: italic;">201811, pp. 723-731(9)</div>
    <div>Authors: Huang, Xin; Zhu, Zerun; Li, Yansheng; Wu, Bo; Yang, Michael</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Tea cultivation has a long history in China, and it is one of the pillar industries of the Chinese agricultural economy. It is therefore necessary to map tea gardens for their ongoing management. However, the previous studies have relied on fieldwork to achieve this task, which is time-consuming. In this paper, we propose a framework to map tea gardens using high-resolution remotely sensed imagery, including three scene-based methods: the bag-of-visual-words (BOVW) model, supervised latent Dirichlet allocation (sLDA), and the unsupervised convolutional neural network (UCNN). These methods can develop direct and holistic semantic representations for tea garden scenes composed of multiple sub-objects, thus they are more suitable than the traditional pixel-based or object-based methods, which focus on the local characteristics of pixels or objects. In the experiments undertaken in this study, the three different methods were tested on four datasets from Longyan (Oolong tea), Hangzhou (Longjing tea), and Puer (Puer tea). All the methods achieved a good performance, both quantitatively and visually, and the UCNN outperformed the other methods. Moreover, it was found that the addition of textural features improved the accuracy of the BOVW and sLDA models, but had no effect on the UCNN.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000011/art00014;jsessionid=6p3s1pm0hxn7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Change Detection based on Stacked Generalization System with Segmentation Constraint
        </a>
    </h3>
    <div style="font-style: italic;">201811, pp. 733-741(9)</div>
    <div>Authors: Tan, Kun; Zhang, Yusha; Du, Qian; Du, Peijun; Jin, Xiao; Li, Jiayi</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Change detection based on a multi-classifier ensemble system can take advantage of multiple classifiers to extract change information in remote sensing images. In this paper, an efficient heterogeneous ensemble algorithm, i.e., the stacked generalization (SG) combined with image segmentation, is proposed to construct a simple multi-classifier ensemble system that can offer better detection accuracy with lower computational cost. Due to the rich spatial information in high-spatial-resolution remote sensing images, structure texture (morphological) and statistical texture features are extracted to construct the input data to the ensemble system along with spectral features. In addition, constrained analysis on segmented objects integrates the smaller heterogeneity segmentation map and pixel-wise change map to generate the final change map. The experiments were carried out on two ZY-3 and a QuickBird dataset. The results show that the proposed algorithm can integrate the advantages of both pixel-wise ensemble and object-oriented methods, and effectively improve the accuracy and stability of change detection.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 11 - Year 2018</p>
        </footer>
    </body>
    </html>
    