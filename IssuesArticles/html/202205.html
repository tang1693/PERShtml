
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 05 - Year 2022</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 05 - Year 2022</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000005" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000005/art00008;jsessionid=1s8y9hf5f2x5n.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Smartphone Digital Photography for Fractional Vegetation Cover Estimation
        </a>
    </h3>
    <div style="font-style: italic;">202205, pp. 303-310(8)</div>
    <div>Authors: Yin, Gaofei; Qu, Yonghua; Verger, Aleixandre; Li, Jing; Jia, Kun; Xie, Qiaoyun; Liu, Guoxiang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Accurate ground measurements of fractional vegetation cover (FVC) are key for characterizing ecosystem functions and evaluating remote sensing products. The increasing performance of cameras equipped in smartphones opens new opportunities for extensive FVC measurement through citizen science initiatives. However, the wide field of view (FOV) of smartphone cameras constitutes a key source of uncertainty in the estimation of vegetation parameters, which has been largely ignored. We designed a practical method to characterize the FOV of smartphones and improve the FVC estimation. The method was assessed in a mountainous forest based on the comparison with in situ fisheye photographs. After the FOV correction, the agreement of smart-phone and fisheye FVC estimates highly improved: root-mean-square error (RMSE) of 0.103 compared to 0.242 of the original smartphone FVC estimates without considering the FOV effect, mean difference of 0.074 versus 0.213, and coefficient of determinationR2of 0.719 versus 0.353. Smartphone cameras outperform traditional fisheye cameras: the overexposure and low vertical resolution of fisheye photographs introduced uncertainties in FVCestimation while the insensitivity to exposure and high spatial resolution of smartphone cameras make photograph acquisition and analysis more automatic and accurate. The smartphone FVCestimates highly agree with the GF-1 satellite product: RMSE = 0.066, bias = 0.007, andR2= 0.745. This study opens new perspectives for the validation of satellite products.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000005/art00009;jsessionid=1s8y9hf5f2x5n.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Low-Cost and Portable Indoor 3D Mapping Approach Using Biaxial Line Laser Scanners and a One-Dimension Laser Range Finder Integrated with Microelectromechanical Systems
        </a>
    </h3>
    <div style="font-style: italic;">202205, pp. 311-321(11)</div>
    <div>Authors: Duan, Xuzhe; Hu, Qingwu; Zhao, Pengcheng; Wang, Shaohua</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Existing indoor 3D mapping solutions suffer from high cost and poor portability. In this article, a low-cost and portable indoor 3D mapping approach using biaxial line laser scanners and a one-dimension laser range finder integrated with microelectromechanical systems is proposed. A multiple-sensor calibration approach is presented to perform the extrinsic calibration of the integrated 3D mapping system. The 2D point cloud acquired by the horizontal laser scanner and the orientation information obtained by the microelectromechanical systems are used as inputs for a simultaneous localization and mapping framework to estimate the 2D poses. The height information acquired by the laser range finder is then fused to obtain the 3D pose, which is applied to restore the actual position and orientation of the 2D point cloud generated by the tilted laser scanner to reconstruct the 3D point cloud of the indoor environment. The experimental results—three typical indoor scenes—demonstrate that the proposed approach can achieve accuracies of 3 cm and 2°. Therefore, the proposed approach is a low-cost, portable, and accurate solution for indoor 3D mapping.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000005/art00011;jsessionid=1s8y9hf5f2x5n.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Alternative Procedure to Improve the Positioning Accuracy of Orthomosaic Images Acquired with Agisoft Metashape and DJI P4 Multispectral for Crop Growth Observation
        </a>
    </h3>
    <div style="font-style: italic;">202205, pp. 323-332(10)</div>
    <div>Authors: Sakamoto, Toshihiro; Ogawa, Daisuke; Hiura, Satoko; Iwasaki, Nobusuke</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Vegetation indices (VIs), such as the green chlorophyll index and normalized difference vegetation index, are calculated from visible and near-infrared band images for plant diagnosis in crop breeding and field management. The DJI P4 Multispectral drone combined with the Agisoft Metashape Structure from Motion/Multi View Stereo software is some of the most cost-effective equipment for creating high-resolution orthomosaic VI images. However, the manufacturer's procedure results in remarkable location estimation inaccuracy (average error: 3.27–3.45 cm) and alignment errors between spectral bands (average error: 2.80–2.84 cm). We developed alternative processing procedures to overcome these issues, and we achieved a higher positioning accuracy (average error: 1.32–1.38 cm) and better alignment accuracy between spectral bands (average error: 0.26–0.32 cm). The proposed procedure enables precise VI analysis, especially when using the green chlorophyll index for corn, and may help accelerate the application of remote sensing techniques to agriculture.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000005/art00012;jsessionid=1s8y9hf5f2x5n.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Robust Dynamic Indoor Visible Light Positioning Method Based on CMOS Image Sensor
        </a>
    </h3>
    <div style="font-style: italic;">202205, pp. 333-342(10)</div>
    <div>Authors: Sun, Senzhen; Li, Guangyun; Gao, Yangjun; Wang, Li</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A real-time imaging recognition and positioning method based on visible light communication flat light source is proposed. This method images the visible light communication flat light source through the rolling shutter effect of the complementary metal-oxide semiconductor imaging sensor and obtains the rectangular area outline of the light source. The light and dark stripe information of image with the digital image processing method realizes light source matching recognition by defining the concept, the autocorrelation sequence, which can be used to obtain the identity of the light source, and the rectangular vertex coordinate information of flat light source achieves high-precision vision positioning on the basis of inertial measurement unit attitude sensor-assisted imaging. Simultaneously, the corresponding positioning module is developed for positioning testing. The test results indicate that the plane positioning error is less than 4.5 cm, and the positioning frequency is greater than 10 Hz, which provides a high-precision visual positioning solution for indoor positioning.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000005/art00013;jsessionid=1s8y9hf5f2x5n.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Comparing the Sensitivity of Pixel-Based and Sub-Watershed-Based Analytic Hierarchy Process to Weighting Criteria for Flood Hazard Estimation
        </a>
    </h3>
    <div style="font-style: italic;">202205, pp. 343-352(10)</div>
    <div>Authors: Zhang, Hongping; Shao, Zhenfeng; Wu, Wenfu; Huang, Xiao; Sun, Jisong; Zhao, Jinqi; Fan, Yewen</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In flood hazard estimation via the analytic hierarchy process (AHP), using the pixel as the basic unit might lead to accuracy relying on the optimal weighting criteria. To this end, considering the sub-watershed as the basic unit is new. In this study, taking the Chaohu Basin in Anhui Province, China, as a study case, the accuracy of the sensitivity of the pixel-based and sub-watershed-based AHP models influenced by weighting criteria was compared. There were 48 judgment ma- trixes defined, following the same order of importance of the involved indicators. Validation ground truthing is constructed by the extracted flooded regions from GF-3 images. As weighting criteria changed, the results indicated that the pixel-based AHP fluctuated significantly, while the correct ratio and fit ratio derived by the sub-watershed-based AHP could improve by >35% and >5%, respectively, over the pixel-based-AHP. It indicated that the sub-watershed-based AHP has an advantage in relying less on in situ weighting criteria than the pixel-based AHP.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 05 - Year 2022</p>
        </footer>
    </body>
    </html>
    