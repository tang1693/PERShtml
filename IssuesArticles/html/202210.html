<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000010/art00008;jsessionid=75lglrldtg0o7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Novel Residual Attitude Estimation Approach Using Georeferenced Satellite Imagery
        </a>
    </h3>
    <div style="font-style: italic;">202210, pp. 631-641(11)</div>
    <div>Authors: Dubey, Bhaskar; Kartikeyan, B.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This article presents an efficient novel approach estimating residual attitude based on geometrically corrected (GEO ) satellite images. A technique is presented that uses orbital plane geometry to compute the rotation angle as a function of geographic latitude between GEO image space and radiometrically corrected (RAD ) image space. First, a nonlinear forward model is established that translates the residual errors in roll, pitch, and yaw to scan errors and pixel errors in GEO image space. Subsequently, the inverse problem is solved using Newton's method of nonlinear optimization for estimating residual roll, pitch, and yaw. We demonstrate our results on data products of the high-resolution Indian satellites Cartosat-2E and Cartosat-2F. Further, the superiority of the proposed method is established by comparing it with multiple existing methods in the literature. The R2 measures of goodness of fit for roll, pitch, and yaw estimation based on RAD and GEO products using the proposed method are 0.65, 0.99, and 0.65, respectively; using the existing method, they are 0.074, 0.005, and 0.50.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000010/art00009;jsessionid=75lglrldtg0o7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Efficient Building Inventory Extraction from Satellite Imagery for Megacities
        </a>
    </h3>
    <div style="font-style: italic;">202210, pp. 643-652(10)</div>
    <div>Authors: Lo, Edmond Yat-Man; Lin, En-Kai; Daksiya, Velautham; Shao, Kuo-Shih; Chuang, Yi-Rung; Pan, Tso-Chien</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Accurate building inventories are essential for city planning and disaster risk management. Traditionally generated via census or selected small surveys, these suffer from data quality and/or resolution. High-resolution satellite imagery with object segmentation provides an effective alternative, readily capturing large extents. This study develops a highly automated building extraction methodology for location-based building exposure data from high (0.5 m) resolution satellite stereo imagery. The development relied on Taipei test areas covering 13.5 km2before application to the megacity of Jakarta. Of the captured Taipei buildings, 48.8% are at one-to-one extraction, improving to 71.9% for larger buildings with total floor area >8000 m2, and to 99% when tightly-spaced building clusters are further included. Mean absolute error in extracted footprint area is 16% for these larger buildings. The extraction parameters are tuned for Jakarta buildings using small test areas before covering Jakarta's 643 km2with over 1.247 million buildings extracted.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000010/art00011;jsessionid=75lglrldtg0o7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Semi-Supervised Learning Method for Hyperspectral-Image Open Set Classification
        </a>
    </h3>
    <div style="font-style: italic;">202210, pp. 653-664(12)</div>
    <div>Authors: Duan, Zhaolin; Chen, Hao; Li, Xiaohua; Zhou, Jiliu; Wang, Yuan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We present a conceptually simple and flexible method for hyperspectral-image open set classification. Unlike previous methods, where the abundant unlabeled data inherent in the data set are ignored completely and unknown classes are inferred using score post-calibration, our approach makes the unlabeled data join in and help to train a simple and practical model for open set classification. The model is able to provide an explicit decision score for both unknown classes and each known class. The main idea of the proposed method is augmenting the original training set of K known classes using the pseudo-labeled unknown-category samples that are detected elaborately from the unlabeled data using modified OpenMax and semi-supervised iterative learning. Then a (K + 1)-class deep convolutional neural network model is trained based on the augmented training set with (K + 1) class samples. The model can not only classify instances of each known class but also refuse instances of unknown class explicitly. We validated the proposed method on four well-known hyperspectral-image data sets, obtaining superior performance over previous methods.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000010/art00012;jsessionid=75lglrldtg0o7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Fractional Vegetation Cover (FVC) and Associated Driving Factors of Modeling in Mining Areas
        </a>
    </h3>
    <div style="font-style: italic;">202210, pp. 665-671(7)</div>
    <div>Authors: Li, Jun; Guo, Tianyu; Zhang, Chengye; Yang, Fei; Sang, Xiao</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                To determine the fractional vegetation cover (FVC ) and associated driving factors of modeling in mining areas, six types of data were used as driving factors and three methods—multi-linear regression (MLR ), geographically weighted regression (GWR ), and geographically weighted artificial neural network (GWANN )—were adopted in the modeling. The experiments, conducted in Shengli mining areas located in Xilinhot city, China, show that the MLR model without consideration of spatial heterogeneity and spatial non-stationarity performs the worst and that the GWR model presents obvious location differences, since it predefines a linear relationship which is unable to describe FVC for some locations. The GWANN model, improving on these defects, is the most suitable model for the FVC driving process in mining areas; it outperforms the other two models, with root-mean-square error (RMSE ) and mean absolute percentage error (MAPE ) reaching 0.16 and 0.20. It has improvements of approximately 24% in RMSE and 33% in MAPE compared to the MLR model, and those values grow to 59% and 71% when compared with the GWR model.
            </details>
        </div>
</article>
