<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000011/art00001;jsessionid=3hcmklkb8btha.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Method for Detecting Windows from Mobile Lidar Data
        </a>
    </h3>
    <div style="font-style: italic;">201211, nan</div>
    <div>Authors: Wang, Ruisheng; Ferrie, Frank P.; Macfarlane, Jane</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Mobile lidar (light detection and ranging) data collection is a rapidly emerging technology in which multiple georeferenced sensors (e.g., laser scanners, cameras) are mounted on a moving vehicle to collect real world data. The photorealistic modeling of large-scale real world scenes such as urban environments has become increasingly interesting to the vision, graphics, and photogrammetry communities. In this paper, we present an automatic approach to window and facade detection from mobile lidar data. The proposed method combines bottom-up with top-down strategies to extract facade planes from noisy lidar point clouds. The window detection is achieved through a two-step approach: potential window point detection and window localization. The facade pattern is automatically inferred to enhance the robustness of the window detection. Experimental results on six datasets result in 71.2 percent and 88.9 percent in the first two datasets, 100 percent for the rest four datasets in terms of completeness rate, and 100 percent correctness rate for all the tested datasets, which demonstrate the effectiveness of the proposed solution for planar facades with rectilinear windows. The application potential includes generation of building facade models with street-level details and texture synthesis for producing realistic occlusion-free facade texture.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000011/art00002;jsessionid=3hcmklkb8btha.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Aerial Image Mosaicking with the Aid of Vector Roads
        </a>
    </h3>
    <div style="font-style: italic;">201211, pp. 1141-1150(10)</div>
    <div>Authors: Wang, Dongliang; Wan, Youchuan; Xiao, Jianhua; Lai, Xudong; Huang, Wenli; Xu, Jingzhong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper proposes a novel approach for using vector roads to aid in the generation of seamline networks for aerial image mosaicking. A representative seamline is extracted as follows. First, the straight skeleton of the overlapping area of adjacent images is extracted. Second, vector roads in the overlapping regions are overlaid with the extracted skeleton to build a weighted graph G (V, E). Dijkstra’s algorithm is applied to find the lowest-cost path that connects two intersections of the polygons of two adjacent images. The lowest-cost path is considered as a seamline candidate. Finally, the seamline candidate is refined by considering its surrounding pixels. The refined seamline is employed as the final seamline. The resultant seamlines commonly follow the centerlines of roads as much as possible, and the mosaic image appears more seamless. Moreover, the vector-based approach is typically more efficient than the existing raster-based approaches: the vector-based approach is nearly ten times faster than a raster–based representative.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000011/art00003;jsessionid=3hcmklkb8btha.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Nighttime Flood from MODIS Observations Using Support Vector Machines
        </a>
    </h3>
    <div style="font-style: italic;">201211, pp. 1151-1161(11)</div>
    <div>Authors: Zhang, Rui; Sun, Donglian; Yu, Yunyue; Goldberg, Mitchell D.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This work proposes a nighttime flood mapping method for Moderate Resolution Imaging Spectroradiometer (MODIS) data. Brightness temperatures at 3.9[H9262]m, and 11[H9262]m channels (BT 3.9, and BT 11, respectively) and differences of brightness temperatures between 3.9[H9262]m and 4.0[H9262]m, and between 11[H9262]m and 12[H9262]m (BT 3.9-BT 4.0, and BT 11-BT 12, respectively) are used to identify nighttime water pixels by a support vector machines (SVM) classifier. Prominent flood locations are detected by a change detection process using a reference water-land map. To test the effectiveness of the proposed method, two flood cases caused by heavy rains were chosen as trial scenarios. The nighttime mapping results are validated with the flood maps, which are obtained from the visual interpretation based on the daytime flood identification results. The experimental results indicate that the proposed method is effective for the delineation of inundated areas with standing water during the nighttime.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000011/art00004;jsessionid=3hcmklkb8btha.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Integrating Landsat-7 Imagery with Physics-based Models for Quantitative Mapping of Coastal Waters near River Discharges
        </a>
    </h3>
    <div style="font-style: italic;">201211, pp. 1163-1174(12)</div>
    <div>Authors: Pahlevan, Nima; Garrett, Alfred J.; Gerace, Aaron D.; Schott, John R.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Remote sensing has traditionally been used to retrieve water constituents by establishing a relationship between in situ measured quantities and image-derived products. Motivated by the dramatically improved potential of the Landsat Data Continuity Mission (LDCM), this paper describes a different approach for water constituent retrieval where both thermal and visible spectral bands of the Enhanced Thematic Mapper Plus (ETM [H11001]) instrument on board Landsat-7 are utilized. In this effort, Landsat data is integrated with a 3D hydrodynamic model to obtain profiles of particles and dissolved matter in the near shore zone in the vicinity of two river discharges. The procedure is based upon performing many hydrodynamic simulations by adjusting input environmental/physical variables and generating Look-Up-Tables (LUTs). The best match, obtained using optimization, demonstrated an average root-mean-squared-error (RMSE) of 0.68 percent, i.e., 0.0068 reflectance units, calculated over the two river plumes. It is concluded that calibrating a physics-based model using the Landsat-7 imagery can provide a more lucid insight into the dynamics of spatially non-uniform waters.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000011/art00005;jsessionid=3hcmklkb8btha.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automatic Generation of 2.5D Terrain Models without Occluding Routes of Interest
        </a>
    </h3>
    <div style="font-style: italic;">201211, pp. 1175-1185(11)</div>
    <div>Authors: Deng, Hao; Zhang, Liqiang; Ma, Jingtao; Zhang, Liang; Chen, Dong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                When a car drives in mountainous regions, the views based on conventional perspective projection often suffer from features of interest being occluded. We propose a method for generating disocclusion views in mountainous regions. The terrain is segmented to build a potential set of occluders; and then an optimized viewpoint is determined, and elevations are rearranged. To obtain a smooth deformed terrain, a smooth displacement function is introduced to deform the level-of-detail terrain models. Compared with previous methods, the merit of this study lies in automatically generating disocclusion views with temporal coherence, while keeping the details of the deformed terrain the same as the original terrain. Experiments performed on the 4098 pixel 4098 pixel mountainous terrain landscape prove that the disocclusion views can achieve 42 to 58 frames/second. Moreover, the shapes of the features of interest on the driving route without occlusion and the spatial configuration of geographical landmarks in its neighborhood can be easily recognized.
            </details>
        </div>
</article>
