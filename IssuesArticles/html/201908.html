<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000008/art00008;jsessionid=1xlghvdq8krv5.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Roof-Cut Guided Localization for Building Change Detection from Imagery and Footprint Map
        </a>
    </h3>
    <div style="font-style: italic;">201908, pp. 543-558(16)</div>
    <div>Authors: Gong, Jinqi; Hu, Xiangyun; Pang, Shiyan; Wei, Yujun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Identification and monitoring of buildings are of considerable practical value in three-dimensional (3D) reconstruction of building models and urbanization monitoring. Especially for the change detection of buildings with composite structures and relief displacements, heterogeneous appearance and positional inconsistencies are two outstanding issues. In this work, a novel roof-cut approach is developed using graph-based model to locate rooftops and demolished buildings through the use of imagery and preexisting building footprint maps. The building region, boundary, and rooftop contour constraint terms were first formulated by multiple cues derived from both data sources. Next, roof-cut segmentation was performed by gathering all terms required for high-quality unsupervised rooftop extraction. Finally, the positional displacement statistics of similar adjacent buildings were collected to accurately estimate the rooftop location and achieve building demolition detection with the overlap ratio index. Experimental results indicated the effectiveness and generality of the proposed roof-cut algorithm for aerial and satellite images.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000008/art00009;jsessionid=1xlghvdq8krv5.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Contextual Global Registration of Point Clouds in Urban Scenes
        </a>
    </h3>
    <div style="font-style: italic;">201908, pp. 559-571(13)</div>
    <div>Authors: Ge, Xuming; Wu, Bo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents an innovative and powerful approach for contextual global registration of partially overlapping point clouds in urban scenes. First, a fast and robust strategy for extraction of feature points from large-scale scanning scenes is proposed and used to represent the scanning scene. Correspondences are then established using a contextual rule-based method at the two-dimensional and three-dimensional levels. A penalization strategy is then introduced to generate dense corresponding sets between two overlapping point clouds. Finally, a three-stage optimal strategy is implemented to efficiently match these point clouds. The proposed approach highlights the following aspects: (1) The designed voting-based feature extraction method can efficiently and robustly represent a scanning scene in a complex environment with a huge database; (2) The contextual information enables the generation of more reliable correspondences beyond the geometric features; (3) The novel penalization strategy and the three-stage optimal method benefit the approach to achieve tight alignment at a lower computational cost. State-of-art baseline algorithms from the field of photogrammetry are used to evaluate the performance of the proposed method in the comprehensive experiments. The presented approach outperforms other methods in registration accuracy and computational cost.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000008/art00010;jsessionid=1xlghvdq8krv5.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Pavement Marking Retroreflectivity Estimation and Evaluation using Mobile Lidar Data
        </a>
    </h3>
    <div style="font-style: italic;">201908, pp. 573-583(11)</div>
    <div>Authors: Che, Erzhuo; Olsen, Michael J.; Parrish, Christopher E.; Jung, Jaehoon</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Pavement markings are produced with retroreflective materials to enhance visibility for motorists, particularly at night. Retroreflectivity evaluation throughout an extensive highway network for maintenance and asset management purposes is a critical, yet challenging task for transportation agencies because visual evaluation can often be subjective and inconsistent, while field measurement can be time-consuming. Mobile Light Detection and Ranging (Lidar) datasets can potentially provide a safe, cost-effective, and reliable method of performing the required evaluation. This paper presents an empirical model for radiometric calibration of Lidar intensity information from the Leica Pegasus:Two system for pavement marking evaluation. The model was developed using dense handheld retroreflectometer measurements and mobile Lidar data collected in a variety of geometric configurations on a test site consisting of various markings with varying degrees of wear. The quantitative accuracy assessment of the proposed radiometric calibration model for estimating retroreflectivity was conducted to another independent dataset collected in different lanes and system configurations.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000008/art00011;jsessionid=1xlghvdq8krv5.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Total Vertical Uncertainty (TVU) Modeling for Topo-Bathymetric LIDAR Systems
        </a>
    </h3>
    <div style="font-style: italic;">201908, pp. 585-596(12)</div>
    <div>Authors: Eren, Firat; Jung, Jaehoon; Parrish, Christopher E.; Sarkozi-Forfinski, Nicholas; Calder, Brian R.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents a comprehensive total vertical uncertainty (TVU) model for topo-bathymetric Light Detection and Ranging (LIDAR) systems. TheTVUmodel consists of a combination of analytical uncertainty propagation for the subaerial (above water) portion and Monte Carlo simulation models for the subaqueous portion (water surface to seafloor). TheTVUmodel was tested on a topo-bathymetricLIDARdata set collected by National Oceanic and Atmospheric Administration's National Geodetic Survey (NGS) in Southwest Florida, U.S., in May 2016 using a Riegl VQ-880-G topo-bathymetric LIDARsystem. TheTVUvalues were compared against the empirical standard deviation and were found to capture the variability of uncertainty with depth while providing (slightly) conservative estimates of uncertainty. The results may be used to inform data acquisition protocols and data processing models. The model implementation is now beginning to be used operationally atNGSfor topo-bathymetricLIDARprojects.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000008/art00012;jsessionid=1xlghvdq8krv5.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Exploiting Cosegmentation and Geo-Eco Zoning for Land Cover Product Updating
        </a>
    </h3>
    <div style="font-style: italic;">201908, pp. 597-611(15)</div>
    <div>Authors: Zhu, Ling; Sun, Yang; Shi, Ruoming; La, Yixuan; Peng, Shu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Land cover is a commonly used index for characterizing land surface and the corresponding human or natural processes. Remote sensing-based land cover maps must be continuously updated to satisfy the requirements of their users. An incremental updating method for land cover maps based on image cosegmentation and a geo-eco zoning-rule database is presented. First, cosegmentation of multitemporal satellite images is used to extract incremental (land cover change) pixels. Then the reliability of the change-detection results is improved by using the geo-eco zoning-rule database to detect and remove spurious changes. Finally, old land cover maps are updated to create new land cover maps. A test data set of 1200×1200 pixels from GlobeLand30 2000 land cover maps are updated to GlobeLand30 2010 land cover maps with an overall accuracy of 84.6%.
            </details>
        </div>
</article>
