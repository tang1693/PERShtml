<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00001;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Comparison of Four Common Atmospheric Correction Methods
        </a>
    </h3>
    <div style="font-style: italic;">200704, nan</div>
    <div>Authors: Mahiny, Abdolrassoul S.; Turner, Brian J.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Four atmospheric correction methods, two relative and two absolute, were compared in this study. Two of the methods (PIF and RCS) were relative approaches; COST is an absolute image-based method and 6S, an absolute modeling method. The methods were applied to the hazy bands 1 through 4 of a Landsat TM scene of the year 1997, which was being used in a change detection project. The effects of corrections were studied in woodland patches. Three criteria, namely (a) image attributes; (b) image classification results, and (c) landscape metrics, were used for comparing the performance of the correction methods. Average pixel values, dynamic range, and coefficient of variation of bands constituted the first criterion, the area of detected vegetation through image classification was the second criterion, and patch and landscape measures of vegetation the third criterion. Overall, the COST, RCS, and 6S methods performed better than PIF and showed more stable results. The 6S method produced some negative values in bands 2 through 4 due to the unavailability of some data needed in the model. Having to use only a single set of image pixels for normalization in the PIF method and the difficulty of selecting such samples in the study area may be the reasons for its poor performance.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00002;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Rigorous Laboratory Calibration Method for Interior Orientation of an Airborne Linear Push-Broom Camera
        </a>
    </h3>
    <div style="font-style: italic;">200704, pp. 369-374(6)</div>
    <div>Authors: Chen, Tianen; Shibasaki, Ryosuke; Lin, Zongjian</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The linear push-broom camera is one of the most important imaging systems in modern photogrammetry and remote sensing to collect high-resolution digital panchromatic and multispectral images for comprehensive evaluation of natural resources and environmental conditions. Most commercial high-resolution satellites such as SPOT-5, Ikonos-2, and QuickBird use similar sensors. Airborne sensors such as the ADS40 and STARIMAGER®also use the push-broom approach to collect multi-channel, seamless image strips for linear objects such as roads, railways, rivers, seashores, electric power lines, pipe lines, and high-rise building areas. Other commercial hyperspectral sensors also use the push-broom approach to collect digital images for remote sensing applications.High performance linear cameras require high resolution geometric, spectral, and radiometric calibration. This topic has not been covered in the scientific literature. Although the self-calibration is successful to compute the calibration parameters of frame camera, it is denied in our tests since the linear camera’s calibrated parameters are dependent on the accuracy of on-board GPS/IMU position and attitude data. In this paper, a rigorous calibration method is presented. This approach has been successfully used in our developed airborne three-line scanner (TLS) imaging system STARIMAGER®in the last five years. The method can accurately compute TLS’s focal length, principle point location, lens distortion, CCD pixel size, CCD curve deformation, and convergence angles between each CCD line sensor on the focal plane. Without any modification, it can be directly applied to single linear sensors and multi-linear sensors.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00003;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Robustness of Change Detection Algorithms in the Presence of Registration Errors
        </a>
    </h3>
    <div style="font-style: italic;">200704, pp. 375-383(9)</div>
    <div>Authors: Sundaresan, Ashok; Varshney, Pramod K.; Arora, Manoj K.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Accurate registration of multi-temporal remote sensing images is critical to any change detection study. The presence of registration errors in the images may affect the accuracy of change detection. In this paper, we evaluate the performance of two change detection algorithms in the presence of artificially introduced registration errors in the dataset. The algorithms considered are image differencing and an algorithm based on a Markov random field (MRF) model. Registration errors have been introduced in four different ways: only in x direction, only in y direction, in both x and y directions without any rotational misregistration, and finally in both x and y directions together with rotational misregistration. Three temporal datasets, a simulated dataset and two synthetic datasets created from remote sensing images acquired by the Landsat TM sensor, have been used in our study. The results indicate that the change detection algorithm based on the MRF model is more robust to the presence of registration errors than the image differencing method.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00004;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Improvement of Lidar Data Accuracy Using Lidar-Specific Ground Targets
        </a>
    </h3>
    <div style="font-style: italic;">200704, pp. 385-396(12)</div>
    <div>Authors: Csanyi, Nora; Toth, Charles K.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                With recent advances of lidar technology, the accuracy potential of lidar data has significantly improved. State-ofthe-art lidar systems can achieve 2 to 3 cm ranging accuracy under ideal conditions, which is the accuracy level required by engineering scale mapping. However, this is also the accuracy range that cannot be realized by routine navigation-based direct sensor platform orientation. Furthermore, lidar systems are highly integrated multi-sensor systems, and the various components, as well as their spatial relationships, introduce different errors that can degrade the lidar data accuracy. Even after careful system calibration, including individual sensor calibration and sensors intra-calibration, certain errors in the collected data can still be present. These errors are usually dominated by navigation errors and cannot be totally eliminated without introducing absolute control information into the lidar data. Therefore, to support applications that require extremely high, engineering scale mapping accuracy, such as transportation corridor mapping, we propose the use of lidar-specific ground targets. Simulations were performed to determine the most advantageous lidar target design and targets were fabricated based upon the simulation results. To investigate the potential of using control targets for lidar data refinement, test flights were carried out with different flight parameters and target distributions. This paper provides a description of the optimal lidar target design, the target identification algorithm, and a detailed performance analysis, including the investigation of the achievable lidar data accuracy improvement using lidar-specific ground control targets in the case of various target distributions and flight parameters.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00005;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Estimating Nitrogen in Eucalypt Foliage by Automatically Extracting Tree Spectra from HyMap™ Data
        </a>
    </h3>
    <div style="font-style: italic;">200704, pp. 397-401(5)</div>
    <div>Authors: Huang, Zhi; Jia, Xiuping; Turner, Brian J.; Dury, Stephen J.; Wallis, Ian R.; Foley, William J.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Airborne HyMap™ data obtained from the crown reflectance of Eucalyptus melliodora were used to estimate nitrogen in the foliage. Estimating chemical concentrations in individual crowns by remote sensing is especially difficult for eucalypts because, first, there is marked variation between individual crowns and, secondly, separating leaf and background spectral information is difficult. We developed an automatic method to select relatively pure tree pixels for each tree. In this method, the background materials are modeled, and the pixels within a crown that do not resemble the background clusters are regarded as target pixels. A modified partial least squares gave an R2value for predicted versus determined nitrogen concentrations of 0.79, with an RMSE of 0.69 mg/g, less than half the standard deviation of the measured values. Automatically selecting tree pixels was more accurate than manual selection, while the study confirmed that using the maximum spectrum gives results that are as accurate as those from the mean spectrum.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00006;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Generation of Orthoimages and Perspective Views with Automatic Visibility Checking and Texture Blending
        </a>
    </h3>
    <div style="font-style: italic;">200704, pp. 403-411(9)</div>
    <div>Authors: Karras, George E.; Grammatikopoulos, Lazaros; Kalisperakis, Ilias; Petsa, Elli</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Conventional orthorectification software cannot handle surface occlusions and image visibility. The approach presented here synthesizes related work in photogrammetry and computer graphics/vision to automatically produce orthographic and perspective views based on fully 3D surface data (supplied by laser scanning). Surface occlusions in the direction of projection are detected to create the depth map of the new image. This information allows identifying, by visibility checking through back-projection of surface triangles, all source images which are entitled to contribute color to each pixel of the novel image. Weighted texture blending allows regulating the local radiometric contribution of each source image involved, while outlying color values are automatically discarded with a basic statistical test. Experimental results from a close-range project indicate that this fusion of laser scanning with multiview photogrammetry could indeed combine geometric accuracy with high visual quality and speed. A discussion of intended improvements of the algorithm is also included.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2007/00000073/00000004/art00007;jsessionid=28nvpou5gnrp8.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Improving Land-cover Classification Using Recognition Threshold Neural Networks
        </a>
    </h3>
    <div style="font-style: italic;">200704, pp. 413-421(9)</div>
    <div>Authors: Aitkenhead, M.J.; Dyer, R.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The use of neural networks to classify land-cover from remote sensing imagery relies on the ability to determine a winner from the candidate land-cover types based on the imagery information available. In the case of a “winnertakes-all” scenario, this does not allow us a measure of how much the prediction of each pixel’s land-cover can be trusted. We present a three-stage method where only winning candidates which are given a clear lead over the other land-cover types are accepted, with a neighborhood relationship and the application of mixed pixels being used to provide full classification. This method allows us to place more faith in the resulting map than simply taking the winner, and results in a higher accuracy of classification. The method is applied to Landsat imagery of an area of the Philippines where natural, urban, and cultivated land-cover types exist.
            </details>
        </div>
</article>
