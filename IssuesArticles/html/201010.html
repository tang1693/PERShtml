
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 10 - Year 2010</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 10 - Year 2010</h1>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000010/art00001;jsessionid=eoh8p8o2g39e6.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Point Clouds
        </a>
    </h3>
    <div style="font-style: italic;">201010, nan</div>
    <div>Authors: Leberl, F.; Irschara, A.; Pock, T.; Meixner, P.; Gruber, M.; Scholz, S.; Wiechert, A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Novel automated photogrammetry is based on four innovations. First is the cost-free increase of overlap between images when sensing digitally. Second is an improved radiometry. Third is multi-view matching. Fourth is the Graphics Processing Unit (GPU), making complex algorithms for image matching very practical. These innovations lead to improved automation of the photogrammetric workflow so that point clouds are created at sub-pixel accuracy, at very dense intervals, and in near real-time, thereby eroding the unique selling proposition of lidar scanners.Two test projects compare point clouds from aerial and street-side lidar systems with those created from images. We show that the photogrammetric accuracy compares well with the lidar-method, yet the density of surface points is much higher from images, and the throughput is commensurate with a fully automated all-digital approach. Beyond this density, we identify 15 additional advantages of the photogrammetric approach.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000010/art00002;jsessionid=eoh8p8o2g39e6.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Two-step Displacement Correction Algorithm for Registration of Lidar Point Clouds and Aerial Images without Orientation Parameters
        </a>
    </h3>
    <div style="font-style: italic;">201010, pp. 1135-1145(11)</div>
    <div>Authors: Wu, Huayi; Li, Yong; Li, Jonathan; Gong, Jianya</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents a novel linear registration algorithm for lidar point clouds and aerial images without orientation parameters. First, preprocessing is conducted to classify the lidar point clouds into ground points, building points, and aboveground, non-building points. After preprocessing, the algorithm consists of two sequential steps, i.e., Tilt Displacement Correction and Height Displacement Correction. As the kernel of the proposed registration algorithm, the mathematical model for Height Displacement Correction is a set of linear formulas analytically deduced from the rigorous geometric function of a single image. The proposed registration algorithm does not require any orientation parameters for the image, which greatly lowers the requirements for image acquisition. Due to the modelâ€™s linearity, the proposed algorithm is computationally efficient. Our experimental results demonstrate that the proposed algorithm can register aerial images without orientation parameters at the same accuracy level of space resection based on collinear equations. This result fulfills the requirement for the fusion of lidar range data and aerial images in most large-scale urban modeling applications.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000010/art00003;jsessionid=eoh8p8o2g39e6.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Functional Linear Analysis of in situ Hyperspectral Data for Assessing CDOM in Rivers
        </a>
    </h3>
    <div style="font-style: italic;">201010, pp. 1147-1158(12)</div>
    <div>Authors: Yu, Qian; Tian, Yong Q.; Chen, Robert F.; Liu, Anna; Gardner, G. Bernard; Zhu, Weining</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Turbidity and chlorophyll introduce high uncertainty in remote sensing of Chromophoric Dissolved Organic Matter (CDOM) in riverine and coastal water. To reduce the uncertainty, we developed a functional linear model (FLM) to analyze spectral responses to CDOM concentrations observed in a cruise along two rivers and a tidal bay. The analysis was supported with the measurement of high spatial resolution underwater CDOM concentrations and concurrent in situ above-surface hyperspectral remote sensing reflectance. The functional linear model is able to explain up to 91percent of CDOM observations (R2= 0.91, RMSE = 0.0206). The dummy variables of local environmental factors included in the estimation improve CDOM assessment in coastal water. Our analysis suggests that the pattern changes of the FLM coefficient curves provide useful information for understanding the spectral signal interference from turbidity and chlorophyll. This work presents a feasibility study of in situ remote sensing of CDOM on a shipboard platform.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000010/art00004;jsessionid=eoh8p8o2g39e6.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Land Cover Classification in a Complex Urban-Rural Landscape with QuickBird Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201010, pp. 1159-1168(10)</div>
    <div>Authors: Lu, Dengsheng; Hetrick, Scott; Moran, Emilio</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                High spatial resolution images have been increasingly used for urban land-use/land-cover classification, but the high spectral variation within the same land-cover, the spectral confusion among different land-covers, and the shadow problem often lead to poor classification performance based on the traditional per-pixel spectral-based classification methods. This paper explores approaches to improve urban land-cover classification with QuickBird imagery. Traditional per-pixel spectral-based supervised classification, incorporation of textural images and multispectral images, spectral-spatial classifier, and segmentation-based classification are examined in a relatively new developing urban landscape, Lucas do Rio Verde in Mato Grosso State, Brazil. This research shows that use of spatial information during the image classification procedure, either through the integrated use of textural and spectral images or through the use of segmentation-based classification method, can significantly improve land-cover classification performance.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000010/art00005;jsessionid=eoh8p8o2g39e6.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Active Contour and Hill Climbing for Tree Crown Detection and Delineation
        </a>
    </h3>
    <div style="font-style: italic;">201010, pp. 1169-1181(13)</div>
    <div>Authors: Ke, Yinghai; Zhang, Wenhua; Quackenbush, Lindi J.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents a new approach for individual tree crown detection and delineation that is applicable under various imaging conditions. The approach extracts crown area using a region-based active contour model and then detects tree tops within the crown area by considering both spectral and shape characteristics of the crown. The detected tree tops allow subsequent clustering of crown pixels using a new hill-climbing algorithm. We tested the approach on a Norway spruce stand using three types of high spatial resolution imagery: an Emerge natural color vertical aerial image, an off-nadir QuickBird panchromatic image, and a natural color digital orthoimage. In comparison to the published region growing algorithm, our approach improved tree crown detection by over 10 percent for all three types of imagery, and provided accurate tree crown diameter estimation, which has utility in tree volume estimation, species composition, and forest health analysis.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000010/art00006;jsessionid=eoh8p8o2g39e6.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Registration of Terrestrial Photogrammetric Data Using Natural Surfaces as Control
        </a>
    </h3>
    <div style="font-style: italic;">201010, pp. 1183-1193(11)</div>
    <div>Authors: Levin, Shahaf; Filin, Sagi</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We present a model for the alignment of image sets using topographic data as control information. Traditional photogrammetric practices are point-based and require wellmeasured and clearly marked entities within the scene; for repeated measurement, their demarcation should also be durable. Nonetheless, placement of photogrammetric control points oftentimes cannot be readily implemented within the area for documentation. In many of those cases, some form of topographic model, either coarse or fine, exists or can be readily established. This topographic description provides a broad and markerless coverage of control information, which, if modeled appropriately, can substitute the use of a control-point network in the alignment process. We present in this paper a registration model for terrestrial images based on surfaces as control information. The paper addresses both the problem of acquiring mutual corresponding entities and registration based on varying resolutions. The application of the proposed approach is demonstrated on a mapping of an archeological site and for registration of a set of terrestrial images of an open, unstructured scene using airborne laser scanning data. Results show both the applicability of such a model and that estimation comparable in quality to point based observations can be achieved.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 10 - Year 2010</p>
        </footer>
    </body>
    </html>
    