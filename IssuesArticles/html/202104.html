
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 04 - Year 2021</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 04 - Year 2021</h1>
            <p>Displaying articles from Issue 04 - Year 2021.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000004/art00007;jsessionid=f4ldtbaho82bm.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Digital Terrain Modeling Method in Urban Areas by the ICESat-2 (Generating precise terrain surface profiles from photon-counting technology)
        </a>
    </h3>
    <div style="font-style: italic;">202104, pp. 237-248(12)</div>
    <div>Authors: Osama, Nahed; Yang, Bisheng; Ma, Yue; Freeshah, Mohamed</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The ICE, Cloud and land Elevation Satellite-2 (ICES at-2) can provide new measurements of the Earth's elevations through photon-counting technology. Most research has focused on extracting the ground and the canopy photons in vegetated areas. Yet the extraction of the ground photons from urban areas, where the vegetation is mixed with artificial constructions, has not been fully investigated. This article proposes a new method to estimate the ground surface elevations in urban areas. The ICES at-2 signal photons were detected by the improved Density-Based Spatial Clustering of Applications with Noise algorithm and the Advanced Topographic Laser Altimeter System algorithm. The Advanced Land Observing Satellite-1 PALSAR â€“derived digital surface model has been utilized to separate the terrain surface from the ICES at-2 data. A set of ground-truth data was used to evaluate the accuracy of these two methods, and the achieved accuracy was up to 2.7 cm, which makes our method effective and accurate in determining the ground elevation in urban scenes.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000004/art00008;jsessionid=f4ldtbaho82bm.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Novel Class-Specific Object-Based Method for Urban Change Detection Using High-Resolution Remote Sensing Imagery
        </a>
    </h3>
    <div style="font-style: italic;">202104, pp. 249-262(14)</div>
    <div>Authors: Bai, Ting; Sun, Kaimin; Li, Wenzhuo; Li, Deren; Chen, Yepei; Sui, Haigang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A single-scale object-based change-detection classifier can distinguish only global changes in land cover, not the more granular and local changes in urban areas. To overcome this issue, a novel class-specific object-based change-detection method is proposed. This method includes three steps: class-specific scale selection, class-specific classifier selection, and land cover change detection. The first step combines multi-resolution segmentation and a random forest to select the optimal scale for each change type in land cover. The second step links multi-scale hierarchical sampling with a classifier such as random forest, support vector machine, gradient-boosting decision tree, or Adaboost; the algorithm automatically selects the optimal classifier for each change type in land cover. The final step employs the optimal classifier to detect binary changes and from-to changes for each change type in land cover. To validate the proposed method, we applied it to two high-resolution data sets in urban areas and compared the change-detection results of our proposed method with that of principal component analysis k-means, object-based change vector analysis, and support vector machine. The experimental results show that our proposed method is more accurate than the other methods. The proposed method can address the high levels of complexity found in urban areas, although it requires historical land cover maps as auxiliary data.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000004/art00009;jsessionid=f4ldtbaho82bm.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Discovering Potential Illegal Construction Within Building Roofs from UAV Images Using Semantic Segmentation and Object-Based Change Detection
        </a>
    </h3>
    <div style="font-style: italic;">202104, pp. 263-271(9)</div>
    <div>Authors: Liu, Yang; Sun, Yujie; Tao, Shikang; Wang, Min; Shen, Qian; Huang, Jiru</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A novel potential illegal construction (PIC) detection method by bitemporal unmanned aerial vehicle (UAV ) image comparison (change detection) within building roof areas is proposed. In this method, roofs are first extracted from UAV images using a depth-channel improved UNet model. A two-step change detection scheme is then implemented for PIC detection. In the change detection stage, roofs with appearance, disappearance, and shape changes are first extracted by morphological analysis. Subroof primitives are then obtained by roof-constrained image segmentation within the remaining roof areas, and object-based iteratively reweighted multivariate alteration detection (IR-MAD ) is implemented to extract the small PICs from the subroof primitives. The proposed method organically combines deep learning and object-based image analysis, which can identify entire roof changes and locate small object changes within the roofs. Experiments show that the proposed method has better accuracy compared with the other counterparts, including the original IR-MAD, change vector analysis, and principal components analysis-K-means.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000004/art00010;jsessionid=f4ldtbaho82bm.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Error Analysis and Optimization of a Sky Full-Polarization Imaging Detection System
        </a>
    </h3>
    <div style="font-style: italic;">202104, pp. 273-282(10)</div>
    <div>Authors: Chen, Yongtai; Tang, William C.; Chu, Jinkui; Zhang, Ran; Li, Song</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                An accurate sky polarization field map is a prerequisite for polarization navigation applications. In this article, a detector for sky full-polarization imaging detection is described, the major error-influencing factors (MEIFS ) are obtained, and the error propagation is modeled and analyzed. We reveal the relationship between the error of the inversed Stokes vector and the condition number of the detector matrix, which shows that the error of the inversed Stokes vector is affected by the Stokes vector of the incident light itself and the MEIFS together, with the MEIFS playing a decisive role. With the MEIFS optimized, the impact of detector error on the inversed Stokes vector is attenuated. A control equation for system calibration is also deduced which can establish the connection between the detector matrix design and calibration process. The work in this article provides a reference for optimization and calibration of sky full-polarization imaging detectors.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000004/art00011;jsessionid=f4ldtbaho82bm.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Parsing of Urban Facades from 3D Point Clouds Based on a Novel Multi-View Domain
        </a>
    </h3>
    <div style="font-style: italic;">202104, pp. 283-293(11)</div>
    <div>Authors: Wang, Wei; Xu, Yuan; Ren, Yingchao; Wang, Gang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Recently, performance improvement in facade parsing from 3D point clouds has been brought about by designing more complex network structures, which cost huge computing resources and do not take full advantage of prior knowledge of facade structure. Instead, from the perspective of data distribution, we construct a new hierarchical mesh multi-view data domain based on the characteristics of facade objects to achieve fusion of deep-learning models and prior knowledge, thereby significantly improving segmentation accuracy. We comprehensively evaluate the current mainstream method on the RueMonge 2014 data set and demonstrate the superiority of our method. The mean intersection-over-union index on the facade-parsing task reached 76.41%, which is 2.75% higher than the current best result. In addition, through comparative experiments, the reasons for the performance improvement of the proposed method are further analyzed.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000004/art00012;jsessionid=f4ldtbaho82bm.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Scene Classification of Remotely Sensed Images via Densely Connected Convolutional Neural Networks and an Ensemble Classifier
        </a>
    </h3>
    <div style="font-style: italic;">202104, pp. 295-308(14)</div>
    <div>Authors: Cheng, Qimin; Xu, Yuan; Fu, Peng; Li, Jinling; Wang, Wei; Ren, Yingchao</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Deep learning techniques, especially convolutional neural networks, have boosted performance in analyzing and understanding remotely sensed images to a great extent. However, existing scene-classification methods generally neglect local and spatial information that is vital to scene classification of remotely sensed images. In this study, a method of scene classification for remotely sensed images based on pretrained densely connected convolutional neural networks combined with an ensemble classifier is proposed to tackle the under-utilization of local and spatial information for image classification. Specifically, we first exploit the pretrained DenseNet and fine-tuned it to release its potential in remote-sensing image feature representation. Second, a spatial-pyramid structure and an improved Fisher-vector coding strategy are leveraged to further strengthen representation capability and the robustness of the feature map captured from convolutional layers. Then we integrate an ensemble classifier in our network architecture considering that lower attention to feature descriptors. Extensive experiments are conducted, and the proposed method achieves superior performance on UC Merced, AID, and NWPU-RESISC45 data sets.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 04 - Year 2021</p>
        </footer>
    </body>
    </html>
    