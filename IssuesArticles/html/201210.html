
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 10 - Year 2012</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 10 - Year 2012</h1>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000010/art00001;jsessionid=3ogdwj7pek4vk.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Supervised and Fuzzy-based Approach to Determine Optimal Multi-resolution Image Segmentation Parameters
        </a>
    </h3>
    <div style="font-style: italic;">201210, nan</div>
    <div>Authors: Tong, Hengjian; Maxwell, Travis; Zhang, Yun; Dey, Vivek</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Image segmentation is important for object-based classification. One of the most advanced image segmentation techniques is multi-resolution segmentation implemented by eCognition®. Multi-resolution segmentation requires users to determine a set of proper segmentation parameters through a trial-and-error process. To achieve accurate segmentations of objects of different sizes, several sets of segmentation parameters are required: one for each level. However, the trial-and-error process is time consuming and operator dependent. To overcome these problems, this paper introduces a supervised and fuzzy-based approach to determine optimal segmentation parameters for eCognition®. This approach is referred to as the Fuzzy-based Segmentation Parameter optimizer (FBSP optimizer) in this paper. It is based on the idea of discrepancy evaluation to control the merging of sub-segments to reach a target segment. Experiments demonstrate that the approach improves the segmentation accuracy by more than 16 percent, reduces the operation time from two hours to one-half hour, and is operator independent.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000010/art00002;jsessionid=3ogdwj7pek4vk.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automated Georegistration of High-Resolution Satellite Imagery using a RPC Model with Airborne Lidar Information
        </a>
    </h3>
    <div style="font-style: italic;">201210, pp. 1045-1056(12)</div>
    <div>Authors: Oh, Jaehong; Lee, Changno; Eo, Yangdam; Bethel, James</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A large amount high-resolution satellite imagery (HRSI) has been available in the commercial market because of its value in creating accurate base maps for various applications. As massive amounts of HRSI are acquired globally by satellites with short revisit times, automated but accurate georegistration is still required despite advances in precise orbit tracking and estimation. Motivated by the attractive properties of airborne lidar data, such as their high resolution and accuracy, this study proposes a new automated method for refining the HRSI with rational polynomial coefficients (RPCs) using airborne lidar information. By projecting the lidar intensity return into the HRSI space, the image matching complexity is reduced to a simple, 2D case. The true challenge is in overcoming the difference between the HRSI and the lidar intensity return to allow for reliable matching. To this end, this paper proposes a new method based on simple relative edge cross correlation (RECC) with a screening method to prevent false matching. To make the approach more robust, data snooping was added for a final detection of outliers. Experiments were performed using three Kompsat-2 images and the potential of the approach was confirmed, showing sub-pixel accuracy.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000010/art00003;jsessionid=3ogdwj7pek4vk.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Generation of a U.S. National Urban Land-Use Product
        </a>
    </h3>
    <div style="font-style: italic;">201210, pp. 1057-1068(12)</div>
    <div>Authors: Falcone, James A.; Homer, Collin G.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Characterization of urban land uses is essential for many applications. However, differentiating among thematicallydetailed urban land uses (residential, commercial, industrial, institutional, recreational, etc.) over broad areas is challenging, in part because image-based solutions are not ideal for establishing the contextual basis for identifying economic function and use. At present no current United States national-scale mapping exists for urban land uses similar to the classical Anderson Level II classification. This paper describes a product that maps urban land uses, and is linked to and corresponds with the National Land Cover Database (NLCD) 2006. In this product, NLCD urban pixels, in addition to their current imperviousness intensity classification, are assigned one of nine urban use classes based on information drawn from multiple data sources. These sources include detailed infrastructure information, population characteristics, and historical land use. The result is a method for creating a 30 m national-scale grid providing thematically-detailed urban land use information which complements the NLCD. Initial results for 10 major metropolitan areas are provided as an on-line link. Accuracy assessment of initial products yielded an overall accuracy of 81.6 percent.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000010/art00004;jsessionid=3ogdwj7pek4vk.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Flexible Mathematical Method for Camera Calibration in Digital Aerial Photogrammetry
        </a>
    </h3>
    <div style="font-style: italic;">201210, pp. 1069-1077(9)</div>
    <div>Authors: Tang, Rongfu; Fritsch, Dieter; Cramer, Michael; Schneider, Werner</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Self-calibration plays a significant role in the automatic interior/exterior orientation of camera systems. This paper presents a new family of self-calibration additional parameters (APs) for digital airborne camera calibration. Photogrammetric self-calibration can (to a very large extent) be considered as a function approximation problem in mathematics. Based on the rigorous approximation theory, a new family of so-calledLegendre self-calibration APsis developed from the orthogonal Legendre Polynomials. An approach is suggested to assess the full potential of in-situ camera calibration. The performance of Legendre APs is investigated in many field tests on the DMC, UltracamX, UltracamXp and DigiCAM camera systems. The external accuracy in the tests can reach 0.2 GSD and 0.4 GSD in horizontal and vertical dimensions, respectively. The posterior standard deviation estimation of image measurements is approx. 0.12 pixel or even less. The advantages of Legendre APs are illustrated over the conventional counterparts. From both the theoretical and practical views, Legendre APs are orthogonal, rigorous, flexible, and effective for calibrating frame-format airborne cameras.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000010/art00005;jsessionid=3ogdwj7pek4vk.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Individual Tree Species in an Urban Forest Using Airborne Lidar Data and Hyperspectral Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201210, pp. 1079-1087(9)</div>
    <div>Authors: Zhang, Caiyun; Qiu, Fang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We developed a neural network based approach to identify urban tree species at the individual tree level from lidar and hyperspectral imagery. This approach is capable of modeling the characteristics of multiple spectral signatures within each species using an internally unsupervised engine, and is able to catch spectral differences between species using an externally supervised system. To generate a species-level map for an urban forest with high spatial heterogeneity and species diversity, we conducted a treetop-based species identification. This can avoid the problems of double-sided illumination, shadow, and mixed pixels, encountered in the crown-based species classification. The study indicates lidar data in conjunction with hyperspectral imagery are not only capable of detecting individual trees and estimating their tree metrics, but also identifying their species types using the developed algorithm. The integration of these two data sources has great potential to take the place of traditional field surveys.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2012/00000078/00000010/art00006;jsessionid=3ogdwj7pek4vk.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Operational Utilization of Aerial Multispectral Remote Sensing during Oil Spill Response
        </a>
    </h3>
    <div style="font-style: italic;">201210, pp. 1089-1102(14)</div>
    <div>Authors: Svejkovsky, Jan; Lehr, William; Muskat, Judd; Graettinger, George; Mullin, Joseph</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A rapidly deployable aerial multispectral sensor utilizing four channels in the visible-near-IR and one channel in the thermal IR was developed along with processing software to identify oil-on-water and map its spatial extents and thickness distribution patterns. Following validation over natural oil seeps and at Bureau of Safety and Environmental Enforcement’s (BSEE’s) Ohmsett test tank, the system was utilized operationally on a near-daily basis for three months during the Deepwater Horizon (MC-252) spill in the Gulf of Mexico in summer 2010. Digital, GIS-compatible analyses were produced and disseminated following each flight mission. The analysis products were utilized for a multitude of response activities including daily offshore oil recovery planning, oil trajectory modeling, dispersant application effect documentation, beached oil mapping and documentation of the relative oil amount along the spill’s offshore perimeter. The system’s prime limitation was its relatively narrow imaging footprint and low sun angle requirement to minimize sunglint, both of which limited the total area that could be imaged each day. This paper discusses the system’s various applications as well as limitations that were encountered during its use in the Deepwater Horizon incident.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 10 - Year 2012</p>
        </footer>
    </body>
    </html>
    