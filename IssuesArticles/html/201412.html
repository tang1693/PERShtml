<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000012/art00001;jsessionid=1dvi01phsmbc0.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            GPU Processing for UAS-Based LFM-CW Stripmap SAR
        </a>
    </h3>
    <div style="font-style: italic;">201412, nan</div>
    <div>Authors: Stringham, Craig; Long, David G.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Unmanned air systems (UAS) provide an excellent platform for synthetic aperture radar (SAR), enabling surveillance and research over areas too difficult, dangerous, or costly to reach using manned aircraft. However, the nimble nature of the small UAS makes them more susceptible to external forces, thus requiring significant motion compensation in order for SAR images to focus properly. SAR backprojection has been found to improve the focusing of low-altitude stripmap SAR images compared to frequency domain algorithms. In this paper we describe the development and implementation of SAR backprojection appropriate for UAS based stripmap SAR that utilizes the unique architecture of a GPU in order to produce high-quality imagery in real-time.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000012/art00002;jsessionid=1dvi01phsmbc0.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Feasibility Study for Pose Estimation of Small UAS in Known 3D Environment Using Geometric Hashing
        </a>
    </h3>
    <div style="font-style: italic;">201412, pp. 1117-1128(12)</div>
    <div>Authors: Armenakis, Costas; Li-Chee-Ming, Julien</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A novel self-localization method for small Unmanned Aerial Systems (UAS) is presented. The algorithm automatically establishes correspondence between the First-Person View (FPV) video streamed from a UAS flying in an urban environment and its 3D building model. The resulting camera pose provides a precise navigation solution in the densely structured environment. Initially, Vertical Line Features are extracted from the FPV video frames, as the forward and downward-looking camera is kept stabilized through a gimbal camera mount. Geometric hashing is then used to match the extracted image features with a database of Vertical Line Features extracted from synthetic images of the 3D building models. The exterior orientation parameters of the FPV video frames for localizing the UAS frames are determined by photogrammetric bundle adjustment. The results demonstrate that sub-meter accuracies in the UAS's X, Y, Z positional coordinates are achievable from flying 40 m above ground.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000012/art00003;jsessionid=1dvi01phsmbc0.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Multi-UAV Surveillance over Forested Regions
        </a>
    </h3>
    <div style="font-style: italic;">201412, pp. 1129-1137(9)</div>
    <div>Authors: Leng, Gerard; Qian, Zhang; Govindaraju, Vengatesan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                S-UAVs (Small-Unmanned Aerial Vehicles) have emerged as low-cost alternatives for aerial surveillance over forests. However, they provide limited coverage owing to their low altitudes and short endurance. Therefore, a quick and effective surveillance necessitates optimal flying paths, maximizing ground visibility. Even though the occlusion of ground points due to vegetation is significant in forests, it is generally neglected. This paper proposes a probabilistic sensing model that incorporates both occlusions due to terrain and vegetation, in the visibility computations and presents a two-step approach to determine near-optimal flight paths: (a) waypoints are strategically deployed to enhance visibility, using centroidal Voronoi tessellation, and (b) flyable paths are designed using a clustered spiral-alternating algorithm. Simulation studies conducted on synthetic terrains and a reconstructed terrain, from satellite data of tree-cover and a Digital Elevation Model (DEM), show the effectiveness of the proposed method in improving the terrain visibility as compared to commonly used grid-based waypoints.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000012/art00004;jsessionid=1dvi01phsmbc0.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Retrieval of Spectral Reflectance of High Resolution Multispectral Imagery Acquired with an Autonomous Unmanned Aerial Vehicle
        </a>
    </h3>
    <div style="font-style: italic;">201412, pp. 1139-1150(12)</div>
    <div>Authors: Zaman, Bushra; Jensen, Austin; Clemens, Shannon R.; McKee, Mac</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This research presents a new semi-automatic model for converting raw AggieAirâ„¢ footprints in visible and near-infrared (NIR) bands into reflectance images. AggieAir, a new unmanned aerial vehicle (UAV) platform, is flown autonomously using pre-programmed flight plans at low altitudes to limit atmospheric effects. The UAV acquires high-resolution, multispectral images and has a flight interval of about 30 minutes. The sensors on board are twin cameras with duplicate settings and automatic mode disabled. A white Barium Sulfate (BaSO4) panel is used for reflectance calibration and in situ irradiance measurements. The spatial and radiometric resolution of the imagery is 25 cm and 8-bit, respectively. The raw images are mosaicked and orthorectified and the model converts their digital numbers (DN) to reflectance values. Imagery, acquired around local solar noon over wetlands on the Great Salt Lake, Utah, is used to illustrate the results. The model generates high quality images and the results are good. The reflectance values of vegetation in the NIR, Green and Red bands extracted at the test locations are consistent. The image processing, reflectance calculations, accuracy issues, with the proposed method are discussed.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000012/art00005;jsessionid=1dvi01phsmbc0.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Modeling Above-Ground Biomass in Tallgrass Prairie Using Ultra-High Spatial Resolution sUAS Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201412, pp. 1151-1159(9)</div>
    <div>Authors: Wang, Huan; Wang, Chuyuan; Price, Kevin P.; van der Merwe, Deon; An, Nan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We examined the relationship between tallgrass above-ground biomass (AGB) and NDVI from ultra-high spatial resolution multispectral imagery collected by small unmanned aircraft systems (sUAS). This study was conducted at the Tallgrass Prairie National Preserve in Chase County, Kansas. Results show that NDVI values computed from sUAS imagery explained up to 94 percent of the variance (p<0.01) in AGB measurements. The model coefficient of determination (r2) decreased with increasing aircraft flight altitude suggesting image spatial resolution is a key factor influencing the strength of the relationship. A scaling-up approach from small-scale sUAS imagery to broad-scale, digital aerial imagery collected at 1,200 meters by a piloted aircraft was used to provide AGB model estimates across the entire 4,500 ha of the Preserve. Spectral reflectance data measured by spectroradiometer were also used to identify three optimal regions of the spectrum that have the highest significant correlations with tallgrass AGB.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2014/00000080/00000012/art00006;jsessionid=1dvi01phsmbc0.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            High Resolution Imagery Collection for Post-Disaster Studies Utilizing Unmanned Aircraft Systems (UAS)
        </a>
    </h3>
    <div style="font-style: italic;">201412, pp. 1161-1168(8)</div>
    <div>Authors: Adams, Stuart M.; Levitan, Marc L.; Friedland, Carol J.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper examines the use of unmanned aircraft systems (UAS) to capture imagery for use in post-disaster field studies at the neighborhood and individual building level. A discussion of post-disaster imagery collection including satellite, aerial, and ground-based platforms is first presented. Applications of UAS in recent disasters as described in the literature are then surveyed, and a case study investigating UAS capabilities for imagery collection following an EF-3 tornado in northern Alabama on 02 March 2012 is presented. Case study considerations include the multi-rotor unmanned aerial vehicle (UAV) equipment and ground station, onboard imagery devices, flight considerations and capabilities, and imagery and metadata collection capabilities of the UAS. Sample post-tornado imagery of building damage is shown, demonstrating the order of magnitude improvement in imagery resolution compared to traditional post-disaster aerial photography.
            </details>
        </div>
</article>
