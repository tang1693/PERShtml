<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000002/art00001;jsessionid=1k17bzchbiiwa.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Direct Linear Transformation from Comparator Coordinates into Object Space Coordinates in Close-Range Photogrammetry
        </a>
    </h3>
    <div style="font-style: italic;">201502, nan</div>
    <div>Authors: Abdel-Aziz, Y.I.; Karara, H.M.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A method for photogrammetric data reduction without the necessity for neither fiducial marks nor initial approximations for inner and outer orientation parameters of the camera has been developed. This approach is particularly suitable for reduction of data from non-metric photography, but has also distinct advantages in its application to metric photography. Preliminary fictitious data tests indicate that the approach is promising. Experiments with real data are underway.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000002/art00002;jsessionid=1k17bzchbiiwa.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Fully Polarimetric Synthetic Aperture Radar (SAR) Processing for Crop Type Identification
        </a>
    </h3>
    <div style="font-style: italic;">201502, pp. 109-117(9)</div>
    <div>Authors: Hong, Gang; Wang, Shusen; Li, Junhua; Huang, Jingfeng</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The target or polarimetric decomposition is widely used to process multi-polarization SAR imagery to establish a correspondence between physical characteristics of interested objects and observed scattering mechanisms. Polarimetric decomposition parameters are used as the basis for developing new classification methods for analyzing polarimetric SAR data. This study proposes to combine two polarimetric decomposition parameters (entropy (H) and angle (α)) derived from the Cloude and Pottier decomposition method and total scattered power (Span) in crop type identification. Support vector machine (SVM) classification algorithm was selected as a classifier to resolve limitations of classifications based on polarimetric decomposition parameters. The advantages of the proposed method are determined by comparing with other commonly used methods based on polarimetric features and the results produced from the coherency matrix, i.e., without target decomposition. Results show that the proposed method is about 10 percent better than other methods based on polarimetric features without Span, and it outperforms the result from the coherency matrix with about 4 percent improvement in the overall accuracy.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000002/art00003;jsessionid=1k17bzchbiiwa.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            An Improved Liberal Cloud-Mask for Addressing Snow/Cloud Confusion with MODIS
        </a>
    </h3>
    <div style="font-style: italic;">201502, pp. 119-129(11)</div>
    <div>Authors: Paull, David J.; Lees, Brian G.; Thompson, Jeffery A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The utility of the daily MODIS snow products depends on the ability of the MODIS cloud-masking algorithm to differentiate between snow- and cloud-cover. Although few studies have explored the issue, snow/cloud confusion is a key issue limiting the accuracy of the MODIS snow products. Recent studies from the Southern Hemisphere suggested that snow/cloud confusion limited the utility of the MODIS snow products there. In this study, MODIS snow/cloud confusion over Australia was investigated using an improved liberal cloud-mask in conjunction with a snow-detection algorithm. The performance of the proposed cloud-mask was assessed using high-resolution ASTER imagery and in situ observations. Results indicated that the improved liberal cloud-masking algorithm reduced snow/ cloud confusion, successfully identifying snow-covered pixels that were previously identified as cloudy. The analysis further suggested that scale-related differences in imagery used in the standard MODIS cloud-masking workflow might be the source of some snow/cloud confusion previously reported.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000002/art00004;jsessionid=1k17bzchbiiwa.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Validation of Geometric Accuracy of Global Land Survey (GLS) 2000 Data
        </a>
    </h3>
    <div style="font-style: italic;">201502, pp. 131-141(11)</div>
    <div>Authors: Rengarajan, Rajagopalan; Sampath, Aparajithan; Storey, James; Choate, Michael</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The Global Land Survey (GLS) 2000 data were generated from Geocover™ 2000 data with the aim of producing a global data set of accuracy better than 25 m Root Mean Square Error (RMSE). An assessment and validation of accuracy of GLS 2000 data set, and its co-registration with Geocover™ 2000 data set is presented here. Since the availability of global data sets that have higher nominal accuracy than the GLS 2000 is a concern, the data sets were assessed in three tiers. In the first tier, the data were compared with the Geocover™ 2000 data. This comparison provided a means of localizing regions of higher differences. In the second tier, the GLS 2000 data were compared with systematically corrected Landsat-7 scenes that were obtained in a time period when the spacecraft pointing information was extremely accurate. These comparisons localize regions where the data are consistently off, which may indicate regions of higher errors. The third tier consisted of comparing the GLS 2000 data against higher accuracy reference data. The reference data were the Digital Ortho Quads over the United States, orthorectified SPOT data over Australia, and high accuracy check points obtained using triangulation bundle adjustment of Landsat-7 images over selected sites around the world. The study reveals that the geometric errors in Geocover™ 2000 data have been rectified in GLS 2000 data, and that the accuracy of GLS 2000 data can be expected to be better than 25 m RMSE for most of its constituent scenes.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000002/art00005;jsessionid=1k17bzchbiiwa.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Vegetation Burn Severity Mapping Using Landsat-8 and WorldView-2
        </a>
    </h3>
    <div style="font-style: italic;">201502, pp. 143-154(12)</div>
    <div>Authors: Wu, Zhuoting; Middleton, Barry; Hetzler, Robert; Vogel, John; Dye, Dennis</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We used remotely sensed data from the Landsat-8 and WorldView-2 satellites to estimate vegetation burn severity of the Creek Fire on the San Carlos Apache Reservation, where wildfire occurrences affect the Tribe's crucial livestock and logging industries. Accurate pre- and post-fire canopy maps at high (0.5-meter) resolution were created from World- View-2 data to generate canopy loss maps, and multiple indices from pre- and post-fire Landsat-8 images were used to evaluate vegetation burn severity. Normalized difference vegetation index based vegetation burn severity map had the highest correlation coefficients with canopy loss map from WorldView-2. Two distinct approaches - canopy loss mapping from WorldView-2 and spectral index differencing from Landsat-8 - agreed well with the field-based burn severity estimates and are both effective for vegetation burn severity mapping. Canopy loss maps created with WorldView-2 imagery add to a short list of accurate vegetation burn severity mapping techniques that can help guide effective management of forest resources on the San Carlos Apache Reservation, and the broader fire-prone regions of the Southwest.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000002/art00006;jsessionid=1k17bzchbiiwa.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Estimating The Population Distribution in a County Area in China Based on Impervious Surfaces
        </a>
    </h3>
    <div style="font-style: italic;">201502, pp. 155-163(9)</div>
    <div>Authors: Zhu, Honglei; Li, Ying; Liu, Zhaoli; Fu, Bolin</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Information on the county level population distribution is essential for supporting a wide variety of local planning processes. Previous researchers found that impervious surfaces had a strong linear relationship with population. But few studies have reported estimating population in a county area of China with impervious surfaces. In this paper, a population distribution model for a county area in China was established using demographic information at the county level (i.e., total population, non-agricultural population, and agricultural population) and impervious surfaces derived from Land-sat TM images. The model was conducted to distribute the population of Fujin County, Heilongjiang Province, China. Population data of 123 villages and 11 towns of Fujin County were used to evaluate the model. The results indicated that the model performs better than area-based approaches, particularly in the estimation of town populations (17.86 percent mean relative error). The results of village population estimation were acceptable, with a mean relative error of 25.3 percent. As a result, impervious surfaces cannot provide height information and identify non-residential areas in developed areas of zhens (urban cores of towns). The model suggests the difficulty of non-agricultural population estimation.
            </details>
        </div>
</article>
