<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000010/art00007;jsessionid=a7cng7mrirdkj.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            System Calibration Including Time Delay Estimation for GNSS/INS-Assisted Pushbroom Scanners Onboard UAV Platforms
        </a>
    </h3>
    <div style="font-style: italic;">202110, pp. 705-716(12)</div>
    <div>Authors: LaForest, Lisa M.; Zhou, Tian; Hasheminasab, Seyyed Meghdad; Habib, Ayman</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Unmanned aerial vehicles (UAVs ) equipped with imaging sensors and integrated global navigation satellite system/inertial navigation system (GNSS/INS ) units are used for numerous applications. Deriving reliable 3D coordinates from such UAVs is contingent on accurate geometric calibration, which encompasses the estimation of mounting parameters and synchronization errors. Through a rigorous impact analysis of such systematic errors, this article proposes a direct approach for spatial and temporal calibration (estimating system parameters through a bundle adjustment procedure) of a GNSS/INS -assisted pushbroom scanner onboard a UAV platform. The calibration results show that the horizontal and vertical accuracies are within the ground sampling distance of the sensor. Unlike for frame camera systems, this article also shows that the indirect approach is not a feasible solution for pushbroom scanners due to their limited ability for decoupling system parameters. This finding provides further support that the direct approach is recommended for spatial and temporal calibration of UAV pushbroom scanner systems.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000010/art00008;jsessionid=a7cng7mrirdkj.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Least Squares Adjustment with a Rank-Deficient Weight Matrix and Its Applicability to Image/Lidar Data Processing
        </a>
    </h3>
    <div style="font-style: italic;">202110, pp. 717-733(17)</div>
    <div>Authors: Ravi, Radhika; Habib, Ayman</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This article proposes a solution to special least squares adjustment (LSA) models with a rank-deficient weight matrix, which are commonly encountered in geomatics. The two sources of rank deficiency in weight matrices are discussed: naturally occurring due to the inherent characteristics ofLSAmathematical models and artificially induced to eliminate nuisance parameters fromLSAestimation. The physical interpretation of the sources of rank deficiency is demonstrated using a case study to solve the problem of 3D line fitting, which is often encountered in geomatics but has not been addressed fully to date. Finally, some geomatics-related applications—mobile lidar system calibration, point cloud registration, and single-photo resection—are discussed along with respective experimental results, to emphasize the need to assessLSAmodels and their weight matrices to draw inferences regarding the effective contribution of observations. The discussion and results demonstrate the vast applications of this research in geomatics as well as other engineering domains.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000010/art00009;jsessionid=a7cng7mrirdkj.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spectral Reflectance Estimation of UAS Multispectral Imagery Using Satellite Cross-Calibration Method
        </a>
    </h3>
    <div style="font-style: italic;">202110, pp. 735-746(12)</div>
    <div>Authors: Gowravaram, Saket; Chao, Haiyang; Molthan, Andrew; Zhao, Tiebiao; Tian, Pengzhi; Flanagan, Harold; Schultz, Lori; Bell, Jordan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper introduces a satellite-based cross-calibration (SCC) method for spectral reflectance estimation of unmanned aircraft system (UAS) multispectral imagery. The SCC method provides a low-cost and feasible solution to convert high-resolution UAS images in digital numbers (DN) to reflectance when satellite data is available. The proposed method is evaluated using a multispectral data set, including orthorectified KHawk UAS DN imagery and Landsat 8 Operational Land Imager Level-2 surface reflectance (SR) data over a forest/grassland area. The estimated UAS reflectance images are compared with the National Ecological Observatory Network's imaging spectrometer (NIS) SR data for validation. The UAS reflectance showed high similarities with the NIS data for the near-infrared and red bands with Pearson's r values being 97 and 95.74, and root-mean-square errors being 0.0239 and 0.0096 over a 32-subplot hayfield.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000010/art00010;jsessionid=a7cng7mrirdkj.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Early Classification Method for US Corn and Soybean by Incorporating MODIS-Estimated Phenological Data and Historical Classification Maps in Random-Forest Regression Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">202110, pp. 747-758(12)</div>
    <div>Authors: Sakamoto, Toshihiro</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                An early crop classification method is functionally required in a near-real-time crop-yield prediction system, especially for upland crops. This study proposes methods to estimate the mixed-pixel ratio of corn, soybean, and other classes within a low-resolution MODIS pixel by coupling MODIS-derived crop phenology information and the past Cropland Data Layer in a random-forest regression algorithm. Verification of the classification accuracy was conducted for the Midwestern United States. The following conclusions are drawn: The use of the random-forest algorithm is effective in estimating the mixed-pixel ratio, which leads to stable classification accuracy; the fusion of historical data and MODIS-derived crop phenology information provides much better crop classification accuracy than when these are used individually; and the input of a longer MODIS data period can improve classification accuracy, especially after day of year 279, because of improved estimation accuracy for the soybean emergence date.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000010/art00011;jsessionid=a7cng7mrirdkj.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Deep Multi-Modal Learning Method and a New RGB-Depth Data Set for Building Roof Extraction
        </a>
    </h3>
    <div style="font-style: italic;">202110, pp. 759-766(8)</div>
    <div>Authors: Khoshboresh-Masouleh, Mehdi; Shah-Hosseini, Reza</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study focuses on tackling the challenge of building mapping in multi-modal remote sensing data by proposing a novel, deep superpixel-wise convolutional neural network called DeepQuantized-Net, plus a new red, green, blue (RGB)-depth data set namedIND. DeepQuantized-Net incorporated two practical ideas in segmentation: first, improving the object pattern with the exploitation of superpixels instead of pixels, as the imaging unit in DeepQuantized-Net. Second, the reduction of computational cost. The generated data set includes 294RGB-depth images (256 training images and 38 test images) from different locations in the state of Indiana in the U.S., with 1024 × 1024 pixels and a spatial resolution of 0.5 ftthat covers different cities. The experimental results using theINDdata set demonstrates the mean F1 scores and the average Intersection over Union scores could increase by approximately 7.0% and 7.2% compared to other methods, respectively.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000010/art00012;jsessionid=a7cng7mrirdkj.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Feature-Point Matching for Aerial and Ground Images by Exploiting Line Segment-Based Local-Region Constraints
        </a>
    </h3>
    <div style="font-style: italic;">202110, pp. 767-780(14)</div>
    <div>Authors: Chen, Min; Fang, Tong; Zhu, Qing; Ge, Xuming; Zhang, Zhanhao; Zhang, Xin</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this study, we propose a feature-point matching method that is robust to viewpoint, scale, and illumination changes between aerial and ground images, to improve matching performance. First, a 3D rendering strategy is adopted to synthesize ground-view images from the 3D mesh model reconstructed from aerial images and overcome the global geometric distortion between aerial and ground images. We do not directly match feature points between the synthesized and ground images, but extract line-segment correspondences by designing a line-segment matching method that can adapt to the local geometric deformation, holes, and blurred textures on the synthesized image. Then, on the basis of the line-segment matches, local-region correspondences are constructed, and local regions on the synthesized image are propagated back to the original aerial images. Lastly, feature-point matching is performed between the aerial and ground images with the constraints of the local-region correspondences. Experimental results demonstrate that the proposed method can obtain more correct matches and higher matching precision than state-of-the-art methods. Specifically, the proposed method increases the average number of correct matches and average matching precision of the second-best method by more than five times and 40%, respectively.
            </details>
        </div>
</article>
