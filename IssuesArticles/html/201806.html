<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000006/art00011;jsessionid=9y3d8y14atwu.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            On a Novel 360° Panoramic Stereo Mobile Mapping System
        </a>
    </h3>
    <div style="font-style: italic;">201806, pp. 347-356(10)</div>
    <div>Authors: Blaser, Stefan; Nebiker, Stephan; Cavegn, Stefan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Image-based mobile mapping systems enable the efficient acquisition of georeferenced image sequences, which can later be exploited in cloud-based 3D geoinformation services. In order to provide a 360° coverage with accurate 3D measuring capabilities, we present a novel 360° panoramic stereo camera configuration. By using two 360° panorama cameras tilted forward and backward in combination with conventional forward and backward looking stereo camera sytems, we achieve a full 360° multi-stereo coverage. We furthermore developed a new mobile mapping system based on our proposed approach, which is operational and fulfills our high accuracy requirements. We successfully implemented a rigorous sensor and system calibration procedure, which allows calibrating all stereo systems with a superior accuracy compared to that of previous work. Our study delivered absolute 3D point accuracies in the range of 2 to 8 cm and relative accuracies of 3D distances in the range of 1 to 5 cm. We achieved these results in a challenging urban area. Furthermore, we automatically reconstructed a 3D city model of our study area by employing all captured and georeferenced mobile mapping imagery. The result is a highly detailed and almost complete 3D city model of the street-level environment.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000006/art00012;jsessionid=9y3d8y14atwu.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Finding Timestamp Offsets for a Multi-Sensor System Using Sensor Observations
        </a>
    </h3>
    <div style="font-style: italic;">201806, pp. 357-366(10)</div>
    <div>Authors: Voges, Raphael; Wieghardt, Christian S.; Wagner, Bernardo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Multi-sensor systems are widely used for robotics applications. While additional sensors can increase the accuracy and robustness of the solution, it is inevitable to synchronize them in order to rely on the results. For our multi-sensor system consisting of an actuated laser scanner, its motor and a camera, we assume that the timestamps are only delayed by a constant offset. We propose two different approaches to calculate timestamp offsets from laser scanner to motor, one of which is additionally capable of determining the timestamp offset between laser scanner and camera. Both approaches use parts of a SLAM algorithm but apply different criteria to find an appropriate solution. Our experiments show that we are able to determine timestamp offsets with a reasonable accuracy. Furthermore, our experiments exhibit the significance of a proper synchronization for a multi-sensor system.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000006/art00013;jsessionid=9y3d8y14atwu.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Range-Image: Incorporating Sensor Topology for Lidar Point Cloud Processing
        </a>
    </h3>
    <div style="font-style: italic;">201806, pp. 367-375(9)</div>
    <div>Authors: Biasutti, P.; Aujol, J-F.; Brédif, M.; Bugeau, A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper proposes a novel methodology for lidar point cloud processing that takes advantage of the implicit topology of various lidar sensors to derive 2D images from the point cloud while bringing spatial structure to each point. The interest of such a methodology is then proved by addressing the problems of segmentation and disocclusion of mobile objects in 3D lidar scenes acquired using street-based Mobile Mapping Systems (MMS). Most of the existing lines of research tackle those problems directly in the 3D space. This work promotes an alternative approach by using this image representation of the 3D point cloud, taking advantage of the fact that the problem of disocclusion has been intensively studied in the 2D image processing community over the past decade. Using the image derived from the sensor data by exploiting the sensor topology, a semi-automatic segmentation procedure based on depth histograms is presented. Then, a variational image inpainting technique is introduced to reconstruct the areas that are occluded by objects. Experiments and validation on real data prove the effectiveness of this methodology both in terms of accuracy and speed.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000006/art00015;jsessionid=9y3d8y14atwu.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Voxel- and Graph-Based Strategy for Segmenting Man-Made Infrastructures Using Perceptual Grouping Laws: Comparison and Evaluation
        </a>
    </h3>
    <div style="font-style: italic;">201806, pp. 377-391(15)</div>
    <div>Authors: Xu, Yusheng; Hoegner, Ludwig; Tuttas, Sebastian; Stilla, Uwe</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this paper, we report a novel strategy for segmenting 3D point clouds using a voxel structure and graph-based clustering with perceptual grouping laws. It provides a completely automatic solution for partitioning point clouds of man-made infrastructure. Two different segmentation methods using voxel and supervoxel structures are presented and evaluated. To increase the efficiency and the robustness of the segmentation process, the voxelization with octree-based structure is introduced, which can suppress effects of noise, outliers, and unevenly distributed point densities as well. The clustering of over-segmented voxels and supervoxels is achieved using graph theory on the basis of the local contextual information, which is commonly conducted merely with pairwise information in conventional clustering algorithms. The graphical model is constructed according to perceptual grouping laws, considering geometric information associated with points. Experiments using both laser scanning and photogrammetric point clouds have demonstrated that the proposed methods can achieve good results, especially complex scenes and nonplanar object surfaces, with F1-measures better than 0.67 for all the testing samples. Quantitative comparisons between the proposed approaches and other representative segmentation methods also confirm the effectiveness and the efficiency of the former. Moreover, a series of experiments is carried out, to investigate the methods' sensitivity with respect to various parameters on the segmentation results.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000006/art00017;jsessionid=9y3d8y14atwu.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Geometric Reasoning with Uncertain Polygonal Faces
        </a>
    </h3>
    <div style="font-style: italic;">201806, pp. 393-401(9)</div>
    <div>Authors: Meidow, Jochen; Förstner, Wolfgang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The reconstruction of urban areas suffers from the dilemma of modeling urban structures in a generic or specific way, thus being too unspecific or too restrictive. One approach to overcome this dilemma is to model and to instantiate buildings as arbitrarily shaped polyhedra and to recognize man-made structures in a subsequent stage by geometric reasoning. Thus, the existence of unconstrained boundary representations for buildings is assumed. To stay generic and to avoid the use of templates for pre-defined building primitives, no assumptions for the buildings' outlines and the planar roof areas are made. Typically, roof areas are derived interactively or in an automatic process based on given point clouds or digital surface models. Due to the measurement process and the assumption of planar boundaries, these planar faces are uncertain. Thus, a stochastic geometric reasoning process with statistical testing is appropriate to detected man-made structures followed by an adjustment to enforce the deduced geometric constraints. Unfortunately, city models usually do not feature information about the uncertainty of geometric entities. We present an approach to specify the uncertainty of the planes corresponding to the planar patches, i.e., polygons bounding a building, analytically. This paves the way to conduct the reasoning process with just a few assumptions. We describe and demonstrate the approach with real data.
            </details>
        </div>
</article>
