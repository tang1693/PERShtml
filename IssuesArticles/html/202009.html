
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 09 - Year 2020</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 09 - Year 2020</h1>
            <p>Displaying articles from Issue 09 - Year 2020.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000009/art00008;jsessionid=85tjeddhcsj9l.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Heliport Detection Using Artificial Neural Networks
        </a>
    </h3>
    <div style="font-style: italic;">202009, pp. 541-546(6)</div>
    <div>Authors: Başeski, Emre</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Automatic image exploitation is a critical technology for quick content analysis of high-resolution remote sensing images. The presence of a heliport on an image usually implies an important facility, such as military facilities. Therefore, detection of heliports can reveal critical information about the content of an image. In this article, two learning-based algorithms are presented that make use of artificial neural networks to detect H-shaped, light-colored heliports. The first algorithm is based on shape analysis of the heliport candidate segments using classical artificial neural networks. The second algorithm uses deep-learning techniques. While deep learning can solve difficult problems successfully, classical-learning approaches can be tuned easily to obtain fast and reasonable results. Therefore, although the main objective of this article is heliport detection, it also compares a deep-learning based approach with a classical learning-based approach and discusses advantages and disadvantages of both techniques.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000009/art00009;jsessionid=85tjeddhcsj9l.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Semi-Automatic Building Extraction from WorldView-2 Imagery Using Taguchi Optimization
        </a>
    </h3>
    <div style="font-style: italic;">202009, pp. 547-555(9)</div>
    <div>Authors: Tonbul, Hasan; Kavzoglu, Taskin</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Due to the complex spectral and spatial structures of remotely sensed images, the delineation of land use/land cover classes using conventional approaches is a challenging task. This article tackles the problem of seeking optimal parameters of multi-resolution segmentation for a classification task using WorldView-2 imagery. Taguchi optimization was applied to search optimal parameters using the plateau objective function (POF) and quality rate (Qr) as fitness criteria. Analysis of variance was also used to estimate the contributions of the parameters for POF and Qr, separately. The scale parameter was the most effective one, with contribution levels of 87.45% and 56.87% for POF and Qr, respectively. Linear regression and support-vector regression methods were used to predict the results of the experiment. Test results revealed that Taguchi optimization was more effective than linear regression and support-vector regression for predicting POF and Qr values.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000009/art00010;jsessionid=85tjeddhcsj9l.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Precise Extraction of Citrus Fruit Trees from a Digital Surface Model Using a Unified Strategy: Detection, Delineation, and Clustering
        </a>
    </h3>
    <div style="font-style: italic;">202009, pp. 557-569(13)</div>
    <div>Authors: Ok, Ali Ozgun; Ozdarici-Ok, Asli</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this study, we present an original unified strategy for the precise extraction of individual citrus fruit trees from single digital surface model (DSM) input data. A probabilistic method combining the circular shape information with the knowledge of the local maxima in the DSM has been used for the detection of the candidate trees. An active contour is applied within each detected region to extract the borders of the objects. Thereafter, all extracted objects are seamlessly divided into clusters considering a new feature data set formed by (1) the properties of trees, (2) planting parameters, and (3) neighborhood relations. This original clustering stage has led to two new contributions: (1) particular objects or clustered structures having distinctive characters and relationships other than the citrus objects can be identified and eliminated, and (2) the information revealed by clustering can be used to recover missing citrus objects within and/or nearby each cluster. The main finding of this research is that a successful clustering can provide valuable input for identifying incorrect and missing information in terms of citrus tree extraction. The proposed strategy is validated in eight test sites selected from the northern part of Mersin province of Turkey. The results achieved are also compared with the state-of-the-art methods developed for tree extraction, and the success of the proposed unified strategy is clearly highlighted.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000009/art00011;jsessionid=85tjeddhcsj9l.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Performance Analysis of Advanced Decision Forest Algorithms in Hyperspectral Image Classification
        </a>
    </h3>
    <div style="font-style: italic;">202009, pp. 571-580(10)</div>
    <div>Authors: Colkesen, Ismail; Ertekin, Omer Habib</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this study, the performances of random forest (RF), rotation forest (RoF), and canonical correlation forest (CCF) algorithms were compared and analyzed for classification of hyperspectral imagery. For this purpose, the Airborne Visible/Infrared Imaging Spectrometer (AVIRIS) Indian Pine (IP), the Reflective Optics System Imaging Spectrometer University of Pavia, and the AVIRIS Kennedy Space Center (KSC) data sets were used as main data sources. In addition to the confusion matrix–derived accuracy measures (overall accuracy, kappa coefficient, F-scores), the performances of the algorithms were analyzed in detail considering three diversity measures (Q statistics, correlations, and interrater agreements) and a kappa-error diagram. Results showed that the highest classification accuracies (87% for IP, 94% for PU, and 93% for KSC data sets) were achieved with the use of CCF algorithm, and improvements in classification accuracy were statistically significant compared to RF and RoF. Based on the diversity measures and the kappa-error diagram, individual learners in the CCF ensemble were found to be more diverse and accurate.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000009/art00012;jsessionid=85tjeddhcsj9l.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Analyzing the Contribution of Training Algorithms on Deep Neural Networks for Hyperspectral Image Classification
        </a>
    </h3>
    <div style="font-style: italic;">202009, pp. 581-588(8)</div>
    <div>Authors: Günen, Mehmet Akif; Atasever, Umit Haluk; Beşdok, Erkan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Autoencoder (AE)-based deep neural networks learn complex problems by generating feature-space conjugates of input data. The learning success of an AE is too sensitive for a training algorithm. The problem of hyperspectral image (HSI) classification by using spectral features of pixels is a highly complex problem due to its multi-dimensional and excessive data nature. In this paper, the contribution of three gradient-based training algorithms (i.e., scaled conjugate gradient (SCG), gradient descent (GD), and resilient backpropagation algorithms (RP)) on the solution of the HSI classification problem by using AE was analyzed. Also, it was investigated how neighborhood component analysis affects classification performance for training algorithms on HSIs. Two hyperspectral image classification benchmark data sets were used in the experimental analysis. Wilcoxon signed-rank test indicates that RB is statistically better than SCG and GD in solving the related image classification problem.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 09 - Year 2020</p>
        </footer>
    </body>
    </html>
    