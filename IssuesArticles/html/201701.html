
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 01 - Year 2017</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 01 - Year 2017</h1>
            <p>Displaying articles from Issue 01 - Year 2017.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000001/art00010;jsessionid=3mjkb0mlvvqiq.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Fire Risk Prediction Using Remote Sensed Products: A Case of Cambodia
        </a>
    </h3>
    <div style="font-style: italic;">201701, pp. 19-25(7)</div>
    <div>Authors: Yu, Bo; Chen, Fang; Li, Bin; Wang, Li; Wu, Mingquan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Forest fire is threatening human life in monsoon countries, such as Cambodia, which suffers from forest fire frequently. Developing an efficient method to predict fire risk for large areas is becoming significantly important. However, the methods used in fire risk prediction are mostly based on field-based meteorological data, and the coefficients are hard-defined, heavily depending on user experience. We propose to use a user-friendly machine learning method, Random Forest™, to train a regression model by synthesizing publicly available remote sensed products to predict fire risk ratings at pixel-level in eight-day advance. The structure of our model synthesizes features in three-time intervals T1, T2, and T3 to predict fire occurrence probability in T4. The experiment demonstrates the efficiency of such model in predicting fire occurrence with a correlation coefficient of 0.987 and mean square error being 0.00285. It results in a practical way to predict fire risk and prevent fires.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000001/art00012;jsessionid=3mjkb0mlvvqiq.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Object-based Wetland Characterization Using Radarsat-2 Quad-Polarimetric SAR Data, Landsat-8 OLI Imagery, and Airborne Lidar-Derived Geomorphometric Variables
        </a>
    </h3>
    <div style="font-style: italic;">201701, pp. 27-36(10)</div>
    <div>Authors: Franklin, Steven E.; Ahmed, Oumer S.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The goal of this research was to classify four wetland types in the Hudson Bay Lowlands in northern Canada using Radarsat-2 quad-polarization and Landsat-8 satellite sensor data and geomorphometric variables extracted from an airborne lidar digital elevation model. Segmentation was followed by object-based image classification implemented with a Radom Forest machine learning algorithm. The classification accuracy was determined to be approximately 91 percent. This is a significant improvement over the accuracy that was obtained using the Radarsat-2 (80 percent) or Landsat-8 sensor data alone (84 percent). Variable importance (VI) was measured for geomorphometric measures related to the gravity-, wind- and solar-fields, which were developed to explain eco-hydrological differences and increase the separability of wetland classes. Further research will consider additional geomorphometric and spectral response variables that are useful in more detailed boreal wetland classifications and analysis of wetland characteristics over time.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000001/art00014;jsessionid=3mjkb0mlvvqiq.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Fusion of Graph Embedding and Sparse Representation for Feature Extraction and Classification of Hyperspectral Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201701, pp. 37-46(10)</div>
    <div>Authors: Luo, Fulin; Huang, Hong; Liu, Jiamin; Ma, Zezhong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The graph embedding algorithms have been widely applied for feature extraction (FE) of hyperspectral imagery (HSI). These methods need to construct a similarity graph with k-nearest neighbors or ∈-radius ball. However, the neighborhood size is difficult to select in real-world applications. To solve the problem, we propose a new unsupervisedFEmethod, called sparsity preserving analysis (SPA), based on sparse representation and graph embedding. The proposed algorithm utilizes sparse representation to obtain the sparse coefficients of data. Then, it constructs a new graph with the sparse coefficients that reveals the sparse properties of data. Finally, the structure of the graph is preserved in low-dimensional space to obtain a transformation matrix forFE. In addition, a new classification method, termed sparse neighborhood classifier (SNC), is designed using the sparse representation-based methodology. It uses the sparse coefficients of a new sample to obtain the similarity weights in each class. Then, the label information of the new sample is obtained by the weights. The classification accuracies ofSPAwithSNCreach to 86.9 percent and 80.6 percent on PaviaU and UrbanHSIdata sets, respectively. The results demonstrate thatSPAwithSNCcan effectively extract low-dimensional features and improve the discriminating power forHSIclassification.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000001/art00015;jsessionid=3mjkb0mlvvqiq.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Exterior Orientation Revisited: A Robust Method Based onlq-norm
        </a>
    </h3>
    <div style="font-style: italic;">201701, pp. 47-56(10)</div>
    <div>Authors: Li, Jiayuan; Hu, Qingwu; Zhong, Ruofei; Ai, Mingyao</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Camera exterior orientation is essential in many photogrammetry and computer vision applications, including 3D reconstruction, digital orthophoto map (DOM) generation, and localization. In this paper, we propose a new formulation of exterior orientation that is robust against gross errors (outliers). Different from classic optimization methods whose cost function is based on thelq-norm of residuals, we uselq-norm (0<q<1) instead. We reformulate the new cost function as an augmented Lagrangian function because it is not strictly convex. In addition, we employ the alternating direction method of multipliers (ADMM) to decompose the augmented Lagrangian function into three simple sub-problems and solve them iteratively. Our work recovers the orientation and position of a camera from outliers contaminating observations without any gross error detection stage such as random sample consensus (RANSAC). Extensive experiments on both synthetic and real data demonstrate that the proposed method significantly outperforms state-of-the-art methods and can easily handle situations with up to 85 percent outliers. The source code of the proposed algorithm is made public.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000001/art00016;jsessionid=3mjkb0mlvvqiq.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping the Spatio-Temporal Evolution of Irrigation in the Coastal Plain of Georgia, USA
        </a>
    </h3>
    <div style="font-style: italic;">201701, pp. 57-67(11)</div>
    <div>Authors: Williams, Marcus D.; Hawley, Christie M.S.; Madden, Marguerite; Shepherd, J. Marshall</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study maps the spatial and temporal evolution of acres irrigated in the Coastal Plain of Georgia over a 38 year period. The goal of this analysis is to create a time-series of irrigated areas in the Coastal Plain of Georgia at a sub-county level. From 1976 through 2013, Landsat images were obtained and sampled at four year intervals to manually detect Center-Pivot irrigation (CPI) systems in the analysis region. During the 38 year analysis period there was a 4,500 percent increase inCPIsystems detected that corresponded to an approximate 2,000 percent increase in total acreage. The bulk of the total acreage irrigated is contained in southwest Georgia, as seven counties in the region contained 38 percent of the total acreage irrigated in 2013. There was substantial growth throughout the entire Coastal Plain Region, but southwest Georgia was identified as the most heavily irrigated region of the state.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 01 - Year 2017</p>
        </footer>
    </body>
    </html>
    