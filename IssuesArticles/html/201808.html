<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000008/art00012;jsessionid=1976850pspst3.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            In-Orbit Geometric Calibration Without Accurate Ground Control Data
        </a>
    </h3>
    <div style="font-style: italic;">201808, pp. 485-493(9)</div>
    <div>Authors: Jiang, Yonghua; Zhang, Guo; Wang, Tong; Li, Deren; Zhao, Yanbin</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In-orbit geometric calibration is a key technology for improving the geometric positioning accuracy of satellites. Conventional geometric calibration, which uses high-accuracy ground control data to accurately calibrate the orientation parameters of a satellite, heavily relies on the control data of the calibration fields and may not be applicable in emergencies where urgent and accurate positioning is needed. The constant calibration of satellites is also difficult owing to the lack of permanent calibration fields. This paper presents a geometric cross-calibration method for the rapid and accurate calibration of satellites. The conjugate points from the multitemporal images of one satellite or multi-satellite images are first automatically extracted; then, the interior orientation parameters of the satellite requiring calibration can be precisely recovered according to the positioning consistency constraint of the conjugate points. In contrast to the conventional method, the proposed method can accurately calibrate the orientation parameters without using high-accuracy control data of the calibration fields. Therefore, the proposed method aids in the constant calibration of satellites to ensure the positioning accuracy, even without sufficient permanent calibration fields. The multitemporal images of the Yaogan-4 satellite and the images of the ZY3-01 and ZY02C satellites were considered for verifying this method. Finally, accuracies of approximately 0.7 and 0.6 pixels were achieved by the proposed and conventional methods, respectively. The difference between the two methods was only approximately 0.1 pixels, demonstrating that the proposed method can achieve a calibration accuracy as high as that achieved by the conventional method, even without the use of high-accuracy control data.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000008/art00013;jsessionid=1976850pspst3.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Incorporating Crown Shape Information for Identifying Ash Tree Species
        </a>
    </h3>
    <div style="font-style: italic;">201808, pp. 495-503(9)</div>
    <div>Authors: Liu, Haijian; Wu, Changshan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Identifying ash trees from other common deciduous trees is challenging due to subtle spectral differences of foliage among species. Although many researchers have integrated lidar-derived tree height and crown size metrics to improve tree species classification accuracy, these simple biophysical attributes provide inadequate explanatory power in distinguishing ash trees (Fraxinus, spp.) in urban ecosystems. To address this issue, shape-related features, including crown shape index (SI) and coefficient of variation (CV) of crown height, were extracted from lidar data, and fused with treetopbased spectra for ash tree species identification in Milwaukee City, Wisconsin, United States. Analysis results indicate shape features includingSIandCVplay a big role in improving the accuracy for ash tree identification. Specifically, Fusion ofCVand treetop-based spectra improved the overall accuracy from 81.9 percent to 89 percent, and McNemar tests indicated the differences in accuracy betweenCVfusion and tree height fusion was statistically significant (p = 0.016).
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000008/art00014;jsessionid=1976850pspst3.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Robust Forest Cover Indices for Multispectral Images
        </a>
    </h3>
    <div style="font-style: italic;">201808, pp. 505-512(8)</div>
    <div>Authors: Becker, Sarah J.; Daughtry, Craig S.T.; Russ, Andrew L.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Trees occur in many land cover classes and provide significant ecosystem services. Remotely sensed multispectral images are often used to create thematic maps of land cover, but accurately identifying trees in mixed land-use scenes is challenging. We developed two forest cover indices and protocols that reliably identified trees in WorldView-2 multispectral images. The study site in Maryland included coniferous and deciduous trees associated with agricultural fields and pastures, residential and commercial buildings, roads, parking lots, wetlands, and forests. The forest cover indices exploited the product of either the reflectance in red (630 to 690 nm) and red edge (705 to 745 nm) bands or the product of reflectance in red and near infrared (770 to 895 nm) bands. For two classes (trees versus other), overall classification accuracy was >77 percent for the four images that were acquired in each season of the year. Additional research is required to evaluate these indices for other scenes and sensors.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2018/00000084/00000008/art00015;jsessionid=1976850pspst3.x-ic-live-02" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Local Distinctive Features Matching Method for Remote Sensing Images with Repetitive Patterns
        </a>
    </h3>
    <div style="font-style: italic;">201808, pp. 513-524(12)</div>
    <div>Authors: Chen, Min; Qin, Rongjun; He, Haiqing; Zhu, Qing; Wang, Xing</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                A novel feature matching method for remote sensing images with repetitive patterns is proposed in this paper. Firstly, a detector, with the feature response function considering geometric distinctiveness of image pixel as well as the support region surrounding the pixel, is proposed to detect local distinctive features. Secondly, those features with higher distinctiveness are selected as seed points and matched. A matching reliability indicator is proposed to select reliable seed matches. Then, a coarse geometric transformation is computed based on the seed matches to define a corresponding search area for each feature. Finally, a feeble interest point searching strategy is adopted to find correspondence for all the features. Experimental results demonstrate that the proposed method is able to obtain much more correct matches than traditional methods, as well as the highest matching precision (around 90 percent) in the comparative evaluations for remote sensing images with highly repetitive patterns.
            </details>
        </div>
</article>
