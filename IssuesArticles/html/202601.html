
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 01 - Year 2026</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 01 - Year 2026</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2026/00000092/00000001" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2026/00000092/00000001/art00007;jsessionid=c89kft5md6pb.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            RSIDetNet: An Efficient Oriented Small Object Detection Model for Remote Sensing Images Based on Cross-Scale Feature Fusion and Large Kernel Decomposition
        </a>
    </h3>
    <div style="font-style: italic;">202601, pp. 23-34(12)</div>
    <div>Authors: Kang, Zizhuang; Han, Yihui; He, Bing; Jia, Mingquan; Luo, Wen; Fu, Ying; He, Wei</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2026/01/RSIDetNet An Efficient Oriented Small Object Detection Model for Remote Sensing Images Based on Cross Scale Feature Fusion and Large Kernel Decomposition.jpeg" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Small object detection in remote sensing images is crucial for maximizing data utility, but small objects face challenges due to their limited pixel coverage, low resolution, and susceptibility to background noise. This paper proposes an orientated small object detection model for remote sensing images based on cross-scale feature fusion and large kernel decomposition. The model consists of four main components: the image feature extraction module, the multi-scale feature fusion module, the cross-fusion region proposal network for generating candidate regions, and the dual detection head for predicting target categories and rotating bounding boxes. Experiments are conducted on two datasets, SODA‐A and HRSC‐2016, and the results show that the proposed model improves the mean average precision (mAP) by at least 6.3% over classical 1‐stage models and by at least 2.6% over classical 2‐stage model. In particular, when detecting very small objects (area less than 144 pixels), the mAP value is as high as 17.2%, which is a significant improvement compared with other models, indicating that it is very effective in dealing with the difficult task of small object detection.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2026/00000092/00000001/art00008;jsessionid=c89kft5md6pb.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Comparison of Intertidal Terrain Extraction Methods Based on ICESat‐2 and Tidal Data
        </a>
    </h3>
    <div style="font-style: italic;">202601, pp. 35-47(13)</div>
    <div>Authors: Chen, Deliang; Lu, Zixuan; ZhuangJianbo Xiao, Qizhi; Xiao, Jianbo; Chen, Song; Cheng, Liang</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2026/01/Comparison of Intertidal Terrain Extraction Methods Based on ICESat-2 and Tidal Data.jpeg" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The intertidal zone is a transitional area between land and sea, characterized by both marine and terrestrial features, with rich resources in mudflats. Accurately mapping the intertidal topography and understanding its dynamic characteristics are of great significance. In this study, Sentinel-2 imagery was used, combined with tidal data and ICESat‐2 data, respectively. Four methods–the waterline method, the inundation frequency method, random forest regression, and the long short-term memory (LSTM) model–were applied to extract intertidal topography in the large radial sand ridges along the Jiangsu coast. When validated with ICESat‐2 data and unmanned aerial vehicle (UAV) data, the root mean square error (RMSE) values of all four methods combined with ICESat‐2 data were lower than those combined with tidal data. Using ICESat‐2 data for validation, the waterline method combined with ICESat‐2 data achieved the lowest RMSE of 0.218 m. When validated with UAV data, the inundation frequency method combined with ICESat‐2 data yielded the lowest RMSE of 0.864 m. From 2020 to 2024, the intertidal zone in this region was initially dominated by erosion, followed by deposition, ultimately reaching a dynamic equilibrium. This study achieved two objectives: (1) under identical area conditions using the same image data and two elevation data, four different methods were validated to compare their topographic extraction performance and identify the optimal approach; and (2) the optimal method was applied to generate multi-temporal topographic results of a local intertidal zone along the Jiangsu coast, analyzing terrain change in the region.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2026/00000092/00000001/art00010;jsessionid=c89kft5md6pb.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Optimized 3D Building Mapping and Reconstruction via Cross-View Collaboration in Densely Built-Up Areas
        </a>
    </h3>
    <div style="font-style: italic;">202601, pp. 49-63(15)</div>
    <div>Authors: Tang, Shengjun; Chen, Yujie; Yu, Tian; Li, You; Xie, Linfu; Wang, Weixi; Guo, Renzhong</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2026/01/Optimized 3D Building Mapping and Reconstruction via Cross-View Collaboration in Densely Built-Up Areas.png" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                High-precision urban three-dimensional (3D) point clouds can be effectively generated using airborne oblique photogrammetry and lidar scanning. However, due to occlusions from dense building layouts and vegetation, existing airborne acquisition methods often struggle to capture complete building geometries. This incompleteness poses serious challenges for applications such as urban planning, smart city management, and autonomous navigation, which require structurally complete and accurate 3D data. To address this limitation, this paper proposes a novel cross-view collaborative surveying framework that integrates aerial and ground-based data collection for precise and efficient 3D reconstruction of urban buildings. The framework begins by performing automated building completeness detection on aerial point clouds using a multi-layer slice projection algorithm, which enables accurate identification of missing regions in both point-wise and surface-wise forms. These detected deficiencies are then used to guide the generation of optimized ground-based supplementary acquisition routes, incorporating a global-local planning mechanism and a multi-objective technologies for autonomous robot exploration (TARE) strategy to enable autonomous and adaptive data collection. Comprehensive experiments were conducted in both simulated and real-world urban environments. Evaluation metrics focused on point cloud completeness and 3D reconstruction accuracy. The results demonstrate that the proposed method significantly enhances the completeness of building point clouds, achieving an average detection accuracy above 90%, while also reducing reconstruction error by up to 65% in complex urban scenarios. The proposed method provides a valuable tool for urban mapping professionals, autonomous systems, and digital city infrastructure developers who depend on high-quality 3D building models.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2026/00000092/00000001/art00011;jsessionid=c89kft5md6pb.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Lightweight YOLO-Based Algorithm for Digital Target Recognition Integrating Positional Enhancement and Morphological Processing
        </a>
    </h3>
    <div style="font-style: italic;">202601, pp. 65-72(8)</div>
    <div>Authors: Wang, Sheng; Zheng, Nae; Lv, Pinpin; Gao, Tian</div>
    <div class="ga-image">
        <img src="https://raw.githubusercontent.com/tang1693/PERShtml/refs/heads/main/IssuesArticles/html/img/2026/01/A Lightweight YOLO-Based Algorithm for Digital Target Recognition Integrating Positional Enhancement and Morphological Processing.jpg" alt="Graphical Abstract">
    </div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Target detection is vital for modern military applications, yet deploying deep learning models on resource-limited edge devices remains challenging. Existing lightweight models often exhibit poor boundary localization and low digit recognition accuracy, falling short of real-time and precision requirements. This paper introduces a lightweight YOLO-based algorithm enhanced with a novel positional mechanism and morphological processing. The key component, a position-enhanced feature pyramid network (Enhanced-FPN), fuses shallow high-resolution and deep semantic features to improve localization accuracy. A ShuffleNetv2 backbone ensures low computational overhead, while a postdetection module applies morphological processing to robustly extract digit contours and orientation. Evaluated on a custom military data set, the model achieves 49.92% mean average precision at a 50% intersection over union threshold (mAP50) at 11.24 frames/second on an edge device–improving accuracy by 7.02 points and speed by 12.8% over the Yolo-FastestV2 baseline, with a comparable 0.11 GFLOP (Giga Floating Point Operations per second) cost. These results highlight the method’s effectiveness for real-time, high-precision target recognition in constrained environments.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 01 - Year 2026</p>
        </footer>
    </body>
    </html>
    