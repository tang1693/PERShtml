
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 06 - Year 2006</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 06 - Year 2006</h1>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00001;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Canopy Reflectance Related to Marsh Dieback Onset and Progression in Coastal Louisiana
        </a>
    </h3>
    <div style="font-style: italic;">200606, nan</div>
    <div>Authors: Ramsey III, Elijah; Rangoonwala, Amina</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this study, we extended previous work linking leaf spectral changes, dieback onset, and progression ofSpartina alterni-floramarshes to changes in site-specific canopy reflectance spectra. First, we obtained canopy reflectance spectra (approximately 20 m ground resolution) from the marsh sites occupied during the leaf spectral analyses and from additional sites exhibiting visual signs of dieback. Subsequently, the canopy spectra were analyzed at two spectral scales: the first scale corresponded to whole-spectra sensors, such as the NASA Earth Observing-1 (EO-1) Hyperion, and the second scale corresponded to broadband spectral sensors, such as the EO-1 Advanced Land Imager and the Landsat Enhanced Thematic Mapper. In the whole-spectra analysis, spectral indicators were generated from the whole canopy spectra (about 400 nm to 1,000 nm) by extracting typical dead and healthy marsh spectra, and subsequently using them to determine the percent composition of all canopy reflectance spectra. Percent compositions were then used to classify canopy spectra at each field site into groups exhibiting similar levels of dieback progression ranging from relatively healthy to completely dead. In the broadband reflectance analysis, blue, green, red, red-edge, and near infrared (NIR) spectral bands and NIR/green and NIR/red transforms were extracted from the canopy spectra. Spectral band and band transform indicators of marsh dieback and progression were generated by relating them to marsh status indicators derived from classifications of the 35 mm slides collected at the same time as the canopy reflectance recordings. The whole spectra and broadband spectral indicators were both able to distinguish (a) healthy marsh, (b) live marsh impacted by dieback, and (c) dead marsh, and they both provided some discrimination of dieback progression. Whole-spectra resolution sensors like the EO-1 Hyperion, however, offered an enhanced ability to categorize dieback progression.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00002;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Time-Series Analysis of Medium-Resolution, Multisensor Satellite Data for Identifying Landscape Change
        </a>
    </h3>
    <div style="font-style: italic;">200606, pp. 653-663(11)</div>
    <div>Authors: Millward, Andrew A.; Piwowar, Joseph M.; Howarth, Philip J.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The overall goal of this study is to use medium-resolution satellite imagery to determine recent changes in the landscape of the coastal zone near Sanya in the Province of Hainan, China. A search for suitable satellite imagery revealed that the only way to identify the changes was to use data from three different sensors acquired over a 12-year time period: a 1987 Landsat 5 Thematic Mapper (TM) image, a 1999 Landsat 7 Enhanced Thematic Mapper Plus (ETM+) image, and two SPOT 2 High Resolution Visible (HRV) images acquired in 1991 and 1997. Given that the Landsat and SPOT images have different spatial resolutions and that the spectral bands cover somewhat different spectral ranges, the challenge was how to combine the images in digital format to be able to detect subtle changes in the landscape. Measures of brightness, greenness, and the normalized difference vegetation index (NDVI) were explored using standardized principal components analysis (PCA). Approximately 38 percent of the scene was occupied by water, so tests were performed with the water included and also with the water masked out to remove these low-variance pixels. Factor loadings and input-band contributions were used to interpret component images. Results show that PCA of the visible bands, representing brightness, is the superior approach for identifying new urban features in the landscape. For identification of changes to vegetation, the near-infrared (NIR) bands outperformed NDVI. Selected stan-dardized PCA images with visible and NIR bands are recommended for identifying general changes to an urban landscape using a time-series of imagery acquired by different satellite sensors. Benefits of using a mask are believed to be dependent upon study-site characteristics.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00003;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Multi-scale Segmentation Approach to Mapping Seagrass Habitats Using Airborne Digital Camera Imagery
        </a>
    </h3>
    <div style="font-style: italic;">200606, pp. 665-675(11)</div>
    <div>Authors: Lathrop, Richard G.; Montesano, Paul; Haag, Scott</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The purpose of this study was to map the areal extent and density of submerged aquatic vegetation, principally the seagrasses, Zostera marina and Ruppia maritima, as part of ongoing monitoring for the Barnegat Bay, New Jersey National Estuary Program. We examine the utility of multi-scale image segmentation/object-oriented image classification using the eCognition software to map seagrass across our 36,000 ha study area. The multi-scale image segmentation/ object oriented classification approach closely mirrored our conceptual model of the spatial structure of the seagrass habitats and successfully extracted the features of ecological interest. The agreement between the mapped results and the original field reference was 68 percent (Kappa = 56.5 percent) for the four category map and 83 percent (Kappa = 63.1 percent) for the presence/absence map; the agreement between the mapped results and the independent reference data was 71 percent (Kappa = 43.0 percent) for a simple presence/absence map. While the aerial digital camera imagery employed in this study had the advantage of flexible acquisition, suitable image scale, fast processing return time, and comparatively low cost, it had inconsistent radiometric response from image to image. This inconsistency made it difficult to develop a rule-based classification that was universally applicable across the 14 individual image mosaics. However, within the individual scene mosaics, using the eCognition software in a “manual classification” mode provided a flexible and time effective approach to mapping seagrass habitats.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00004;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automated Thematic Registration of NOAA, CoastWatch, and AVHRR Images
        </a>
    </h3>
    <div style="font-style: italic;">200606, pp. 677-685(9)</div>
    <div>Authors: Ferguson, Randolph L.; Krouse, Charles; Patterson, Marlene; Hare, Jonathan A.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Daily for the United States, the National Oceanic and Atmospheric Administration (NOAA), CoastWatch Program produces multiple regional daytime images and sea surface temperature (SST) images derived from Advanced Very High Resolution Radiometry (AVHRR). Images have 1.1 km pixel resolution at nadir, <1 pixel systematic error (rotation, scale, distortion), but up to 9 pixels translation (offset) error. New fully-automated registration to a reference map corrects translation error to mean radial error<1 pixel suitable for full pixel resolution application in inshore waters and large estuaries. The approach converts AVHRR Channel 1 and 2 data to a land and water thematic image, finds the offset to maximize classification accuracy, and repositions the AVHRR and SST images. Registration was robust to cloud cover and missing data and was more reliable than manual registration for cloudy images. Developed for the southeast region of the U.S., the approach is transportable to other regions.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00005;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            High Spatial Resolution Satellite Imagery, DEM Derivatives, and Image Segmentation for the Detection of Mass Wasting Processes
        </a>
    </h3>
    <div style="font-style: italic;">200606, pp. 687-692(6)</div>
    <div>Authors: Barlow, John; Franklin, Steven; Martin, Yvonne</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                An automated approach to identifying landslides using a combination of high-resolution satellite imagery and digital elevation derivatives is offered as an alternative to aerial photographic interpretation. Previous research has demonstrated that per pixel spectral response patterns are ineffective in discriminating mass movements. This technique utilizes image segmentation and digital elevation data in order to identify mass movements based not only on their reflectance but also on their shape properties and their geomorphic context. Dividing the classification by process into debris slides, debris flows, and rock slides makes the method far more useful than methods that group all mass movements together. A hierarchical classification scheme is utilized to eliminate areas that are not of interest and to identify areas where mass movements are probable. A supervised classification is then conducted using spectral, shape, and textural properties to identify failures that were greater than 1 ha in area. The resulting accuracy was 90 percent for debris slides, 60 percent for debris flows, and 80 percent for rock slides.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00006;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Fusing Landsat-5/TM Imagery and Shaded Relief Maps in Tectonic and Geomorphic Mapping
        </a>
    </h3>
    <div style="font-style: italic;">200606, pp. 693-700(8)</div>
    <div>Authors: Soulakellis, Nikolaos A.; Novak, Irwin D.; Zouros, Nikolaos; Lowman, Paul; Yates, Jacob</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The significance of both solar elevation angle and azimuth are critical elements for examining Earth observation datasets. Illumination angle is a crucial parameter affecting the appearance of the topographically related and dependent features. Therefore, an improved methodology of data fusion for tectonic and geomorphic mapping is needed to augment the traditional false color composite analysis. A long-standing problem in such applications is the bias introduced by illumination geometry, specifically sun elevation and azimuth. A Landsat-5 image of Lesvos Island, Greece, was combined with digital elevation models to produce fused images with a wide range of illumination azimuths and elevation in a GIS environment. Sixteen combinations of sun elevation angle (using 15° and 30°) paired with azimuth (0° to 360° at 45° increments) were considered. This new technique compensates for local conditions such as generally cloudy winters which make it difficult to obtain images with low sun elevation or images of eroded landforms with subdued geomorphic expression. The resulting fused images combine the tonal information and high spatial resolution of Landsat with the strong topographic rendition of digital elevation models. Well-known faults, with more or less significant expression on the surface known from previous image interpretation and fieldwork, are more easily identifiable. Shaded relief maps produced by applying the lower illumination angle in combination with an azimuth perpendicular to the fault orientation produced the best results. Additionally, previously unknown linear and circular features, e.g., calderas, were represented in the low illumination angle image, independent of its azimuth. Fused images will be further combined with geologic and seismicity maps to study problems such as location of the Anatolian Plate’s boundaries and their nature (sharp or diffuse).
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2006/00000072/00000006/art00007;jsessionid=17yfj9i3ig99t.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Built-up Areas from Multitemporal Interferometric SAR Images - A Segment-based Approach
        </a>
    </h3>
    <div style="font-style: italic;">200606, pp. 701-714(14)</div>
    <div>Authors: Matikainen, Leena; Hyyppä, Juha; Engdahl, Marcus E.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Automatic mapping of built-up areas from a multitemporal interferometric ERS-1/2 Tandem dataset was studied. The image data were segmented into homogeneous regions, and the regions were classified as built-up areas, forests, and open areas using their mean intensity and coherence values and additional contextual information. Compared with a set of reference points, an overall classification accuracy of 97 percent was achieved. The classification process was highly automatic and resulted in homogeneous regions resembling a map drawn by a human interpreter. The feasibility of the imagery for dividing built-up areas further into subclasses was also investigated. The results suggest that low-rise areas, high-rise areas, and industrial areas are difficult to distinguish from each other. On the other hand, a correlation between the building density, the proportion of land covered with buildings, and intensity/coherence in the image data was found. The dataset thus appeared to be promising for classifying built-up areas into subclasses according to building density.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 06 - Year 2006</p>
        </footer>
    </body>
    </html>
    