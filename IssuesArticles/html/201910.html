
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 10 - Year 2019</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 10 - Year 2019</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000010" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000010/art00012;jsessionid=4p1rfhfutrdw7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Mapping Annual Urban Change Using Time Series Landsat and NLCD
        </a>
    </h3>
    <div style="font-style: italic;">201910, pp. 715-724(10)</div>
    <div>Authors: Wan, Heng; Shao, Yang; Campbell, James B.; Deng, Xinwei</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Annual urban change information is important for an improved understanding of urban dynamics and continuous modeling of urban ecosystem processes. This study examined Landsat-derived Normalized Difference Vegetation Index (NDVI) time series for characterizing annual urban change. To reduce impacts from cloud contamination and missing data, United States Geological Survey (USGS) Landsat Analysis Ready Data were processed to derive annual NDVI layers using a maximum value composite algorithm. National Land Cover Database land cover products from 2001 and 2011 were used as references for generating a decadal urban change mask. Within the decadal urban change mask and using annual NDVI as input, we examined three time-series change detection methods to pinpoint specific year of urban change: (a) minimum-value method, (b) break-point detection, and (c) simple-threshold identification. For accuracy assessment, we divided change pixels into urbanization and urban-intensification pixel groups, defined by initial land cover types. We used Google Earth's High-Resolution Imagery Archive as primary reference data for detailed accuracy assessment. Overall, the urbanization pixel group has good change detection accuracies of above 82% for all three change detection algorithms. The break-point detection method resulted in the highest overall accuracy of 88%. Overall accuracies for urban intensification pixel group were in the range of 35%–76%, depending on choice of change detection algorithm, length of input time-series, and further division of pixel subgroups.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000010/art00013;jsessionid=4p1rfhfutrdw7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Robust Multisource Remote Sensing Image Registration Method Based on Scene Shape Similarity
        </a>
    </h3>
    <div style="font-style: italic;">201910, pp. 725-736(12)</div>
    <div>Authors: Hao, Ming; Jin, Jian; Zhou, Mengchao; Tian, Yi; Shi, Wenzhong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Image registration is an indispensable component of remote sensing applications, such as disaster monitoring, change detection, and classification. Grayscale differences and geometric distortions often occur among multisource images due to their different imaging mechanisms, thus making it difficult to acquire feature points and match corresponding points. This article proposes a scene shape similarity feature (SSSF) descriptor based on scene shape features and shape context algorithms. A new similarity measure called SSSFnccis then defined by computing the normalized correlation coefficient of the SSSF descriptors between multisource remote sensing images. Furthermore, the tie points between the reference and the sensed image are extracted via a template matching strategy. A global consistency check method is then used to remove the mismatched tie points. Finally, a piecewise linear transform model is selected to rectify the remote sensing image. The proposed SSSFnccaims to extract the scene shape similarity between multisource images. The accuracy of the proposed SSSFnccis evaluated using five pairs of experimental images from optical, synthetic aperture radar, and map data. Registration results demonstrate that the SSSFnccsimilarity measure is robust enough for complex nonlinear grayscale differences among multisource remote sensing images. The proposed method achieves more reliable registration outcomes compared with other popular methods.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000010/art00014;jsessionid=4p1rfhfutrdw7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Accurate Detection of Built-Up Areas from High-Resolution Remote Sensing Imagery Using a Fully Convolutional Network
        </a>
    </h3>
    <div style="font-style: italic;">201910, pp. 737-752(16)</div>
    <div>Authors: Tan, Yihua; Xiong, Shengzhou; Li, Zhi; Tian, Jinwen; Li, Yansheng</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The analysis of built-up areas has always been a popular research topic for remote sensing applications. However, automatic extraction of built-up areas from a wide range of regions remains challenging. In this article, a fully convolutional network (FCN)–based strategy is proposed to address built-up area extraction. The proposed algorithm can be divided into two main steps. First, divide the remote sensing image into blocks and extract their deep features by a lightweight multi-branch convolutional neural network (LMB-CNN). Second, rearrange the deep features into feature maps that are fed into a well-designed FCN for image segmentation. Our FCN is integrated with multi-branch blocks and outputs multi-channel segmentation masks that are utilized to balance the false alarm and missing alarm. Experiments demonstrate that the overall classification accuracy of the proposed algorithm can achieve 98.75% in the test data set and that it has a faster processing compared with the existing state-of-the-art algorithms.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000010/art00015;jsessionid=4p1rfhfutrdw7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Postprocessing Synchronization of a Laser Scanning System Aboard a UAV
        </a>
    </h3>
    <div style="font-style: italic;">201910, pp. 753-763(11)</div>
    <div>Authors: Machado, Marcela do Valle; Tommaselli, Antonio Maria Garcia; Torres, Fernanda Magri; Campos, Mariana Batista</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Synchronization of airborne laser scanning devices is a critical process that directly affects data accuracy. This process can be more challenging with low-cost airborne laser scanning (ALS) systems because some device connections from off-the-shelf sensors are less stable. An alternative to synchronization is performing a postprocessing clock correction. This article presents a technique for postprocessing synchronization (off-line) that estimates clock differences based on the correlation between the signals from the global navigation satellite system (GNSS) trajectory and the light detection and ranging (lidar) range, followed by refinement with a least-squares method. The correlation between signals was automatically estimated considering the planned flight maneuvers, in a flat terrain, to produce altimetric trajectory variations. Experiments were performed with an Ibeo LUX laser unit integrated with a NovAtel SPAN-IGM-S1 inertial navigation system that was transported by an unmanned aerial vehicle (UAV). The planimetric and altimetric accuracies of the point cloud obtained with the proposed postprocessing synchronization technique were 28 cm and 10 cm, respectively, at a flight height of 35 m.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2019/00000085/00000010/art00016;jsessionid=4p1rfhfutrdw7.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A CNN-Based Subpixel Level DSM Generation Approach via Single Image Super-Resolution
        </a>
    </h3>
    <div style="font-style: italic;">201910, pp. 765-775(11)</div>
    <div>Authors: Zhang, Yongjun; Zheng, Zhi; Luo, Yimin; Zhang, Yanfeng; Wu, Jun; Peng, Zhiyong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Previous work for subpixel level Digital Surface Model (DSM) generation mainly focused on data fusion techniques, which are extremely limited by the difficulty of multisource data acquisition. Although several DSM super resolution (SR) methods have been developed to ease the problem, a new issue that plenty of DSM samples are needed to train the model is raised. Therefore, considering the original images have vital influence on its DSM's accuracy, we address the problem by directly improving images resolution. Several SR models are refined and brought into the traditional DSM generation process as an image quality improvement stage to construct an easy but effective workflow for subpixel level DSM generation. Experiments verified the validity and significance of bringing SR technology into this kind of application. Statistical analysis also confirmed that a subpixel level DSM with higher fidelity can be obtained more easily compared to directly DSM interpolation.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 10 - Year 2019</p>
        </footer>
    </body>
    </html>
    