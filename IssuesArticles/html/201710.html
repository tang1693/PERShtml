
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 10 - Year 2017</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 10 - Year 2017</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00008;jsessionid=hm6qh4tdumpw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Bound-Constrained Multiple-Image Least-Squares Matching for Multiple-Resolution Images
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 667-677(11)</div>
    <div>Authors: Hu, Han; Wu, Bo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Satellite images from multiple sources with different resolutions are currently able to observe the same region. Reliable image matching between these images is the first step in their integrated use. Image matching of multiple-resolution images is not trivial because of the large geometric differences among the images, which can cause failure of matching and losses of matching accuracy. This paper presents a bound-constrained, multiple-image, least-squares matching (LSM) method that extends the classicalLSMin two ways for better performance. First, the a priori metadata of the images, including the geo-referencing and scale information, are used for initial matching and to provide bound constraints in theLSMto improve its stability. Second, multiple images are matched in a single optimization rather than the traditional pairwise matching. This brings additional observations in the least-squares optimization, which makes the matching aware of both larger and local context and improves matching quality even with inaccurate initializations for high resolution images. Experimental analysis using multiple-source satellite images with multiple resolutions collected on Mars and in Hong Kong reveals that the proposed method is capable of obtaining reliable multiple-fold matches effectively, even in challenging cases with resolution differences as much as 20-fold. The method proposed in this paper has significance for the synergistic use of multiple-source satellite images in various applications.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00009;jsessionid=hm6qh4tdumpw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Thematic Accuracy of Agriculture in Land Cover Layers of Select Virginia Counties
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 679-692(14)</div>
    <div>Authors: Kokkinidis, Ioannis; Hodges, Steven C.; Wynne, Randolph H.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                NLCDandNASS CDLare freely available moderate resolution land cover datasets, but their accuracies vary widely and are untested for agricultural land in Virginia. We performed validation through aerial photointerpretation of agriculture at the field level, using cadastral parcels as proxies for fields, over Albemarle, Charles City, Chesterfield, and Henrico Counties forNLCD1992, 2001, 2006 andCDL2002, 2008, 2009, 2010, and 2011. The extent of agricultural land remained generally stable over 19 years but is generally overestimated by the datasets in all four counties, ranging from 70.06 percent to 697.48 percent of validation layer extent. Extent of agricultural land in our validation layer also differed from the Census of Agriculture, likely due to differing definition. Comparison of layer pairs on extent of agricultural land mostly reveals classification artifacts rather than change. The limited extent of agriculture and mixed land cover characteristics of the region suggest the use of multitemporal data to extract agricultural land cover.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00010;jsessionid=hm6qh4tdumpw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Geometric Correspondence Feature Based-Mismatch Removal in Vision Based-Mapping and Navigation
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 693-704(12)</div>
    <div>Authors: Li, Zeyu; Wang, Jinling; Toth, Charles</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Images with large-area repetitive texture, significant viewpoint, and illumination changes as well as occlusions often induce high-percentage keypoint mismatches, affecting the performance of vision-based mapping and navigation. Traditional methods for mismatch elimination tend to fail when the percentage of mismatches is high. In order to remove mismatches effectively, a new geometry-based approach is proposed in this paper, where Geometric Correspondence Feature (GCF) is used to represent the tentative correspondence. Based on the clustering property ofGCFsfrom correct matches, a new clustering algorithm is developed to identify the cluster formed by the correct matches.With the defined quality factor calculated from the identified cluster, a Progressive Sample Consensus (PROSAC) process integrated with hyperplane-model is employed to further eliminate mismatches.Extensive experiments based on both simulated and real images in indoor and outdoor environments have demonstrated that the proposed approach can significantly improve the performance of mismatch elimination in the presence of high-percentage mismatches.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00011;jsessionid=hm6qh4tdumpw.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Registration of Images To Lidar and GIS Data Without Establishing Explicit Correspondences
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 705-716(12)</div>
    <div>Authors: Barsai, Gabor; Yilmaz, Alper; Nagarajan, Sudhagar; Srestasathiern, Panu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Recovering the camera orientation is a fundamental problem in photogrammetry for precision 3D recovery, orthophoto generation, and image registration. In this paper, we achieve this goal by fusing the image information with information extracted from different modalities, including lidar andGIS. In contrast to other approaches, which require feature correspondences, our approach exploits edges across the modalities without the necessity to explicitly establish correspondences. In the proposed approach, extracted edges from different modalities are not required to have analytical forms. This flexibility is achieved by minimizing a new cost function using a Bayesian approach, which takes the Euclidean distances between the projected edges extracted from the other data source and the edges extracted from the reference image as its random variable. The proposed formulation minimizes the overall distances between the sets of edges iteratively, such that the end product results in the correct camera parameters for the reference image as well as matching features across the modalities. The initial solution can be obtained fromGPS/IMUdata. The formulation is shown to successfully handle noise and missing observations in edges. Point matching methods may fail for oblique images, especially high oblique images. We eliminate the requirement for exact point-to-point matching. The feasibility of the method is experimented with nadir and oblique images.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00008;jsessionid=2goo4m0s6qhqb.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Bound-Constrained Multiple-Image Least-Squares Matching for Multiple-Resolution Images
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 667-677(11)</div>
    <div>Authors: Hu, Han; Wu, Bo</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Satellite images from multiple sources with different resolutions are currently able to observe the same region. Reliable image matching between these images is the first step in their integrated use. Image matching of multiple-resolution images is not trivial because of the large geometric differences among the images, which can cause failure of matching and losses of matching accuracy. This paper presents a bound-constrained, multiple-image, least-squares matching (LSM) method that extends the classicalLSMin two ways for better performance. First, the a priori metadata of the images, including the geo-referencing and scale information, are used for initial matching and to provide bound constraints in theLSMto improve its stability. Second, multiple images are matched in a single optimization rather than the traditional pairwise matching. This brings additional observations in the least-squares optimization, which makes the matching aware of both larger and local context and improves matching quality even with inaccurate initializations for high resolution images. Experimental analysis using multiple-source satellite images with multiple resolutions collected on Mars and in Hong Kong reveals that the proposed method is capable of obtaining reliable multiple-fold matches effectively, even in challenging cases with resolution differences as much as 20-fold. The method proposed in this paper has significance for the synergistic use of multiple-source satellite images in various applications.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00009;jsessionid=2goo4m0s6qhqb.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Thematic Accuracy of Agriculture in Land Cover Layers of Select Virginia Counties
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 679-692(14)</div>
    <div>Authors: Kokkinidis, Ioannis; Hodges, Steven C.; Wynne, Randolph H.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                NLCDandNASS CDLare freely available moderate resolution land cover datasets, but their accuracies vary widely and are untested for agricultural land in Virginia. We performed validation through aerial photointerpretation of agriculture at the field level, using cadastral parcels as proxies for fields, over Albemarle, Charles City, Chesterfield, and Henrico Counties forNLCD1992, 2001, 2006 andCDL2002, 2008, 2009, 2010, and 2011. The extent of agricultural land remained generally stable over 19 years but is generally overestimated by the datasets in all four counties, ranging from 70.06 percent to 697.48 percent of validation layer extent. Extent of agricultural land in our validation layer also differed from the Census of Agriculture, likely due to differing definition. Comparison of layer pairs on extent of agricultural land mostly reveals classification artifacts rather than change. The limited extent of agriculture and mixed land cover characteristics of the region suggest the use of multitemporal data to extract agricultural land cover.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00010;jsessionid=2goo4m0s6qhqb.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Geometric Correspondence Feature Based-Mismatch Removal in Vision Based-Mapping and Navigation
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 693-704(12)</div>
    <div>Authors: Li, Zeyu; Wang, Jinling; Toth, Charles</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Images with large-area repetitive texture, significant viewpoint, and illumination changes as well as occlusions often induce high-percentage keypoint mismatches, affecting the performance of vision-based mapping and navigation. Traditional methods for mismatch elimination tend to fail when the percentage of mismatches is high. In order to remove mismatches effectively, a new geometry-based approach is proposed in this paper, where Geometric Correspondence Feature (GCF) is used to represent the tentative correspondence. Based on the clustering property ofGCFsfrom correct matches, a new clustering algorithm is developed to identify the cluster formed by the correct matches.With the defined quality factor calculated from the identified cluster, a Progressive Sample Consensus (PROSAC) process integrated with hyperplane-model is employed to further eliminate mismatches.Extensive experiments based on both simulated and real images in indoor and outdoor environments have demonstrated that the proposed approach can significantly improve the performance of mismatch elimination in the presence of high-percentage mismatches.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2017/00000083/00000010/art00011;jsessionid=2goo4m0s6qhqb.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Registration of Images To Lidar and GIS Data Without Establishing Explicit Correspondences
        </a>
    </h3>
    <div style="font-style: italic;">201710, pp. 705-716(12)</div>
    <div>Authors: Barsai, Gabor; Yilmaz, Alper; Nagarajan, Sudhagar; Srestasathiern, Panu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Recovering the camera orientation is a fundamental problem in photogrammetry for precision 3D recovery, orthophoto generation, and image registration. In this paper, we achieve this goal by fusing the image information with information extracted from different modalities, including lidar andGIS. In contrast to other approaches, which require feature correspondences, our approach exploits edges across the modalities without the necessity to explicitly establish correspondences. In the proposed approach, extracted edges from different modalities are not required to have analytical forms. This flexibility is achieved by minimizing a new cost function using a Bayesian approach, which takes the Euclidean distances between the projected edges extracted from the other data source and the edges extracted from the reference image as its random variable. The proposed formulation minimizes the overall distances between the sets of edges iteratively, such that the end product results in the correct camera parameters for the reference image as well as matching features across the modalities. The initial solution can be obtained fromGPS/IMUdata. The formulation is shown to successfully handle noise and missing observations in edges. Point matching methods may fail for oblique images, especially high oblique images. We eliminate the requirement for exact point-to-point matching. The feasibility of the method is experimented with nadir and oblique images.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 10 - Year 2017</p>
        </footer>
    </body>
    </html>
    