
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 05 - Year 2016</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 05 - Year 2016</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00012;jsessionid=kks97b4hx4sj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Camera Self-Calibration with Lens Distortion from a Single Image
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 325-334(10)</div>
    <div>Authors: Liu, Dan; Liu, Xuejun; Wang, Meizhen</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents an effective approach for self-calibration with lens distortion using a single image combined with geometric constraints including vanishing points and ellipses. To improve the accuracy of self-calibration, radial distortion and distortion center are included in the calibration procedure. First, assuming image center as the symmetric center, the first radial distortion coefficient and vanishing points are simultaneously optimized from line segments in the image. Second, by utilizing the optimized vanishing points and extracted ellipse, principal distance and principal point are estimated. Last, distortion center is set as the current calculated principal point, and the above steps are then repeated until the principal point reaches a stable solution. Extensive quantitative and qualitative studies of the approach are performed. The experiments pertaining to simulated and real images demonstrate that the approach is effective and suitable and that the approach obtains satisfactory results.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00013;jsessionid=kks97b4hx4sj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Extraction of Urban Impervious Surface Using Two-Season WorldView-2 Images: A Comparison
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 335-349(15)</div>
    <div>Authors: Cai, Cai; Li, Peijun; Jin, Huiran</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Although multispectral images acquired during the summer season have been used extensively in impervious surface extraction with relatively high accuracy, the area of impervious surface extracted is generally underestimated. In this study, a quantitative comparison of urban impervious surface extraction was conducted using WorldView-2 images of the summer and winter seasons over two urban areas in a temperate region of Northern China. A hierarchical object-based classification method was adopted to extract urban impervious surfaces. The results showed that the impervious surface extraction from the winter image achieved an accuracy comparable with that from the summer image. However, the area of impervious surface extracted from the winter image was much greater than that from the summer image, which was mainly attributed to seasonal variations of deciduous trees. Therefore, winter images are recommended for impervious surface mapping in temperate regions using very high resolution images.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00016;jsessionid=kks97b4hx4sj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            ICESat/GLAS Canopy Height Sensitivity Inferred from Airborne Lidar
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 351-363(13)</div>
    <div>Authors: Mahoney, Craig; Hopkinson, Chris; Held, Alex; Kljun, Natascha; Van Gorsel, Eva</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Variations in laser properties and data acquisition times introduced inconsistencies in Geoscience Laser Altimeter System (GLAS) data. The effect of data inconsistencies, on two GLAS height retrieval methods, from three study sites, are investigated and validated against airborne laser scanning (ALS) percentile heights, from three data sources: all/first return point clouds, and raster canopy height models. GLAS/ALS controls were established as a basis against which the influence of laser number, transmission energy, and seasonality were assessed through comparison statistics. The favored GLAS height method best compared with ALS 95thpercentile heights from an all return point cloud. Optimal GLAS data (R2= 0.69, RMSE = 8.10 m) were noted when GLAS acquired data during summertime from high energy, laser three transmissions. As GLAS data can be used in global biomass assessments, there is a need to understand and quantify the influence of these data inconsistencies on canopy height estimates.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00018;jsessionid=kks97b4hx4sj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Novel Automatic Structural Linear Feature-based Matching Method Based on New Concepts of Mathematically-Generated-Points and Lines
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 365-376(12)</div>
    <div>Authors: Yavari, Somayeh; Zoej, Mohammad Javad Valadan; Sahebi, Mahmod Reza; Mokhtarzade, Mehdi</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper investigates reliable automatic high resolution image to map matching using a novel structural linear feature-based matching (SLIM) method. The main components used by this method are the specific patterns as well as the lines and points generated mathematically. These components are produced by extension and intersection of extracted line-segments. Due to the high numbers of extracted line-segments in both image and object space, the number of possible patterns is very high. In order to decrease the search space, the innovativeSLIMmethod is performed in three main phases. In the first phase, using a new weighting procedure, only optimum numbers of high-qualified well-distributed patterns, which are more likely to have any correspondence in object space, are selected. In the second phase, the aim is to find a pair with maximum numbers of conjugate lines. To do so, all the possible patterns in object space are screened for each selected image pattern using four predefined geometric criteria. Simultaneously, the correspondence of the other crossing lines is also determined in the same manner. In third phase, the pair with maximum numbers of matched-lines is selected among all the results of second phase. Additionally, the final-phase is done to increase the amount of correctly matched-lines. The main contribution of this investigation is automatic and correct matching of linear features with no need to any initial information. Additionally, the end-points of the corresponding lines are not necessarily conjugate points. The results show the high potential of the proposed method in terms of accuracy, reliability, automation, and time reduction even in images with repetitive patterns or a high numbers of outliers.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00019;jsessionid=kks97b4hx4sj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Autonomous Ortho-Rectification of Very High Resolution Imagery Using SIFT and Genetic Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 377-388(12)</div>
    <div>Authors: Konugurthi, Pramod Kumar; Kune, Raghavendra; Nooka, Ravi; Sarma, Venkatraman</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Ortho-rectification of very high resolution imagery from agile platforms using Rigorous Sensor Model / Rational Functional Model is quite challenging and demands a fair amount of interactivity in Ground Control Point (GCP) identification/selection for refining the model and for final product evaluation. The paper proposes achieving complete automation in the ortho-rectification process by eliminating all the interactive components, and incorporating fault tolerance mechanisms within the model to make the process robust and reliable. The key aspects proposed in this paper are: two stage Scale Invariant Feature Transform (SIFT) based matching to obtain a large numbers of checkpoints using much coarser resolution images such as Landsat/ETM+, followed by a GA to select the right combination of minimal GCPS based on minimizing Root Mean Square Error (RMSE) and maximizing the area covered under GCPS, and finally, a decision rule based product evaluation to make the process operate in an "autonomous closed loop mode". The method is generic and has been tested on hundreds of Cartosat-1/2 images, and has achieved above 90% reliability with sub-pixel relative error of reference data.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00012;jsessionid=rx00wfm9ifj8.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Camera Self-Calibration with Lens Distortion from a Single Image
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 325-334(10)</div>
    <div>Authors: Liu, Dan; Liu, Xuejun; Wang, Meizhen</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents an effective approach for self-calibration with lens distortion using a single image combined with geometric constraints including vanishing points and ellipses. To improve the accuracy of self-calibration, radial distortion and distortion center are included in the calibration procedure. First, assuming image center as the symmetric center, the first radial distortion coefficient and vanishing points are simultaneously optimized from line segments in the image. Second, by utilizing the optimized vanishing points and extracted ellipse, principal distance and principal point are estimated. Last, distortion center is set as the current calculated principal point, and the above steps are then repeated until the principal point reaches a stable solution. Extensive quantitative and qualitative studies of the approach are performed. The experiments pertaining to simulated and real images demonstrate that the approach is effective and suitable and that the approach obtains satisfactory results.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00013;jsessionid=rx00wfm9ifj8.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Extraction of Urban Impervious Surface Using Two-Season WorldView-2 Images: A Comparison
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 335-349(15)</div>
    <div>Authors: Cai, Cai; Li, Peijun; Jin, Huiran</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Although multispectral images acquired during the summer season have been used extensively in impervious surface extraction with relatively high accuracy, the area of impervious surface extracted is generally underestimated. In this study, a quantitative comparison of urban impervious surface extraction was conducted using WorldView-2 images of the summer and winter seasons over two urban areas in a temperate region of Northern China. A hierarchical object-based classification method was adopted to extract urban impervious surfaces. The results showed that the impervious surface extraction from the winter image achieved an accuracy comparable with that from the summer image. However, the area of impervious surface extracted from the winter image was much greater than that from the summer image, which was mainly attributed to seasonal variations of deciduous trees. Therefore, winter images are recommended for impervious surface mapping in temperate regions using very high resolution images.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00016;jsessionid=rx00wfm9ifj8.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            ICESat/GLAS Canopy Height Sensitivity Inferred from Airborne Lidar
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 351-363(13)</div>
    <div>Authors: Mahoney, Craig; Hopkinson, Chris; Held, Alex; Kljun, Natascha; Van Gorsel, Eva</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Variations in laser properties and data acquisition times introduced inconsistencies in Geoscience Laser Altimeter System (GLAS) data. The effect of data inconsistencies, on two GLAS height retrieval methods, from three study sites, are investigated and validated against airborne laser scanning (ALS) percentile heights, from three data sources: all/first return point clouds, and raster canopy height models. GLAS/ALS controls were established as a basis against which the influence of laser number, transmission energy, and seasonality were assessed through comparison statistics. The favored GLAS height method best compared with ALS 95thpercentile heights from an all return point cloud. Optimal GLAS data (R2= 0.69, RMSE = 8.10 m) were noted when GLAS acquired data during summertime from high energy, laser three transmissions. As GLAS data can be used in global biomass assessments, there is a need to understand and quantify the influence of these data inconsistencies on canopy height estimates.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00018;jsessionid=rx00wfm9ifj8.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Novel Automatic Structural Linear Feature-based Matching Method Based on New Concepts of Mathematically-Generated-Points and Lines
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 365-376(12)</div>
    <div>Authors: Yavari, Somayeh; Zoej, Mohammad Javad Valadan; Sahebi, Mahmod Reza; Mokhtarzade, Mehdi</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper investigates reliable automatic high resolution image to map matching using a novel structural linear feature-based matching (SLIM) method. The main components used by this method are the specific patterns as well as the lines and points generated mathematically. These components are produced by extension and intersection of extracted line-segments. Due to the high numbers of extracted line-segments in both image and object space, the number of possible patterns is very high. In order to decrease the search space, the innovativeSLIMmethod is performed in three main phases. In the first phase, using a new weighting procedure, only optimum numbers of high-qualified well-distributed patterns, which are more likely to have any correspondence in object space, are selected. In the second phase, the aim is to find a pair with maximum numbers of conjugate lines. To do so, all the possible patterns in object space are screened for each selected image pattern using four predefined geometric criteria. Simultaneously, the correspondence of the other crossing lines is also determined in the same manner. In third phase, the pair with maximum numbers of matched-lines is selected among all the results of second phase. Additionally, the final-phase is done to increase the amount of correctly matched-lines. The main contribution of this investigation is automatic and correct matching of linear features with no need to any initial information. Additionally, the end-points of the corresponding lines are not necessarily conjugate points. The results show the high potential of the proposed method in terms of accuracy, reliability, automation, and time reduction even in images with repetitive patterns or a high numbers of outliers.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2016/00000082/00000005/art00019;jsessionid=rx00wfm9ifj8.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Autonomous Ortho-Rectification of Very High Resolution Imagery Using SIFT and Genetic Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">201605, pp. 377-388(12)</div>
    <div>Authors: Konugurthi, Pramod Kumar; Kune, Raghavendra; Nooka, Ravi; Sarma, Venkatraman</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Ortho-rectification of very high resolution imagery from agile platforms using Rigorous Sensor Model / Rational Functional Model is quite challenging and demands a fair amount of interactivity in Ground Control Point (GCP) identification/selection for refining the model and for final product evaluation. The paper proposes achieving complete automation in the ortho-rectification process by eliminating all the interactive components, and incorporating fault tolerance mechanisms within the model to make the process robust and reliable. The key aspects proposed in this paper are: two stage Scale Invariant Feature Transform (SIFT) based matching to obtain a large numbers of checkpoints using much coarser resolution images such as Landsat/ETM+, followed by a GA to select the right combination of minimal GCPS based on minimizing Root Mean Square Error (RMSE) and maximizing the area covered under GCPS, and finally, a decision rule based product evaluation to make the process operate in an "autonomous closed loop mode". The method is generic and has been tested on hundreds of Cartosat-1/2 images, and has achieved above 90% reliability with sub-pixel relative error of reference data.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 05 - Year 2016</p>
        </footer>
    </body>
    </html>
    