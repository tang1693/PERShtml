
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 07 - Year 2015</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 07 - Year 2015</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00013;jsessionid=6qh7sn4q1pcl0.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Universal Lidar Error Model
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 543-556(14)</div>
    <div>Authors: Rodarmel, Craig; Lee, Mark; Gilbert, John; Wilkinson, Ben; Theiss, Henry; Dolloff, John; O'Neill, Christopher</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Methods to adjust multiple lidar datasets, to adjust lidar with other modalities, and to quantify lidar accuracy are limited. While lidar sensor modeling, error propagation, and data adjustment exist in literature, there are no known implementations supporting all three operations within existing file formats and processing architectures. The Universal Lidar Error Model (ULEM) has been developed to meet the community's need for rigorous error propagation and data adjustment. ULEM exploitation allows one to develop predicted error covariance at single points and full covariance among multiple points. It defines a standardized set of adjustable parameters, provides for the modeling and storage of correlations and cross-correlations among parameters, and stores the data within existing file formats. This paper provides an introduction to ULEM, its metadata requirements, and its model exploitation methods. It concludes with an example of ULEM error modeling, showing the predicted uncertainty agrees well with errors calculated from surveyed control.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00014;jsessionid=6qh7sn4q1pcl0.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Rice Crop Discrimination Using Single Date RISAT1 Hybrid (RH, RV) Polarimetric Data
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 557-563(7)</div>
    <div>Authors: Uppala, Deepika; Kothapalli, Ramana Venkata; Poloju, Srikanth; Mullapudi, Sesha Sai Venkata Rama; Dadhwal, Vinay Kumar</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Rice is the most important food grain crop in India and contributes to more than 40 percent of the country's food grain production. Spaceborne remote sensing offers economically viable and accurate production and area statistics. The utility of optical remote sensing in mapping rice cropped area is limited by persistent cloud cover during monsoon season. Temporal availability of SAR data has facilitated an operational procedure to monitor the rice crop. The current study discriminates rice crop, using single date hybrid polarimetric data available from RISAT-1 SAR. This was subjected to Raney m-δ, m-χ decompositions, and supervised classification was performed. The accuracy was estimated using the field points. The results were compared with rice map generated using optical sensor Resourcesat-2 LISS-IV and statistical data. The spatial agreement between the estimate from RISAT-1 and LISS-IV data was found to be 85 percent. The class kappa value was 0.94 and 0.92 for LISSIV and RISAT-1, respectively.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00017;jsessionid=6qh7sn4q1pcl0.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Fast and Robust Scan-Line Search Algorithm for Object-to-Image Projection of Airborne Pushbroom Images
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 565-572(8)</div>
    <div>Authors: Shen, Xiang; Wu, Guofeng; Sun, Ke; Li, Qingquan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The projection of a 3D object point onto a 2Dimage plane (i.e., the object-to-image projection) is one of the fundamental operations in photogrammetric data processing. Unlike that for a frame image, the object-to-image projection for a pushbroom image is not a straightforward process because each scan line is exposed at a distinct instant of time, and a preliminary step is therefore required to determine the corresponding scan-line coordinate of the ground point to be projected. This paper presents a new scan-line search algorithm for the object-to-image projection of airborne pushbroom images, which employs a coarse-to-fine strategy following four consecutive steps: affine transformation, iterative search, sequential search, and sub-pixel interpolation. The experimental results with 255 pushbroom images captured in various flight conditions show that the proposed algorithm is robust and can save at least 15 percent of the computational time when compared to the previous methods, while the latter often cannot yield correct results in strong turbulence scenarios.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00018;jsessionid=6qh7sn4q1pcl0.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Landsat Data Tiling and Compositing Approach Optimized for Change Detection in the Conterminous United States
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 573-586(14)</div>
    <div>Authors: Nelson, Kurtis J.; Steinwand, Daniel</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Annual disturbance maps are produced by the LANDFIRE program across the conterminous United States (CONUS). Existing LANDFIRE disturbance data from 1999 to 2010 are available and current efforts will produce disturbance data through 2012. A tiling and compositing approach was developed to produce bi-annual images optimized for change detection. A tiled grid of 10,000 × 10,000 30 m pixels was defined for CONUS and adjusted to consolidate smaller tiles along national borders, resulting in 98 non-overlapping tiles. Data from Landsat-5,-7, and -8 were re-projected to the tile extents, masked to remove clouds, shadows, water, and snow/ice, then composited using a cosine similarity approach. The resultant images were used in a change detection algorithm to determine areas of vegetation change. This approach enabled more efficient processing compared to using single Landsat scenes, by taking advantage of overlap between adjacent paths, and allowed an automated system to be developed for the entire process.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00019;jsessionid=6qh7sn4q1pcl0.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Deriving the Spatiotemporal NPP Pattern in Terrestrial Ecosystems of Mongolia Using MODIS Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 587-598(12)</div>
    <div>Authors: Lin, Chinsu; Dugarsuren, Narangarav</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Net primary production (NPP) is a carbon cycle process that is examined within terrestrial ecosystems. Exploring the distribution of nationwide NPP helps to diagnose the response of ecosystems to natural/anthropogenic influences and resource management. Based on the CASA model, the MODIS-NDVI-derived spatiotemporal pattern of Mongolian NPP was analyzed by factorial ANOVA and regression analysis. Results showed that the nationwide distribution of NPP was coincidence with the distribution of terrestrial ecosystems. During the growing season, the monthly-NPP average of every terrestrial ecosystem behaved temporally as an inverse-U shape that peaked in June/July and varied as a power and logarithm function of the monthly average temperature and precipitation respectively. The desert had an insignificant growth of NPP during the growing season, while the forest, grassland, and desert steppe had a significant positive-growth in April/June period and then a significant negative-growth in July/October. Interannual NPP showed insignificant change during a five-year period.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00013;jsessionid=i1lcfcpa8luj.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            The Universal Lidar Error Model
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 543-556(14)</div>
    <div>Authors: Rodarmel, Craig; Lee, Mark; Gilbert, John; Wilkinson, Ben; Theiss, Henry; Dolloff, John; O'Neill, Christopher</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Methods to adjust multiple lidar datasets, to adjust lidar with other modalities, and to quantify lidar accuracy are limited. While lidar sensor modeling, error propagation, and data adjustment exist in literature, there are no known implementations supporting all three operations within existing file formats and processing architectures. The Universal Lidar Error Model (ULEM) has been developed to meet the community's need for rigorous error propagation and data adjustment. ULEM exploitation allows one to develop predicted error covariance at single points and full covariance among multiple points. It defines a standardized set of adjustable parameters, provides for the modeling and storage of correlations and cross-correlations among parameters, and stores the data within existing file formats. This paper provides an introduction to ULEM, its metadata requirements, and its model exploitation methods. It concludes with an example of ULEM error modeling, showing the predicted uncertainty agrees well with errors calculated from surveyed control.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00014;jsessionid=i1lcfcpa8luj.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Rice Crop Discrimination Using Single Date RISAT1 Hybrid (RH, RV) Polarimetric Data
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 557-563(7)</div>
    <div>Authors: Uppala, Deepika; Kothapalli, Ramana Venkata; Poloju, Srikanth; Mullapudi, Sesha Sai Venkata Rama; Dadhwal, Vinay Kumar</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Rice is the most important food grain crop in India and contributes to more than 40 percent of the country's food grain production. Spaceborne remote sensing offers economically viable and accurate production and area statistics. The utility of optical remote sensing in mapping rice cropped area is limited by persistent cloud cover during monsoon season. Temporal availability of SAR data has facilitated an operational procedure to monitor the rice crop. The current study discriminates rice crop, using single date hybrid polarimetric data available from RISAT-1 SAR. This was subjected to Raney m-δ, m-χ decompositions, and supervised classification was performed. The accuracy was estimated using the field points. The results were compared with rice map generated using optical sensor Resourcesat-2 LISS-IV and statistical data. The spatial agreement between the estimate from RISAT-1 and LISS-IV data was found to be 85 percent. The class kappa value was 0.94 and 0.92 for LISSIV and RISAT-1, respectively.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00017;jsessionid=i1lcfcpa8luj.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Fast and Robust Scan-Line Search Algorithm for Object-to-Image Projection of Airborne Pushbroom Images
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 565-572(8)</div>
    <div>Authors: Shen, Xiang; Wu, Guofeng; Sun, Ke; Li, Qingquan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The projection of a 3D object point onto a 2Dimage plane (i.e., the object-to-image projection) is one of the fundamental operations in photogrammetric data processing. Unlike that for a frame image, the object-to-image projection for a pushbroom image is not a straightforward process because each scan line is exposed at a distinct instant of time, and a preliminary step is therefore required to determine the corresponding scan-line coordinate of the ground point to be projected. This paper presents a new scan-line search algorithm for the object-to-image projection of airborne pushbroom images, which employs a coarse-to-fine strategy following four consecutive steps: affine transformation, iterative search, sequential search, and sub-pixel interpolation. The experimental results with 255 pushbroom images captured in various flight conditions show that the proposed algorithm is robust and can save at least 15 percent of the computational time when compared to the previous methods, while the latter often cannot yield correct results in strong turbulence scenarios.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00018;jsessionid=i1lcfcpa8luj.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Landsat Data Tiling and Compositing Approach Optimized for Change Detection in the Conterminous United States
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 573-586(14)</div>
    <div>Authors: Nelson, Kurtis J.; Steinwand, Daniel</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Annual disturbance maps are produced by the LANDFIRE program across the conterminous United States (CONUS). Existing LANDFIRE disturbance data from 1999 to 2010 are available and current efforts will produce disturbance data through 2012. A tiling and compositing approach was developed to produce bi-annual images optimized for change detection. A tiled grid of 10,000 × 10,000 30 m pixels was defined for CONUS and adjusted to consolidate smaller tiles along national borders, resulting in 98 non-overlapping tiles. Data from Landsat-5,-7, and -8 were re-projected to the tile extents, masked to remove clouds, shadows, water, and snow/ice, then composited using a cosine similarity approach. The resultant images were used in a change detection algorithm to determine areas of vegetation change. This approach enabled more efficient processing compared to using single Landsat scenes, by taking advantage of overlap between adjacent paths, and allowed an automated system to be developed for the entire process.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2015/00000081/00000007/art00019;jsessionid=i1lcfcpa8luj.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Deriving the Spatiotemporal NPP Pattern in Terrestrial Ecosystems of Mongolia Using MODIS Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201507, pp. 587-598(12)</div>
    <div>Authors: Lin, Chinsu; Dugarsuren, Narangarav</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Net primary production (NPP) is a carbon cycle process that is examined within terrestrial ecosystems. Exploring the distribution of nationwide NPP helps to diagnose the response of ecosystems to natural/anthropogenic influences and resource management. Based on the CASA model, the MODIS-NDVI-derived spatiotemporal pattern of Mongolian NPP was analyzed by factorial ANOVA and regression analysis. Results showed that the nationwide distribution of NPP was coincidence with the distribution of terrestrial ecosystems. During the growing season, the monthly-NPP average of every terrestrial ecosystem behaved temporally as an inverse-U shape that peaked in June/July and varied as a power and logarithm function of the monthly average temperature and precipitation respectively. The desert had an insignificant growth of NPP during the growing season, while the forest, grassland, and desert steppe had a significant positive-growth in April/June period and then a significant negative-growth in July/October. Interannual NPP showed insignificant change during a five-year period.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 07 - Year 2015</p>
        </footer>
    </body>
    </html>
    