
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 01 - Year 2020</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 01 - Year 2020</h1>
            <p><a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001" target="_blank" style="color: white;">View Full Issue</a></p>
            <p>Photogrammetric Engineering and Remote Sensing</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001/art00008;jsessionid=761s8tp3hc8t7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Application of PCA Analysis and QR Decomposition to Address RFM's Ill-Posedness
        </a>
    </h3>
    <div style="font-style: italic;">202001, pp. 17-21(5)</div>
    <div>Authors: Naeini, Amin Alizadeh; Moghaddam, Sayyed Hamed Alizadeh; Sheikholeslami, Mohammad Moein; Amiri-Simkooei, AliReza</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Rational function model (RFM) is the most widely used sensor model in the remote sensing community. However, it suffers from ill-posedness, challenging its feasibility. This problem, i.e., ill-posedness, is mainly caused due to highly correlated coefficients of theRFM, which magnifies any small perturbations of observations, such as noise and instrumental error. This paper outlines a novel two-step method, called principal component analysis (PCA)-RFM, based on the integration ofPCAand QR decomposition. In the first step, thePCA-RFMreduces the observational perturbations from the design matrix using thePCA. In the next step, theRFM's coefficients are estimated using aQRdecomposition with column pivoting and least square method. According to the results, thePCA-RFMis less sensitive than its rivals to the changes of the ground control point (GCPs) distribution. Geometrically speaking, in addition,PCA-RFMis more accurate than recently established methods even in the presence of the small number ofGCPs.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001/art00009;jsessionid=761s8tp3hc8t7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            3D Iterative Spatiotemporal Filtering for Classification of Multitemporal Satellite Data Sets
        </a>
    </h3>
    <div style="font-style: italic;">202001, pp. 23-31(9)</div>
    <div>Authors: Albanwan, Hessah; Qin, Rongjun; Lu, Xiaohu; Li, Mao; Liu, Desheng; Guldmann, Jean-Michel</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The current practice in land cover/land use change analysis relies heavily on the individually classified maps of the multi-temporal data set. Due to varying acquisition conditions (e.g., illumination, sensors, seasonal differences), the classification maps yielded are often inconsistent through time for robust statistical analysis. 3D geometric features have been shown to be stable for assessing differences across the temporal data set. Therefore, in this article we investigate the use of a multi-temporal orthophoto and digital surface model derived from satellite data for spatiotemporal classification. Our approach consists of two major steps: generating per-class probability distribution maps using the random-forest classifier with limited training samples, and making spatiotemporal inferences using an iterative 3D spatiotemporal filter operating on per-class probability maps. Our experimental results demonstrate that the proposed methods can consistently improve the individual classification results by 2%–6% and thus can be an important postclassification refinement approach.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001/art00010;jsessionid=761s8tp3hc8t7.x-ic-live-02" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Robust Pose Estimation and Calibration of Catadioptric Cameras With Spherical Mirrors
        </a>
    </h3>
    <div style="font-style: italic;">202001, pp. 33-44(12)</div>
    <div>Authors: Filin, Sagi; Ilizirov, Grigory; Elnashef, Bashar</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Catadioptric cameras broaden the field of view and reveal otherwise occluded object parts. They differ geometrically from central-perspective cameras because of light reflection from the mirror surface. To handle these effects, we present new pose-estimation and reconstruction models for imaging through spherical mirrors. We derive a closed-form equivalent to the collinearity principle via which three methods are established to estimate the system parameters: a resection-based one, a trilateration-based one that introduces novel constraints that enhance accuracy, and a direct and linear transform-based one. The estimated system parameters exhibit improved accuracy compared to the state of the art, and analysis shows intrinsic robustness to the presence of a high fraction of outliers. We then show that 3D point reconstruction can be performed at accurate levels. Thus, we provide an in-depth look into the geometrical modeling of spherical catadioptric systems and practical enhancements of accuracies and requirements to reach them.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001/art00008;jsessionid=1wh8g1o85wmrv.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Application of PCA Analysis and QR Decomposition to Address RFM's Ill-Posedness
        </a>
    </h3>
    <div style="font-style: italic;">202001, pp. 17-21(5)</div>
    <div>Authors: Naeini, Amin Alizadeh; Moghaddam, Sayyed Hamed Alizadeh; Sheikholeslami, Mohammad Moein; Amiri-Simkooei, AliReza</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Rational function model (RFM) is the most widely used sensor model in the remote sensing community. However, it suffers from ill-posedness, challenging its feasibility. This problem, i.e., ill-posedness, is mainly caused due to highly correlated coefficients of theRFM, which magnifies any small perturbations of observations, such as noise and instrumental error. This paper outlines a novel two-step method, called principal component analysis (PCA)-RFM, based on the integration ofPCAand QR decomposition. In the first step, thePCA-RFMreduces the observational perturbations from the design matrix using thePCA. In the next step, theRFM's coefficients are estimated using aQRdecomposition with column pivoting and least square method. According to the results, thePCA-RFMis less sensitive than its rivals to the changes of the ground control point (GCPs) distribution. Geometrically speaking, in addition,PCA-RFMis more accurate than recently established methods even in the presence of the small number ofGCPs.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001/art00009;jsessionid=1wh8g1o85wmrv.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            3D Iterative Spatiotemporal Filtering for Classification of Multitemporal Satellite Data Sets
        </a>
    </h3>
    <div style="font-style: italic;">202001, pp. 23-31(9)</div>
    <div>Authors: Albanwan, Hessah; Qin, Rongjun; Lu, Xiaohu; Li, Mao; Liu, Desheng; Guldmann, Jean-Michel</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The current practice in land cover/land use change analysis relies heavily on the individually classified maps of the multi-temporal data set. Due to varying acquisition conditions (e.g., illumination, sensors, seasonal differences), the classification maps yielded are often inconsistent through time for robust statistical analysis. 3D geometric features have been shown to be stable for assessing differences across the temporal data set. Therefore, in this article we investigate the use of a multi-temporal orthophoto and digital surface model derived from satellite data for spatiotemporal classification. Our approach consists of two major steps: generating per-class probability distribution maps using the random-forest classifier with limited training samples, and making spatiotemporal inferences using an iterative 3D spatiotemporal filter operating on per-class probability maps. Our experimental results demonstrate that the proposed methods can consistently improve the individual classification results by 2%–6% and thus can be an important postclassification refinement approach.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2020/00000086/00000001/art00010;jsessionid=1wh8g1o85wmrv.x-ic-live-01" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Robust Pose Estimation and Calibration of Catadioptric Cameras With Spherical Mirrors
        </a>
    </h3>
    <div style="font-style: italic;">202001, pp. 33-44(12)</div>
    <div>Authors: Filin, Sagi; Ilizirov, Grigory; Elnashef, Bashar</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Catadioptric cameras broaden the field of view and reveal otherwise occluded object parts. They differ geometrically from central-perspective cameras because of light reflection from the mirror surface. To handle these effects, we present new pose-estimation and reconstruction models for imaging through spherical mirrors. We derive a closed-form equivalent to the collinearity principle via which three methods are established to estimate the system parameters: a resection-based one, a trilateration-based one that introduces novel constraints that enhance accuracy, and a direct and linear transform-based one. The estimated system parameters exhibit improved accuracy compared to the state of the art, and analysis shows intrinsic robustness to the presence of a high fraction of outliers. We then show that 3D point reconstruction can be performed at accurate levels. Thus, we provide an in-depth look into the geometrical modeling of spherical catadioptric systems and practical enhancements of accuracies and requirements to reach them.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>PE&RS Issue 01 - Year 2020</p>
        </footer>
    </body>
    </html>
    