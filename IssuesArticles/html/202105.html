<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000005/art00011;jsessionid=149n2qh9fmhpm.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Inversion of Solar-Induced Chlorophyll Fluorescence Using Polarization Measurements of Vegetation
        </a>
    </h3>
    <div style="font-style: italic;">202105, pp. 331-338(8)</div>
    <div>Authors: Yao, Haiyan; Li, Ziying; Han, Yang; Niu, Haofang; Hao, Tianyi; Zhou, Yuyu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In vegetation remote sensing, the apparent radiation of the vegetation canopy is often combined with three components derived from different parts of vegetation that have different production mechanisms and optical properties: volume scattering Lvol, polarized light Lpol, and chlorophyll fluorescence ChlF. The chlorophyll fluorescence plays a very important role in vegetation remote sensing, and the polarization information in vegetation remote sensing has become an effective way to characterize the physical characteristics of vegetation. This study analyzes the difference between these three types of radiation flux and utilizes polarization radiation to separate them from the apparent radiation of the vegetation canopy. Specifically, solar-induced chlorophyll fluorescence is extracted from vegetation canopy radiation data using standard Fraunhofer-line discrimination. The results show that polarization measurements can quantitatively separate Lvol, Lpol, and ChlF and extract the solar-induced chlorophyll fluorescence. This study improves our understanding of the light-scattering properties of vegetation canopies and provides insights for developing building models and research algorithms.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000005/art00012;jsessionid=149n2qh9fmhpm.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Quality Assessment of Heterogeneous Training Data Sets for Classification of Urban Area with Landsat Imagery
        </a>
    </h3>
    <div style="font-style: italic;">202105, pp. 339-348(10)</div>
    <div>Authors: Lyimo, Neema Nicodemus; Luo, Fang; Cheng, Qimin; Peng, Hao</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Quality assessment of training samples collected from heterogeneous sources has received little attention in the existing literature. Inspired by Euclidean spectral distance metrics, this article derives three quality measures for modeling uncertainty in spectral information of open-source heterogeneous training samples for classification with Landsat imagery. We prepared eight test case data sets from volunteered geographic information and open government data sources to assess the proposed measures. The data sets have significant variations in quality, quantity, and data type. A correlation analysis verifies that the proposed measures can successfully rank the quality of heterogeneous training data sets prior to the image classification task. In this era of big data, pre-classification quality assessment measures empower research scientists to select suitable data sets for classification tasks from available open data sources. Research findings prove the versatility of the Euclidean spectral distance function to develop quality metrics for assessing open-source training data sets with varying characteristics for urban area classification.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000005/art00013;jsessionid=149n2qh9fmhpm.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Comparative Assessment of Target-Detection Algorithms for Urban Targets Using Hyperspectral Data
        </a>
    </h3>
    <div style="font-style: italic;">202105, pp. 349-362(14)</div>
    <div>Authors: Gakhar, Shalini; Tiwari, K.C.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Hyperspectral data present better opportunities to exploit the treasure of spectral and spatial content that lies within their spectral bands. Hyperspectral data are increasingly being considered for exploring levels of urbanization, due to their capability to capture the spectral variability that a modern urban landscape offers. Data and algorithms are two sides of a coin: while the data capture the variations, the algorithms provide suitable methods to extract relevant information. The literature reports a variety of algorithms for extraction of urban information from any given data, with varying accuracies. This article aims to explore the binary-classifier approach to target detection to extract certain features. Roads and roofs are the most common features present in any urban scene. These experiments were conducted on a subset of AVIRIS-NG hyperspectral data from the Udaipur region of India, with roads and roofs as targets. Four categories of target-detection algorithms are identified from a literature survey and our previous experience—distance measures, angle-based measures, information measures, and machine-learning measures—followed by performance evaluation. The article also presents a brief taxonomy of algorithms; explores methods such as the Mahalanobis angle, which has been reported to be effective for extraction of urban targets; and explores newer machine-learning algorithms to increase accuracy. This work is likely to aid in city planning, sustainable development, and various other governmental and nongovernmental efforts related to urbanization.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000005/art00014;jsessionid=149n2qh9fmhpm.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Real-Time Photogrammetric System for Acquisition and Monitoring of Three-Dimensional Human Body Kinematics
        </a>
    </h3>
    <div style="font-style: italic;">202105, pp. 363-373(11)</div>
    <div>Authors: Chen, Long; Wu, Bo; Zhao, Yao; Li, Yuan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Real-time acquisition and analysis of three-dimensional (3D) human body kinematics are essential in many applications. In this paper, we present a real-time photogrammetric system consisting of a stereo pair of red-green-blue (RGB) cameras. The system incorporates a multi-threaded and graphics processing unit (GPU)-accelerated solution for real-time extraction of 3D human kinematics. A deep learning approach is adopted to automatically extract two-dimensional (2D) human body features, which are then converted to 3D features based on photogrammetric processing, including dense image matching and triangulation. The multi-threading scheme and GPU-acceleration enable real-time acquisition and monitoring of 3D human body kinematics. Experimental analysis verified that the system processing rate reached ∼18 frames per second. The effective detection distance reached 15 m, with a geometric accuracy of better than 1% of the distance within a range of 12 m. The real-time measurement accuracy for human body kinematics ranged from 0.8% to 7.5%. The results suggest that the proposed system is capable of real-time acquisition and monitoring of 3D human kinematics with favorable performance, showing great potential for various applications.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2021/00000087/00000005/art00015;jsessionid=149n2qh9fmhpm.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Modeling Hyperhemispherical Points and Calibrating a Dual-Fish-Eye System for Close-Range Applications
        </a>
    </h3>
    <div style="font-style: italic;">202105, pp. 375-384(10)</div>
    <div>Authors: Castanheiro, Letícia Ferrari; Tommaselli, Antonio Maria Garcia; Berveglieri, Adilson; Campos, Mariana Batista; Junior, José Marcato</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Omnidirectional systems composed of two hyperhemispherical lenses (dual-fish-eye systems) are gaining popularity, but only a few works have studied suitable models for hyperhemispherical lenses and dual-fish-eye calibration. In addition, the effects of using points in the hyperhemispherical field of view in photogrammetric procedures have not been addressed. This article presents a comparative analysis of the fish-eye models (equidistant, equisolid-angle, stereographic, and orthogonal) for hyperhemispherical-lens and dual-fish-eye calibration techniques. The effects of adding points beyond 180° field of view in dual-fish-eye calibration using stability constraints of relative orientation parameters are also assessed. The experiments were performed with the Ricoh Theta dual-fish-eye system, which is composed of fish-eye lenses with a field of view of approximately 190° each. The equisolid-angle model presented the best results in the simultaneous calibration experiments. An accuracy of approximately one pixel in the object space units was achieved, showing the potential of the proposed approach for close-range applications.
            </details>
        </div>
</article>
