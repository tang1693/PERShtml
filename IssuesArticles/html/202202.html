<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000002/art00010;jsessionid=3ng8iuki1ugx6.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Spatiotemporal Temperature Fusion Based on a Deep Convolutional Network
        </a>
    </h3>
    <div style="font-style: italic;">202202, pp. 93-101(9)</div>
    <div>Authors: Wang, Xuehan; Shao, Zhenfeng; Huang, Xiao; Li, Deren</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                High-spatiotemporal-resolution land surface temperature (LST) images are essential in various fields of study. However, due to technical constraints, sensing systems have difficulty in providing LSTs with both high spatial and high temporal resolution. In this study, we propose a multi-scale spatiotemporal temperature-image fusion network (MSTTIFN) to generate high-spatial-resolution LST products. The MSTTIFN builds nonlinear mappings between the input Moderate Resolution Imaging Spectroradiometer (MODIS) LSTs and the out- put Landsat LSTs at the target date with two pairs of references and therefore enhances the resolution of time-series LSTs. We conduct experiments on the actual Landsat andMODISdata in two study areas (Beijing and Shandong) and compare our proposed MSTTIFN with four competing methods: the Spatial and Temporal Adaptive Reflectance Fusion Model, the Flexible Spatiotemporal Data Fusion Model, a two-stream convolutional neural network (StfNet), and a deep learning-based spatiotemporal temperature-fusion network. Results reveal that the MSTTIFN achieves the best and most stable performance.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000002/art00012;jsessionid=3ng8iuki1ugx6.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Three-Dimensional Point Cloud Analysis for Building Seismic Damage Information
        </a>
    </h3>
    <div style="font-style: italic;">202202, pp. 103-111(9)</div>
    <div>Authors: Yang, Fan; Fan, Zhiwei; Wen, Chao; Wang, Xiaoshan; Li, Xiaoli; Li, Zhiqiang; Wen, Xintao; Wei, Zhanyu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Postearthquake building damage assessment requires professional judgment; however, there are factors such as high workload and human error. Making use of Terrestrial Laser Scanning data, this paper presents a method for seismic damage information extraction. This new method is based on principal component analysis calculating the local surface curvature of each point in the point cloud. Then use the nearest point angle algorithm, combined with the data features of the actual measured value to identify point cloud seismic information, and filter the points that tend to the plane by setting the threshold value. Based on the statistical analysis of the normal vector, the raw point cloud data are deplanarized to obtain the preliminary results of seismic damage information. The density clustering algorithm is used to denoise the initially extracted seismic damage information. Ultimately, we can obtain the distribution patterns and characteristics of cracks in the walls of the building. The extraction result of the seismic damage information point cloud data is compared with the photos collected at the site, showing that the algorithm steps successfully identify the crack and shed wall skin information recorded in the site photos (identification rate: 95%). Point cloud distribution maps of cracked and shed siding areas determine quantitative information on seismic damage, providing a higher level of performance and detail than direct contact measurements.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000002/art00014;jsessionid=3ng8iuki1ugx6.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Effectiveness of Deep Learning Trained on SynthCity Data for Urban Point-Cloud Classification
        </a>
    </h3>
    <div style="font-style: italic;">202202, pp. 113-120(8)</div>
    <div>Authors: Spiegel, Steven; Shanks, Casey; Chen, Jorge</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                3D object recognition is one of the most popular areas of study in computer vision. Many of the more recent algorithms focus on indoor point clouds, classifying 3D geometric objects, and segmenting outdoor 3D scenes. One of the challenges of the classification pipeline is finding adequate and accurate training data. Hence, this article seeks to evaluate the accuracy of a synthetically generated data set called SynthCity, tested on two mobile laser-scan data sets. Varying levels of noise were applied to the training data to reflect varying levels of noise in different scanners. The chosen deep-learning algorithm was Kernel Point Convolution, a convolutional neural network that uses kernel points in Euclidean space for convolution weights.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000002/art00015;jsessionid=3ng8iuki1ugx6.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Estimating the Aboveground Biomass of Urban Trees by Combining Optical and Lidar Data: A Case Study of Hengqin, Zhuhai, China
        </a>
    </h3>
    <div style="font-style: italic;">202202, pp. 121-128(8)</div>
    <div>Authors: Bai, Linze; Cheng, Qimin; Shu, Yuxuan; Zhang, Sihang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The aboveground biomass (AGB) of trees plays an important role in the urban ecological environment. Unlike forest biomass estimation, the estimation of AGB of urban trees is greatly influenced by human activities and has strong spatial heterogeneity. In this study, taking Hengqin, China, as an example, we extract the tree area accurately and design a collaborative scheme of optical and lidar data. Finally, five evaluation models are used, including two deep learning models (deep belief network and stacked sparse autoencoder), two machine learning models (random forest and support vector regression), and a geographically weighted regression model. The experimental results show that the deep learning model is effective. The result of the stacked sparse autoen - coder, which is the best model, is thatR2= 0.768 and root mean square error = 18.17 mg/ha. The results show that our method can be applied to estimate the AGB of urban trees, which greatly influences urban ecological construction.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2022/00000088/00000002/art00016;jsessionid=3ng8iuki1ugx6.x-ic-live-01" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Cloud Detection in ZY-3 Multi-Angle Remote Sensing Images
        </a>
    </h3>
    <div style="font-style: italic;">202202, pp. 129-138(10)</div>
    <div>Authors: Huang, Haiyan; Cheng, Qimin; Pan, Yin; Lyimo, Neema Nicodemus; Peng, Hao; Cheng, Gui</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Cloud pollution on remote sensing images seriously affects the actual use rate of remote sensing images. Therefore, cloud detection of remote sensing images is an indispensable part of image preprocessing and image availability screening. Aiming at the lack of short wave infrared and thermal infrared bands in ZY-3 high-resolution satellite images resulting in the poor detection effect, considering the obvious difference in geographic height between cloud and ground surface objects, this paper proposes a thick and thin cloud detection method combining spectral information and digital height model (DHM) based on multi-scale features-convolutional neural network (MF-CNN) model. To verify the importance of DHM height information in cloud detection of ZY-3 multi-angle remote sensing images, this paper implements cloud detection comparison of the data set with and without DHM height information based on the MF-CNN model. The experimental results show that the ZY-3 multi-angle image with DHM height information can effectively improve the confusion between highlighted surface and thin cloud, which also means the assistance of DHM height information can make up for the disadvantage of high-resolution image lacking short wave infrared and thermal infrared bands.
            </details>
        </div>
</article>
