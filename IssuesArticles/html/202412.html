<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00008;jsessionid=9a8ib0ew1wvq.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Remote Sensing Tailing Pond Image–Detection Method Based on YOLOv8-RVSW
        </a>
    </h3>
    <div style="font-style: italic;">202412, pp. 735-744(10)</div>
    <div>Authors: Dang, Zhengjun; Li, Kun</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This study proposes an automated tailings pond-detection method based on the YOLOv8-RVSW model to address the limitations of traditional surveys. A tailings pond dataset was created using high-resolution satellite images, and data quality was improved through data augmentation techniques. In the model, YOLOv8's backbone feature network was replaced with RepViT to effectively capture global and local information. Additionally, the C2f module was enhanced to QuadraSE_C2f to focus on essential feature channels, and WIoUv3 was used as the loss function to improve object localization and detection accuracy. Experimental results indicate that compared with the original model, accuracy increased by 3.9% to 97.4%, recall improved by 4.9% to 96.3%, and mean average precision rose by 2.4% to 98.5%. This method significantly enhances the automation and intelligence of tailings pond monitoring, providing an effective tool for emergency monitoring.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00010;jsessionid=9a8ib0ew1wvq.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring LULC Changes in Babil Province for Sustainable Development Purposes Within the Period 2004–2023
        </a>
    </h3>
    <div style="font-style: italic;">202412, pp. 745-753(9)</div>
    <div>Authors: Jassoom, Hayder Hameed; Abdoon, Rabab Saadoon</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Land use and land cover studies are fundamental to achieving sustainable development goals by providing the information necessary for informed decision-making in social and economic development and natural resource management. This study relied on remote sensing data to analyze and assess land use and land cover changes in Babil Province, Iraq, over the past two decades. The study focused on identifying the patterns and factors influencing these changes, using Landsat satellite imagery to create digital maps classifying land into four main categories: urban lands, bare soil lands, water bodies, and vegetation lands. The results showed a noticeable expansion of urban lands at the expense of bare soil lands, primarily attributed to population growth, economic development, and improved security conditions. This study underscores the importance of sustainable land management and urban planning in Babil Province. These results highlight the importance of sustainable land management in Babil Province, including sound urban planning considering urban expansion's environmental, social, and economic effects. The classification was implemented using a maximum likelihood classifier, and the accuracy assessment yielded satisfactory results with an overall accuracy of 93.5517%. This study encourages using artificial intelligence to track and analyze land use changes in Babil.
            </details>
        </div>
</article>
<article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles <span style="color: rgb(0, 191, 255);">Open Access</span></div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2024/00000090/00000012/art00012;jsessionid=9a8ib0ew1wvq.x-ic-live-03" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Image Fusion in Remote Sensing: An Overview and Meta-Analysis
        </a>
    </h3>
    <div style="font-style: italic;">202412, pp. 755-775(21)</div>
    <div>Authors: Albanwan, Hessah; Qin, Rongjun; Tang, Yang</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Remote sensing image fusion is consistently used to turn raw images of different resolutions, sources, and modalities into accurate, complete, and spatiotemporally coherent images. It facilitates downstream applications such as pan sharpening, change detection, and classification. However, image fusion solutions are highly disparate to various remote sensing problems and are often narrowly defined in existing reviews as topical applications (e. g., pan sharpening). Theoretically, image fusion can be applied to any gridded data through pixel-level operations; thus, we expand its scope by comprehensively surveying relevant works. We develop a simple taxonomy for many-to-one and many-to-many image fusion, defining it as a mapping problem turning one or multiple images into another set based on desired coherence. Furthermore, we provide a meta-analysis to cover 10,420 peer-reviewed papers from the 1980s to 2023 studying various types of image fusion and their applications. Finally, we discuss image fusion's benefits and emerging challenges to provide open research directions.
            </details>
        </div>
</article>
