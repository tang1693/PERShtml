
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 04 - Year 2010</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 04 - Year 2010</h1>
            <p>Displaying articles from Issue 04 - Year 2010.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00001;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Multi-scale Approach for Delineating Individual Tree Crowns with Very High Resolution Imagery
        </a>
    </h3>
    <div style="font-style: italic;">201004, nan</div>
    <div>Authors: Wang, Le</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                This paper presents a multi-scale approach for delineating individual tree crowns (ITC) from high spatial resolution imagery. By analyzing the evolution of image gradients over the scale-space constructed with orthogonal wavelets, tree crown boundaries are effectively strengthened while the textures resulted from tree branches and twigs are largely suppressed. Two scale consistency checks, a scale and a geometric consistency check, were devised to account for tree crownâ€™s radiometric and geometric characteristic. After an edge-enhanced image was acquired, a previously developed marker-controlled watershed segmentation method was adopted to delineate ITC. An experiment was carried out in a study site in California. Field measurements of crown size of 58 trees were compared with those derived from aerial imagery. An R square value of 0.68 was achieved. It was found that crown size was underestimated from the photo interpretation compared to that from the ground survey. The result can be attributed to the fact that pixels lying on the tree crown boundaries are poorly represented in the image.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00002;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            A Modified PSO Algorithm for Remote Sensing Image Template Matching
        </a>
    </h3>
    <div style="font-style: italic;">201004, pp. 379-389(11)</div>
    <div>Authors: An, Ru; Gong, Peng; Wang, Huilin; Feng, Xuezhi; Xiao, Pengfeng; Chen, Qi; Zhang, Qing; Chen, Chunye; Yan, Peng</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Image template matching is essential in image analysis and computer vision tasks. Cross-correlation algorithms are often used in practice, but they are sensitive to nonlinear changes in image intensity and random noise, and are computationally expensive. In this paper, we propose a template-matching algorithm based on a modified particle swarm optimization (PSO) procedure with a mutual information (MI) similarity measure. The influence of MI on the performance of template matching, calculated by different histogram bins, is analyzed first. A modified PSO method (CRI-PSO) is then presented. The proposed algorithm is tested with remote sensing imagery from different sensors and for different seasons. Our experimental results indicate that the proposed approach is robust in practical scenarios and outperforms the standard PSO, multi-start PSO, and cross-correlation algorithms in accuracy and efficiency with our test data. The proposed method can be used for position estimation of aircraft, object recognition, and image retrieval.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00003;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Detection of Roadway Sign Condition Changes using Multi-Scale Sign Image Matching (M-SIM)
        </a>
    </h3>
    <div style="font-style: italic;">201004, pp. 391-405(15)</div>
    <div>Authors: Tsai, Yichang (James); Hu, Zhaozheng; Alberti, Chris</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Roadway signs are important for safety, and transportation agencies need to identify sign condition changes to perform timely maintenance, including replacement. Currently, sign condition changes are inspected manually in the field, which is time consuming, costly, and sometimes dangerous. This paper first proposes a novel algorithm to detect three condition changes: missing, tilted, and blocked signs, using GPS data and video log images. The algorithm consists of three steps: (a) Multi-Scale Sign Image Matching (M-SIM), (b) Image feature analysis, and (c) Sign condition change detection and classification. The algorithm was tested using images with simulated sign condition changes and actual video images taken in Fiscal Year (FY) 2003 and 2005 by the Louisiana Department of Transportation and Development (LADOTD). The tests demonstrate the algorithm is effective to detect three types of sign condition changes. Out of 34,000 actual video log images, the algorithm detected and classified 100 percent of the missing signs, 72.7 percent of the tilted signs, and 66.7 percent of the blocked signs, for an overall 74.3 percent detection rate. These results show that the algorithm is useful for developing an intelligent roadway sign condition change detection system.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00004;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automatic Segmentation of Lidar Data into Coplanar Point Clusters Using an Octree-Based Split-and-Merge Algorithm
        </a>
    </h3>
    <div style="font-style: italic;">201004, pp. 407-420(14)</div>
    <div>Authors: Wang, Miao; Tseng, Yi-Hsing</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Lidar (light detection and ranging) point cloud data contain abundant three-dimensional (3D) information. Dense distribution of scanned points on object surfaces prominently implies surface features. Particularly, plane features commonly appear in a typical lidar dataset of artificial structures. To explore implicitly contained spatial information, this study developed an automatic scheme to segment a lidar point cloud dataset into coplanar point clusters. The central mechanism of the proposed method is a split-and-merge segmentation based on an octree structure. Plane fitting serves as an engine in the mechanism that evaluates how well a group of points fits to a plane. Segmented coplanar points and derived parameters of their best-fit plane are obtained through the process. This paper also provides algorithms to derive various geometric properties of segmented coplanar points, including inherent properties of a plane, intersections of planes, and properties of point distribution on a plane. Several successful cases of handling airborne and terrestrial lidar data as well as a combination of the two are demonstrated. This method should improve the efficiency of object modelling using lidar data.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00005;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Comparison of Airborne and Terrestrial Lidar Estimates of Seacliff Erosion in Southern California
        </a>
    </h3>
    <div style="font-style: italic;">201004, pp. 421-427(7)</div>
    <div>Authors: Young, Adam P.; Olsen, M. J.; Driscoll, N.; Flick, R.E.; Gutierrez, R.; Guza, R.T.; Johnstone, E.; Kuester, F.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Seacliff changes evaluated using both terrestrial and airborne lidar are compared along a 400 m length of coast in Del Mar, California. The many large slides occurring during the rainy, six-month study period (September 2004 to April 2005) were captured by both systems, and the alongshore variation of cliff face volume changes estimated with the airborne and terrestrial systems are strongly correlated (r20.95). However, relatively small changes in the cliff face are reliably detected only with the more accurate terrestrial lidar, and the total eroded volume estimated with the terrestrial system was 30 percent larger than the corresponding airborne estimate. Although relatively small cliff changes are not detected, the airborne system can rapidly survey long cliff lengths and provides coverage on the cliff top and beach at the cliff base.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00006;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Effect of Sun Elevation Angle on DSMs Derived from Cartosat-1 Data
        </a>
    </h3>
    <div style="font-style: italic;">201004, pp. 429-438(10)</div>
    <div>Authors: Martha, Tapas R.; Kerle, Norman; van Westen, Cees J.; Jetten, Victor; Vinod Kumar, K.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Along-track stereoscopic satellite data are increasingly used for automatic extraction of digital surface models (DSM) due to the reduced radiometric variation between the images. Problems remain with the quality of such DSMs, especially in steep terrain. This paper explores the accuracy of DSMs extracted from Cartosat-1 data acquired under high and low sun elevation angle conditions in High Himalayan terrain. The metric accuracy of the DSM was estimated by comparing it with check points obtained with a differential GPS. Additionally, we used spatial discrepancy of drainage lines to estimate errors in the DSM due to spatial auto-correlation. For valleys perpendicular to the satellite track, the DSM extracted from a low sun elevation angle data showed 45 percent higher spatial accuracy than the DSM extracted from high sun elevation angle data. The results indicate that the sun elevation angle and valley orientation affect the spatial accuracy of the DSM, though metric accuracy remains comparable.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2010/00000076/00000004/art00007;jsessionid=2f6o8alb5cjqj.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Reconstruction and Texturing of 3D Urban Terrain from Uncalibrated Monocular Images Using L1Splines
        </a>
    </h3>
    <div style="font-style: italic;">201004, pp. 439-449(11)</div>
    <div>Authors: Bulatov, Dimitri; Lavery, John E.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                We propose a five-step procedure for reconstruction and texturing of 3D urban terrain based on a novel approach for 3D surface reconstruction from optical images produced by monocular optical cameras on small, inexpensive vehicles without external referencing. The approach consists of generation of a nonparametric 2.5D L1-spline surface from a point cloud and iterative creation of parametric 3D L1-spline surfaces based on parametrizations using the previous surface. Computational results for a model house and for Gottesaue Palace in Karlsruhe, Germany are presented. The results presented here are proof of principle results that show that the L1-spline-based procedure is able to reconstruct and texture 3D urban terrain in spite of the large, abrupt changes in density of the point cloud, and that it produces results that are visually competitive with or superior to competing procedures. Future improvements (finer grids, adaptive grids and parameters, reduction of computing time) are outlined.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 04 - Year 2010</p>
        </footer>
    </body>
    </html>
    