
    <!DOCTYPE html>
    <html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Issue 12 - Year 2013</title>
        <style>
            body {
                font-family: Arial, sans-serif;
                line-height: 1.6;
                margin: 0;
                padding: 0;
                background-color: #f9f9f9;
                color: #333;
            }
            header {
                background-color: #1b5faa;
                color: white;
                padding: 20px;
                text-align: center;
            }
            article {
                background-color: #fff;
                margin: 20px auto;
                padding: 20px;
                border: 1px solid #ddd;
                border-radius: 5px;
                max-width: 800px;
            }
            h1 {
                font-size: 1.8em;
                margin-bottom: 0.5em;
            }
            h3 {
                font-size: 1.4em;
                margin: 10px 0;
            }
            .separator {
                border-bottom: 1px solid #ddd;
                margin: 20px 0;
            }
            footer {
                text-align: center;
                margin-top: 40px;
                font-size: 0.9em;
                color: #666;
            }
            .ga-image img {
                max-width: 100%;
                height: auto;
                border: 1px solid #ddd;
                border-radius: 5px;
                margin: 10px 0;
            }
        </style>
    </head>
    <body>
        <header>
            <h1>Issue 12 - Year 2013</h1>
            <p>Displaying articles from Issue 12 - Year 2013.</p>
        </header>
        <main>
    <article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2013/00000079/00000012/art00001;jsessionid=2fguu01vmcgx7.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Temperature and Emissivity Separation from Thermal Airborne Hyperspectral Imager (TASI) Data
        </a>
    </h3>
    <div style="font-style: italic;">201312, nan</div>
    <div>Authors: Hang, Yang; Lifu, Zhang; Yingqian, Gao; Shunshi, Hu; Xueke, Li; Genzhong, Zhang; Qingxi, Tong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The Thermal Airborne Hyperspectral Imager (TASI) acquires 32 bands to provide continuous spectral coverage in the wavelength range of 8 to 11.5μm. The instrument was used during a field campaign in the City of Shijiazhuang, Hebei Province, China, in 2010. Land surface temperature and emissivity were measured near simultaneous with the airborne campaign for calibration and validation of the instrument. Radiance calibration was performed band-by-band using calibration coefficients, and atmospheric correction was performed using data from in situ measurements and the MODTRAN model. Surface temperature and emissivity separation were determined using the ASTER temperature-emissivity separation (ASTER_TES) and iterative spectral smooth temperature and emissivity separation (ISSTES) methods. The ASTER_TES method resulted in satisfactory agreement with ground data, with root mean square error (RMSE) values of 2.2 K for temperature and 0.0460 for broad-emissivity. The ISSTES method provided better ground validation results, with a RMSE for temperature of 1.8 K and a RMSE for broad-emissivity of 0.0394. The emissivity shapes acquired by the two methods were very similar. The results have relevance to studies of global climate change, environmental monitoring, classification, feature mining, and target recognition.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2013/00000079/00000012/art00002;jsessionid=2fguu01vmcgx7.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Hierarchical Method of Urban Building Extraction Inspired by Human Perception
        </a>
    </h3>
    <div style="font-style: italic;">201312, pp. 1109-1119(11)</div>
    <div>Authors: Tao, Chao; Tan, Yihua; Zou, Zheng-rong</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In a high-resolution satellite image, buildings can be considered as clustered objects belonging to the same category. Human perception of such objects consists of an initial identification of simple instances followed by recognition of more complicated ones by deduction. Inspired by this observation, a hierarchical building extraction framework is proposed to simulate the process, which includes three major components. First, a total variation-based segmentation algorithm is presented to decompose the given image into object-level elements. Then, shape analysis is applied to extract some common and easily identified rectangular buildings. Finally, the detection of buildings with complex structures is formulated as a deduction problem based on preceding extracted information in terms of maximum a posteriori (MAP) estimation, and a Bayesian based approach is proposed to deal with it. The experimental results demonstrate that the proposed framework is capable of efficiently identifying urban buildings from high-resolution satellite images.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2013/00000079/00000012/art00003;jsessionid=2fguu01vmcgx7.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Assessing Post-Fire Regeneration in a Mediterranean Mixed Forest Using Lidar Data and Artificial Neural Networks
        </a>
    </h3>
    <div style="font-style: italic;">201312, pp. 1121-1130(10)</div>
    <div>Authors: Debouk, Haifa; Riera-Tatché, Ramon; Vega-García, Cristina</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Post-wildfire management practices can greatly influence vegetation condition and dynamics, and are crucial in Mediterranean erosion-prone poor soil sites. Acquiring accurate ground inventory data is time-consuming, expensive and limited to small areas; but lidar data can be used to assess the impact of fires, and also to determine the convenient silvicultural measurements which should be carried out for site restoration. The aim of this paper was to assess the post-fire regeneration status of the vegetation in Sant Llorenç del Munt massif after a wildfire in summer 2003 by modeling the relationship between lidar height bins and canopy height model (CHM) with field data. Artificial Neural Network (ANN) prediction models provided estimations of vegetation fraction cover, average height (HM) over 1.30 m and number of stems over 1.30 m, with Pearson r values between 0.18 and 0.83. Classification models built with the same variables allowed separating two ground-based regeneration classes (good and scarce regeneration) with an approximate accuracy of 83 to 76 percent (model building and validation data, respectively).
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2013/00000079/00000012/art00004;jsessionid=2fguu01vmcgx7.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Basic Products of the ZiYuan-3 Satellite and Accuracy Evaluation
        </a>
    </h3>
    <div style="font-style: italic;">201312, pp. 1131-1145(15)</div>
    <div>Authors: Pan, Hongbo; Zhang, Guo; Tang, Xinming; Li, Deren; Zhu, Xiaoyong; Zhou, Ping; Jiang, Yonghua</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The ZiYuan-3 satellite allows users to obtain triplet along-track stereo and four-band multispectral images within a single pass. Its basic sensor-corrected products are generated by reimaging with a virtual CCD array in which inner and exterior distortions are resolved and the introduced errors are negligible. In this study, three ZY-3 datasets (Dengfeng, Anping, and Taihang) were used to evaluate the accuracy of bundle adjustment using triplet stereo images. For both standard and long-strip scenes, the RMS errors of plane and elevation were 2.6 m and 1.6 m, respectively, when ground control points (GCPS) were deployed around the corners. The digital surface model (DSM) of the Dengfeng dataset was compared with a reference DEM (1:2000); the RMS errors produced varied with topography, with values of 3.9 m, 6.4 m, and 6.8 m for plain, hilly, and steep mountainous areas, respectively.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2013/00000079/00000012/art00005;jsessionid=2fguu01vmcgx7.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            3D Tree Reconstruction from Simulated Small Footprint Waveform Lidar
        </a>
    </h3>
    <div style="font-style: italic;">201312, pp. 1147-1157(11)</div>
    <div>Authors: Wu, Jiaying; Cawse-Nicholson, Kerry; van Aardt, Jan</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Lidar-based 3D tree reconstruction enables the retrieval of detailed tree structure; however, many existing methods are based on high-density discrete return lidar datasets. In this paper, we propose the use of small footprint waveform lidar data to achieve branch-level tree reconstruction for both leaf-off and leaf-on conditions. The DIRSIG simulation environment was used for algorithm validation purposes. Leaf-off data served as reference, and leaf-on reconstruction for a particular tree resulted in an average branch length difference of 0.07 m and an average angular difference of approximately 6 degrees for both tilt and azimuth angles. Compared to in situ methods this approach may be used by an airborne system for accurate estimation of forest biomass, forest inventory, land degradation, etc. in large scale applications. Furthermore, since this approach can also be applied on leaf-on trees, the tree skeleton characterization eventually can be conducted year round and will be less dependent on seasonal changes.
            </details>
        </div>
</article>
<div class="separator"></div><article style="padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://www.ingentaconnect.com/contentone/asprs/pers/2013/00000079/00000012/art00006;jsessionid=2fguu01vmcgx7.x-ic-live-03" target="_blank" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Illustrating the Temporal Progress of Environmental Change
        </a>
    </h3>
    <div style="font-style: italic;">201312, pp. 1159-1170(12)</div>
    <div>Authors: Harvey, Joann W.; Green, Edwin J.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Remotely sensed Advanced Very High Resolution Radiometer (AVHRR) images, collected during the northern Alaskan growing seasons of 1995 through 2011, and a Bayesian Regression Tree modeling method were brought together, with two novel ideas, to characterize year-to-year environmental change in a multivariate feature space (vegetation, temperature, precipitable water, and cloud cover). The method used collection year as the “response” variable, and the algorithm was applied in two stages to reduce the effects of cloud cover upon the results and to reveal the temporal distribution of cloudy conditions. The analysis identified a shift in environmental conditions between 2003 and 2004 when cloudy and wet conditions were replaced by clear and dry conditions. Gradual changes that occurred throughout the study period were also detected. The analysis also confirmed that it could detect that region’s recent (2007, 2010, 2011) warming associated with sea ice melting.
            </details>
        </div>
</article>
<div class="separator"></div>
        </main>
        <footer>
            <p>Generated automatically for Issue 12 - Year 2013</p>
        </footer>
    </body>
    </html>
    