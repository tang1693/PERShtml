<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://doi.org/10.14358/pers.21-00032r2" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Automated 3D Reconstruction of LoD2 and LoD1 Models for All 10 Million Buildings of the Netherlands
        </a>
    </h3>
    <div style="font-style: italic;">Year: 2022, Volume: 88, Issue: 3</div>
    <div>Authors: Peters, Ravi, Dukai, Balázs, Vitalis, Stelios, van Liempt, Jordi, Stoter, Jantien</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In this paper, we present our workflow to automatically reconstruct three-dimensional (3D) building models based on two-dimensional building polygons and a lidar point cloud. The workflow generates models at different levels of detail (LoDs) to support data requirements of different applications from one consistent source. Specific attention has been paid to make the workflow robust to quickly run a new iteration in case of improvements in an algorithm or in case new input data become available. The quality of the reconstructed data highly depends on the quality of the input data and is monitored in several steps of the process. A 3D viewer has been developed to view and download the openly available 3D data at different LoDs in different formats. The workflow has been applied to all 10 million buildings of the Netherlands. The 3D service will be updated after new input data becomes available.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://doi.org/10.14358/pers.24-00001r2" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Monitoring an Ecosystem in Crisis: Measuring Seagrass Meadow Loss Using Deep Learning in Mosquito Lagoon, Florida
        </a>
    </h3>
    <div style="font-style: italic;">Year: 2024, Volume: 90, Issue: 6</div>
    <div>Authors: Insalaco, Stephanie A., Herrero, Hannah V., Limber, Russ, Oliver, Clancy, Wolfson, William B.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                The ecosystem of Mosquito Lagoon, Florida, has been rapidly deteriorating since the 2010s, with a notable decline in keystone seagrass species. Seagrass is vital for many species in the lagoon, but nutrient overloading, algal blooms, boating, manatee grazing, and other factors have led to its loss. To understand this decline, a deep neural network analyzed Landsat imagery from 2000 to 2020. Results showed significant seagrass loss post-2013, coinciding with the 2011–2013 super algal bloom. Seagrass abundance varied annually, with the model performing best in years with higher seagrass coverage. While the deep learning method successfully identified seagrass, it also revealed that recent seagrass coverage is almost non-existent. This monitoring approach could aid in ecosystem recovery if coupled with appropriate policies for Mosquito Lagoon's restoration.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://doi.org/10.14358/pers.22-00039r2" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            New Generation Hyperspectral Sensors DESIS and PRISMA Provide Improved Agricultural Crop Classifications
        </a>
    </h3>
    <div style="font-style: italic;">Year: 2022, Volume: 88, Issue: 11</div>
    <div>Authors: Aneece, Itiya, Thenkabail, Prasad S.</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Using new remote sensing technology to study agricultural crops will support advances in food and water security. The recently launched, new generation spaceborne hyperspectral sensors, German DLR Earth Sensing Imaging Spectrometer (DESIS) and Italian PRecursore IperSpettrale della Missione Applicativa (PRISMA), provide unprecedented data in hundreds of narrow spectral bands for the study of the Earth. Therefore, our overarching goal in this study was to use these data to explore advances that can be made in agricultural research. We selected PRISMA and DESIS images during the 2020 growing season in California's Central Valley to study seven major crops. PRISMA and DESIS images were highly correlated (R 2of 0.9–0.95). Out of the 235 DESIS bands (400–1000 nm) and 238 PRISMA bands (400–2500 nm), 26 (11%) and 45 (19%) bands, respectively, were optimal to study agricultural crops. These optimal bands provided crop type classification accuracies of 83–90%. Hyperspectral vegetation indices to estimate plant pigment content, stress, biomass, moisture, and cellulose/lignin content were also identified.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://doi.org/10.14358/pers.23-00073r2" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Real-Time Cross-View Image Matching and Camera Pose Determination for Unmanned Aerial Vehicles
        </a>
    </h3>
    <div style="font-style: italic;">Year: 2024, Volume: 90, Issue: 6</div>
    <div>Authors: Chen, Long, Wu, Bo, Duan, Ran, Chen, Zeyu</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                In global navigation satellite systems (GNSS)-denied environments, vision-based methods are commonly used for the positioning and navigation of aerial robots. However, traditional methods often suffer from accumulative estimation errors over time, leading to trajectory drift and lack real-time performance, particularly in large-scale scenarios. This article presents novel approaches, including feature-based cross-view image matching and the integration of visual odometry and photogrammetric space resection for camera pose determination in real-time. Experimental evaluation with real UAV datasets demonstrated that the proposed method reliably matches features in cross-view images with large differences in spatial resolution, coverage, and perspective views, achieving a root-mean-square error of 4.7 m for absolute position error and 0.33° for rotation error, and delivering real-time performance of 12 frames per second (FPS) when implemented in a lightweight edge device onboard UAV. This approach offters potential for diverse intelligent UAV applications in GNSS-denied environments based on real-time feedback control.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://doi.org/10.14358/pers.23-00042r2" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            Investigation of Underwater Photogrammetry Method with Cost-Effective Action Cameras and Comparative Analysis between Reconstructed 3D Point Clouds
        </a>
    </h3>
    <div style="font-style: italic;">Year: 2024, Volume: 90, Issue: 4</div>
    <div>Authors: Hamal, Seda Nur Gamze, Ulvi, Ali</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Currently, digital cameras and equipment used underwater are often inaccessible to the general public due to their professional-grade quality and high cost. Therefore alternative solutions have been sought that are both cost-effective and suitable for nonprofessional use. A review of the literature shows that researchers primarily use GoPro action cameras, while other action cameras with similar capabilities are rarely used. This study thus examines underwater photogrammetry methods using a widely recognized action camera as a reference and compares it with another camera of similar characteristics as a potential alternative. For a comprehensive temporal analysis in underwater studies, both cameras were used to capture photographic and video imagery, and the resulting 3D point clouds were compared. Comparison criteria included data collection and processing times, point cloud densities, cloud-to-cloud analysis, and assessments of surface density and roughness. Having analysed, the study concluded that the proposed alternative action camera can feasibly be used in underwater photogrammetry.
            </details>
        </div>
</article>
<article style="border-top: 1px solid #000; padding: 15px;">
    <div style="display: flex; justify-content: space-between; align-items: center;">
        <div style="font-weight: bold; color: gray;">Research Articles </div>
        
    </div>
    <h3 style="margin: 5px 0;">
        <a href="https://doi.org/10.14358/pers.24-00006r2" rel="noreferrer" style="text-decoration: none; color: #1b5faa;">
            One-Dimensional-Mixed Convolution Neural Network and Covariance Pooling Model for Mineral Mapping of Porphyry Copper Deposit Using PRISMA Hyperspectral Data
        </a>
    </h3>
    <div style="font-style: italic;">Year: 2024, Volume: 90, Issue: 8</div>
    <div>Authors: Peyghambari, Sima, Zhang, Yun, Heidarian, Hassan, Sekandari, Milad</div>
    <div>
            Abstract: 
            <details>
                <summary style="color: #1b5faa;">Read more...</summary>
                Mapping distribution of alterations around porphyry copper deposits (PCDs) greatly affects mineral exploration. Diverse geological processes generate irregular alteration patterns with diverse spectral characteristics in mineral deposits. Applying remotely sensed hyperspectral images (HSIs) is an appealing technology for geologic surveyors to generate alteration maps. Conventional methods mainly use shallow spectral absorption features to discriminate minerals and cannot extract their important spectral information. Deep neural networks with nonlinear layers can evoke the deep spectral and spatial information of HSIs. Deep learning???based methods include fully connected neural networks, convolutional neural networks, and hybrid convolutional networks like mixed convolution neural network and covariance pooling (MCNN‐CP) algorithms. However, each has its advantages and limitations. To significantly avoid losing important spectral features, we proposed a new method by fusing a one‐dimensional convolutional neural network (1D‐CNN) with MCNN‐CP (1D‐MCNN‐CP), achieving an overall accuracy (97.44%) of mineral mapping from PRISMA HSIs. This research deduced that 1D‐MCNN‐CP improved performance and reduced misclassification errors among minerals sharing similar spectral features.
            </details>
        </div>
</article>
